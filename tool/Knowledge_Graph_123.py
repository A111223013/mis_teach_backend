#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import random
import difflib
from typing import List, Dict, Any

# ====== è®€å– API KEY ======
def load_api_keys(env_file: str = "api.env") -> List[str]:
    api_keys = []
    if os.path.exists(env_file):
        print(f"âœ… æˆåŠŸè¼‰å…¥ {env_file}")
        with open(env_file, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip() and not line.startswith("#"):
                    key = line.strip()
                    if key.startswith("AIza"):
                        api_keys.append(key)
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ° {env_file}")
    print(f"ğŸ”‘ è¼‰å…¥APIå¯†é‘°: {len(api_keys)} å€‹")
    return api_keys

# ====== è¼‰å…¥åˆ†é¡æ•¸æ“š ======
def load_classification_data(domains_file: str, micro_concepts_file: str):
    try:
        with open(domains_file, "r", encoding="utf-8") as f:
            domains_data = json.load(f)
        if isinstance(domains_data, dict) and "domains" in domains_data:
            domains_data = domains_data["domains"]

        with open(micro_concepts_file, "r", encoding="utf-8") as f:
            micro_data = json.load(f)
        if isinstance(micro_data, dict) and "micro_concepts" in micro_data:
            micro_data = micro_data["micro_concepts"]

        domains_list = [d.get("name", "") for d in domains_data if isinstance(d, dict) and d.get("name")]
        micro_list = [m.get("name", "") for m in micro_data if isinstance(m, dict) and m.get("name")]

        print(f"ğŸ“Š è¼‰å…¥äº† {len(domains_list)} å€‹å¤§çŸ¥è­˜é» å’Œ {len(micro_list)} å€‹å°çŸ¥è­˜é»")
        return domains_list, micro_list

    except Exception as e:
        print(f"âŒ è¼‰å…¥åˆ†é¡æ•¸æ“šéŒ¯èª¤: {e}")
        return [], []

# ====== è¼‰å…¥é¡Œç›® ======
def load_questions(file_path: str) -> List[Dict[str, Any]]:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict) and "questions" in data:
            data = data["questions"]
        print(f"ğŸ“˜ è¼‰å…¥äº† {len(data)} é¡Œ")
        return data
    except Exception as e:
        print(f"âŒ è¼‰å…¥é¡Œç›®éŒ¯èª¤: {e}")
        return []

# ====== æ–‡å­—æ¨™æº–åŒ– ======
def normalize_text(text: str) -> str:
    return text.lower().replace(" ", "").replace("\n", "")

# ====== å¤§çŸ¥è­˜é»åŒ¹é… ======
def match_domains(text: str, domains: List[str], key_points: str) -> str:
    text_norm = normalize_text(text)
    key_norm = normalize_text(key_points)
    # å…ˆæ‰¾æ–‡å­—ä¸­æˆ– key_points å‡ºç¾çš„ domain
    for d in domains:
        d_norm = normalize_text(d)
        if d_norm in text_norm or d_norm in key_norm:
            return d
    # æ‰¾ä¸åˆ°å°±é¸æœ€æ¥è¿‘çš„ä¸€å€‹
    if domains:
        best_match = max(domains, key=lambda d: difflib.SequenceMatcher(None, text_norm, normalize_text(d)).ratio())
        return best_match
    return ""

# ====== å¾®æ¦‚å¿µåŒ¹é… ======
def match_micro_concepts(text: str, micro_list: List[str], key_points: str) -> List[str]:
    text_norm = normalize_text(text)
    key_norm = normalize_text(key_points)
    matched = []

    # æ‰¾æ–‡å­—ä¸­æˆ– key_points å‡ºç¾çš„å¾®æ¦‚å¿µ
    for m in micro_list:
        m_norm = normalize_text(m)
        if m_norm in text_norm or m_norm in key_norm:
            matched.append(m)

    # æ‰¾ä¸åˆ°å°±é¸æœ€æ¥è¿‘çš„ä¸€å€‹
    if not matched and micro_list:
        best_match = max(micro_list, key=lambda m: difflib.SequenceMatcher(None, text_norm, normalize_text(m)).ratio())
        matched = [best_match]

    return matched

# ====== åˆ†é¡é¡Œç›® ======
def classify_questions(questions: List[Dict[str, Any]], domains: List[str], micro_concepts: List[str]) -> List[Dict[str, Any]]:
    classified = []
    for q in questions:
        text = q.get("question_text", "")
        # å¦‚æœ options æœ‰å…§å®¹ï¼Œä¹Ÿç´å…¥åˆ¤æ–·
        options_text = " ".join(q.get("options", [])) if q.get("options") else ""
        full_text = text + " " + options_text
        key_points = q.get("key-points", "")

        domain = match_domains(full_text, domains, key_points)
        micro_matched = match_micro_concepts(full_text, micro_concepts, key_points)

        q["key-points"] = domain
        q["micro_concepts"] = micro_matched
        classified.append(q)
    return classified

# ====== å„²å­˜ JSON ======
def save_to_json(data: Any, filename: str):
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²è¼¸å‡ºåˆ° {filename}")
    except Exception as e:
        print(f"âŒ å„²å­˜ JSON éŒ¯èª¤: {e}")

# ====== ä¸»ç¨‹å¼ ======
if __name__ == "__main__":
    api_keys = load_api_keys("api.env")
    domains, micro_concepts = load_classification_data("domains_batch_20250903.json", "micro_concepts_batch_20250903.json")
    questions = load_questions("fainaldata_no_del.json")

    if questions:
        classified = classify_questions(questions, domains, micro_concepts)
        save_to_json(classified, "classified_questions.json")
