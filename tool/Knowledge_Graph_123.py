#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import re
import time
from typing import List, Dict, Any
import google.generativeai as genai

# å»¶é²æ™‚é–“ï¼ˆç§’ï¼‰
delay_between_requests = 1.0

# ========== è¼‰å…¥åˆ†é¡æ•¸æ“š ==========
def load_classification_data(domains_file: str, micro_concepts_file: str):
    """å¾ JSON æª”æ¡ˆè¼‰å…¥ key-points å’Œ micro_concepts æ¸…å–®ã€‚"""
    try:
        with open(domains_file, "r", encoding="utf-8") as f:
            domains_data = json.load(f)
        if isinstance(domains_data, dict) and "domains" in domains_data:
            domains_data = domains_data["domains"]

        with open(micro_concepts_file, "r", encoding="utf-8") as f:
            micro_data = json.load(f)
        if isinstance(micro_data, dict) and "micro_concepts" in micro_data:
            micro_data = micro_data["micro_concepts"]

        domains_list = [d.get("name", "") for d in domains_data if isinstance(d, dict) and d.get("name")]
        micro_list = [m.get("name", "") for m in micro_data if isinstance(m, dict) and m.get("name")]

        print(f"ğŸ“Š è¼‰å…¥äº† {len(domains_list)} å€‹ key-points å’Œ {len(micro_list)} å€‹ micro_concepts")
        return domains_list, micro_list

    except Exception as e:
        print(f"âŒ è¼‰å…¥åˆ†é¡æ•¸æ“šéŒ¯èª¤: {e}")
        return [], []

# ========== è¼‰å…¥é¡Œç›® ==========
def load_questions(file_path: str) -> List[Dict[str, Any]]:
    """å¾ JSON æª”æ¡ˆè¼‰å…¥é¡Œç›®æ¸…å–®ã€‚"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict) and "questions" in data:
            data = data["questions"]
        print(f"ğŸ“˜ è¼‰å…¥äº† {len(data)} é¡Œ")
        return data
    except Exception as e:
        print(f"âŒ è¼‰å…¥é¡Œç›®éŒ¯èª¤: {e}")
        return []

# ========== ä½¿ç”¨ Gemini AI æ‰¹é‡åˆ¤æ–·ï¼ˆå«é‡è©¦æ©Ÿåˆ¶ï¼‰ ==========
def classify_with_gemini_batch(model_name: str, questions: List[Dict[str, Any]], domains: List[str], micro_concepts: List[str], max_retries=3):
    """
    æ‰¹é‡è™•ç†é¡Œç›®ï¼Œå°‡å¤šå€‹å•é¡Œæ‰“åŒ…æˆä¸€å€‹ API è«‹æ±‚ã€‚
    
    æ ¹æ“š key-points æ¬„ä½æ˜¯å¦ç‚º "åŸºæœ¬è¨ˆæ¦‚" ä¾†æ±ºå®šåˆ¤æ–·ç¯„åœã€‚
    """
    
    # æ ¹æ“š key-points å€åˆ†éœ€è¦é‡æ–°åˆ¤æ–·çš„é¡Œç›®å’Œåªéœ€åˆ¤æ–· micro_concepts çš„é¡Œç›®
    reclassify_questions = [q for q in questions if q.get('key-points') == 'åŸºæœ¬è¨ˆæ¦‚']
    micro_only_questions = [q for q in questions if q.get('key-points') != 'åŸºæœ¬è¨ˆæ¦‚']

    classified_results = []
    
    # --- è™•ç† key-points ç‚º "åŸºæœ¬è¨ˆæ¦‚" çš„é¡Œç›® ---
    if reclassify_questions:
        print(f"ğŸ”„ æ­£åœ¨é‡æ–°åˆ¤æ–· {len(reclassify_questions)} é¡Œ 'åŸºæœ¬è¨ˆæ¦‚' é¡åˆ¥çš„é¡Œç›®...")
        prompt_reclassify = f"""
è«‹å”åŠ©åˆ¤æ–·ä»¥ä¸‹é¡Œç›®çš„ key-points å’Œ micro_conceptsï¼Œä¸¦ä»¥ JSON é™£åˆ—æ ¼å¼å›è¦†ã€‚

å€™é¸ key-points: {domains}
å€™é¸ micro_concepts: {micro_concepts}

è¦æ±‚ï¼š
1. é‡å°æ¯å€‹é¡Œç›®ï¼Œå¾å€™é¸åˆ—è¡¨ä¸­é¸å‡ºæœ€ç¬¦åˆçš„ key-points å’Œ micro_conceptsã€‚
2. key_points å¿…é ˆç‚ºå–®ä¸€å­—ä¸²ï¼Œå¦‚æœæ²’æœ‰æ˜ç¢ºåŒ¹é…ï¼Œé¸æœ€æ¥è¿‘çš„ä¸€å€‹ã€‚
3. micro_concepts å¿…é ˆç‚ºå­—ä¸²é™£åˆ— (array of strings)ï¼Œå…è¨±å¤šå€‹ï¼Œè‹¥å®Œå…¨æ²’æœ‰åŒ¹é…ï¼Œé¸æœ€æ¥è¿‘çš„ä¸€å€‹ã€‚
4. ä»¥ JSON é™£åˆ—æ ¼å¼å›è¦†ï¼Œæ¯å€‹ç‰©ä»¶ä»£è¡¨ä¸€é¡Œï¼Œå…¶çµæ§‹æ‡‰ç‚ºï¼š
   {{"question_number": "é¡Œè™Ÿ", "key_points": "é¸å‡ºçš„ key-points", "micro_concepts": ["é¸å‡ºçš„å¾®æ¦‚å¿µåˆ—è¡¨"]}}

å¾…åˆ†é¡çš„é¡Œç›®åˆ—è¡¨ï¼š
{json.dumps(reclassify_questions, ensure_ascii=False, indent=2)}
"""
        attempt = 0
        while attempt < max_retries:
            try:
                gemini_model = genai.GenerativeModel(model_name=model_name)
                response = gemini_model.generate_content(
                    prompt_reclassify,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        max_output_tokens=4096  # å¢åŠ  token é™åˆ¶ä»¥è™•ç†å¤šå€‹é¡Œç›®
                    )
                )
                if not response.text:
                    raise ValueError("API å›æ‡‰ç‚ºç©º")

                output_text = response.text
                json_match = re.search(r'\[\s*\{.*\}\s*\]', output_text, re.S)
                if json_match:
                    classified_results.extend(json.loads(json_match.group()))
                    break
                else:
                    raise ValueError("API å›æ‡‰ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON é™£åˆ—")

            except Exception as e:
                attempt += 1
                wait_time = 2 ** attempt
                print(f"âŒ Gemini æ‰¹é‡åˆ¤æ–· (åŸºæœ¬è¨ˆæ¦‚) å¤±æ•— (ç¬¬ {attempt} æ¬¡): {e}, {wait_time}s å¾Œé‡è©¦...")
                time.sleep(wait_time)
        else:
            print("âŒ Gemini åˆ¤æ–·é‡è©¦å¤±æ•—ï¼Œè·³éæ‰€æœ‰ 'åŸºæœ¬è¨ˆæ¦‚' é¡Œç›®ã€‚")

    # --- è™•ç†åªéœ€åˆ¤æ–· micro_concepts çš„é¡Œç›® ---
    if micro_only_questions:
        print(f"ğŸ” æ­£åœ¨åˆ¤æ–· {len(micro_only_questions)} é¡Œ 'éåŸºæœ¬è¨ˆæ¦‚' é¡åˆ¥çš„ micro_concepts...")
        prompt_micro_only = f"""
è«‹å”åŠ©åˆ¤æ–·ä»¥ä¸‹é¡Œç›®çš„ micro_conceptsï¼Œä¸¦ä»¥ JSON é™£åˆ—æ ¼å¼å›è¦†ã€‚
é€™äº›é¡Œç›®çš„ key-points å·²ç¢ºå®šï¼Œè«‹å¿½ç•¥ã€‚

å€™é¸ micro_concepts: {micro_concepts}

è¦æ±‚ï¼š
1. é‡å°æ¯å€‹é¡Œç›®ï¼Œå¾å€™é¸åˆ—è¡¨ä¸­é¸å‡ºé¡Œç›®ä¸­å‡ºç¾çš„æˆ–æœ€ç›¸é—œçš„å¾®æ¦‚å¿µã€‚
2. micro_concepts å¿…é ˆç‚ºå­—ä¸²é™£åˆ— (array of strings)ï¼Œå…è¨±å¤šå€‹ï¼Œè‹¥å®Œå…¨æ²’æœ‰åŒ¹é…ï¼Œé¸æœ€æ¥è¿‘çš„ä¸€å€‹ã€‚
3. ä»¥ JSON é™£åˆ—æ ¼å¼å›è¦†ï¼Œæ¯å€‹ç‰©ä»¶ä»£è¡¨ä¸€é¡Œï¼Œå…¶çµæ§‹æ‡‰ç‚ºï¼š
   {{"question_number": "é¡Œè™Ÿ", "micro_concepts": ["é¸å‡ºçš„å¾®æ¦‚å¿µåˆ—è¡¨"]}}

å¾…åˆ†é¡çš„é¡Œç›®åˆ—è¡¨ï¼š
{json.dumps(micro_only_questions, ensure_ascii=False, indent=2)}
"""
        attempt = 0
        while attempt < max_retries:
            try:
                gemini_model = genai.GenerativeModel(model_name=model_name)
                response = gemini_model.generate_content(
                    prompt_micro_only,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        max_output_tokens=4096
                    )
                )
                if not response.text:
                    raise ValueError("API å›æ‡‰ç‚ºç©º")

                output_text = response.text
                json_match = re.search(r'\[\s*\{.*\}\s*\]', output_text, re.S)
                if json_match:
                    classified_results.extend(json.loads(json_match.group()))
                    break
                else:
                    raise ValueError("API å›æ‡‰ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON é™£åˆ—")
            except Exception as e:
                attempt += 1
                wait_time = 2 ** attempt
                print(f"âŒ Gemini æ‰¹é‡åˆ¤æ–· (micro_concepts) å¤±æ•— (ç¬¬ {attempt} æ¬¡): {e}, {wait_time}s å¾Œé‡è©¦...")
                time.sleep(wait_time)
        else:
            print("âŒ Gemini åˆ¤æ–·é‡è©¦å¤±æ•—ï¼Œè·³éæ‰€æœ‰ 'éåŸºæœ¬è¨ˆæ¦‚' é¡Œç›®ã€‚")

    return classified_results

# ========== å„²å­˜ JSON ==========
def save_to_json(data: Any, filename: str):
    """å°‡è³‡æ–™å„²å­˜ç‚º JSON æª”æ¡ˆã€‚"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²è¼¸å‡ºåˆ° {filename}")
    except Exception as e:
        print(f"âŒ å„²å­˜ JSON éŒ¯èª¤: {e}")

# ========== ä¸»ç¨‹å¼ ==========
if __name__ == "__main__":
    # é€™è£¡åªéœ€è¦è¨­å®šæ¨¡å‹åç¨±ï¼Œä¸éœ€è¦åˆå§‹åŒ–å®Œæ•´çš„æ¨¡å‹ç‰©ä»¶
    genai.configure(api_key="AIzaSyC8y6nInv339tG3j2jwFfd2W3lU1A6aoBg") # è«‹ç¢ºä¿æ‚¨å·²è¨­å®šæ‚¨çš„ API é‡‘é‘°
    model_name = 'gemini-1.5-flash'
    
    # è¼‰å…¥æ‰€æœ‰æ•¸æ“š
    domains, micro_concepts = load_classification_data("domains_batch_20250903.json", "micro_concepts_batch_20250903.json")
    questions = load_questions("check_exam_output2.json")

    if questions and domains and micro_concepts:
        # æ‰¹é‡å‘¼å« Gemini API é€²è¡Œåˆ†é¡
        classified_results = classify_with_gemini_batch(model_name, questions, domains, micro_concepts)

        # å°‡åˆ†é¡çµæœèˆ‡åŸå§‹é¡Œç›®æ•¸æ“šåˆä½µ
        final_questions = []
        result_map = {q.get('question_number'): q for q in classified_results}
        for q in questions:
            q_num = q.get('question_number')
            if q_num in result_map:
                classified_info = result_map[q_num]
                # åªæ›´æ–°æœ‰åˆ¤æ–·çµæœçš„æ¬„ä½
                q['key-points'] = classified_info.get('key_points', q.get('key-points'))
                q['micro_concepts'] = classified_info.get('micro_concepts', q.get('micro_concepts', []))
            final_questions.append(q)

        # å„²å­˜æœ€çµ‚çµæœ
        save_to_json(final_questions, "classified_questions_batch.json")