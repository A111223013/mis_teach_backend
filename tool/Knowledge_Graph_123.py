import json
import random
import threading
import os
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from bson import ObjectId
import google.generativeai as genai
from tqdm import tqdm
import time

# ====== API å¯†é’¥ ======
API_KEYS = [
    "AIzaSyC8y6nInv339tG3j2jwFfd2W3lU1A6aoBg", 
    "AIzaSyAgJI1A8MCEIbvMtuyhWoqvVL1ffDPWjBs",
    "AIzaSyA0qRAxFFrtL7CljNpDG0YV8JIZEdHBI5c", 
    "AIzaSyD1mJZjj7GWLhDYAgXk-BR9DJf_yTJzSMw"
]

key_lock = threading.Lock()
key_index = 0
api_error_count = 0
max_api_errors = 100

def set_api_key():
    global key_index
    with key_lock:
        api_key = API_KEYS[key_index]
        key_index = (key_index + 1) % len(API_KEYS)
    genai.configure(api_key=api_key)

def extract_json_from_text(text):
    if not text:
        return {}
    
    try:
        return json.loads(text)
    except:
        pass
    
    json_match = re.search(r'\{[\s\S]*\}', text)
    if json_match:
        try:
            return json.loads(json_match.group())
        except:
            pass
    
    return {}

def safe_json_parse(text):
    try:
        result = extract_json_from_text(text)
        if result:
            return result
        
        text = text.replace("'", '"')
        lines = text.split('\n')
        json_lines = []
        in_json = False
        
        for line in lines:
            if '{' in line or '[' in line:
                in_json = True
            if in_json:
                json_lines.append(line)
            if '}' in line or ']' in line:
                in_json = False
        
        json_text = '\n'.join(json_lines)
        return json.loads(json_text)
        
    except Exception as e:
        print(f"âš ï¸ JSON parse error: {e}")
        return {}

def match_from_list(text, valid_list):
    if not text or not valid_list:
        return random.choice(valid_list) if valid_list else ""
    
    text_lower = str(text).lower()
    for item in valid_list:
        if str(item).lower() in text_lower:
            return item
    return random.choice(valid_list) if valid_list else ""

# ====== å›ºå®šæ¸…å• ======
domains_list = ["æ•¸ä½é‚è¼¯","ä½œæ¥­ç³»çµ±","ç¨‹å¼èªè¨€","è³‡æ–™çµæ§‹","ç¶²è·¯","è³‡æ–™åº«","AIèˆ‡æ©Ÿå™¨å­¸ç¿’","è³‡è¨Šå®‰å…¨","é›²ç«¯èˆ‡è™›æ“¬åŒ–","ç®¡ç†è³‡è¨Šç³»çµ±ï¼ˆMISï¼‰","è»Ÿé«”å·¥ç¨‹èˆ‡ç³»çµ±é–‹ç™¼"]
blocks_list = ["è³‡æ–™åº«æ¦‚è«–","è³‡æ–™æ¨¡å‹","é—œè¯å¼è³‡æ–™åº«åŸºç¤","SQL åŸºç¤","æŸ¥è©¢é€²éš","æ­£è¦åŒ–èˆ‡è¨­è¨ˆ","äº¤æ˜“ç®¡ç†","ç´¢å¼•èˆ‡æ•ˆèƒ½èª¿æ ¡","åˆ†æ•£å¼è³‡æ–™åº«èˆ‡é›²ç«¯","è³‡æ–™åº«å®‰å…¨èˆ‡å‚™æ´","æ–°èˆˆè­°é¡Œ","äººå·¥æ™ºæ…§æ¦‚è«–","æ©Ÿå™¨å­¸ç¿’åŸºç¤","å¸¸è¦‹æ¼”ç®—æ³•","æ·±åº¦å­¸ç¿’","ç‰¹å¾µå·¥ç¨‹","æ¨¡å‹è©•ä¼°èˆ‡é©—è­‰","AI æ‡‰ç”¨é ˜åŸŸ","AI èˆ‡ç¤¾æœƒ","è³‡è¨Šå®‰å…¨æ¦‚è«–","å¯†ç¢¼å­¸åŸºç¤","ç¶²è·¯å®‰å…¨","ç³»çµ±å®‰å…¨","æ‡‰ç”¨å®‰å…¨","å®‰å…¨ç®¡ç†","æ–°èˆˆè­°é¡Œ","é›²ç«¯è¨ˆç®—æ¦‚è«–","è™›æ“¬åŒ–æŠ€è¡“","é›²ç«¯åŸºç¤æ¶æ§‹","é›²ç«¯é‹ç®—å¹³å°","é›²ç«¯å®‰å…¨","é›²ç«¯æ‡‰ç”¨","MIS æ¦‚è«–","è³‡è¨Šç³»çµ±é¡å‹","è³‡è¨Šç³»çµ±é–‹ç™¼èˆ‡å°å…¥","è³‡è¨Šç§‘æŠ€èˆ‡çµ„ç¹”","MIS èˆ‡æ±ºç­–æ”¯æŒ","MIS çš„æ–°èˆˆè­°é¡Œ","è»Ÿé«”å·¥ç¨‹æ¦‚è«–","è»Ÿé«”é–‹ç™¼æ–¹æ³•","ç³»çµ±åˆ†æèˆ‡è¨­è¨ˆ","ç‰©ä»¶å°å‘æ–¹æ³•","è»Ÿé«”æ¸¬è©¦èˆ‡é©—è­‰","è»Ÿé«”ç¶­è­·èˆ‡æ¼”åŒ–","è»Ÿé«”å“è³ªä¿è­‰","è»Ÿé«”å°ˆæ¡ˆç®¡ç†","æ•¸å€¼ç³»çµ±èˆ‡äºŒé€²åˆ¶","å¸ƒæ—ä»£æ•¸èˆ‡é‚è¼¯é–˜","å¾ªåºé‚è¼¯","é›»è…¦çµ„ç¹”","è¨˜æ†¶é«”éšå±¤","ä½œæ¥­ç³»çµ±æ¦‚è«–","è¡Œç¨‹èˆ‡åŸ·è¡Œç·’ç®¡ç†","è¨˜æ†¶é«”ç®¡ç†","æª”æ¡ˆç³»çµ±","è¨­å‚™ç®¡ç†","ç¨‹å¼èªè¨€æ¦‚è«–","ç¨‹å¼è¨­è¨ˆç¯„å¼","ç¨‹å¼èªè¨€åŸºç¤","ç¨‹å¼èªè¨€æ ¸å¿ƒæ¦‚å¿µ","è¨˜æ†¶é«”ç®¡ç†","è³‡æ–™çµæ§‹æ¦‚è«–","ç·šæ€§è³‡æ–™çµæ§‹","éç·šæ€§è³‡æ–™çµæ§‹","é›œæ¹Šè¡¨èˆ‡æ¼”ç®—æ³•","æŠ½è±¡è³‡æ–™å‹æ…‹ (ADT)","ç¶²è·¯æ¦‚è«–","ç¶²è·¯å”å®šèˆ‡æ¶æ§‹","ç¶²è·¯è¨­å‚™","ç¶²éš›ç¶²è·¯èˆ‡æœå‹™","ç¶²è·¯å®‰å…¨"]
micro_concepts_list = ["è³‡æ–™ã€è³‡è¨Šèˆ‡çŸ¥è­˜çš„é—œä¿‚", "è³‡æ–™åº«çš„å®šç¾©èˆ‡ç‰¹æ€§", "è³‡æ–™åº«ç³»çµ±çš„çµ„æˆ (DBMS, Database, Application)", "è³‡æ–™åº« vs æª”æ¡ˆç³»çµ±", "éšå±¤å¼æ¨¡å‹", "ç¶²è·¯æ¨¡å‹", "é—œè¯å¼æ¨¡å‹ (Relational Model)", "ç‰©ä»¶å°å‘è³‡æ–™æ¨¡å‹", "NoSQL èˆ‡æ–°èˆˆè³‡æ–™æ¨¡å‹", "é—œä¿‚ (Relation)ã€å±¬æ€§ (Attribute)ã€å…ƒçµ„ (Tuple)", "ä¸»éµ (Primary Key) èˆ‡å¤–éµ (Foreign Key)", "å®Œæ•´æ€§ç´„æŸ (Integrity Constraints)", "DDLï¼ˆè³‡æ–™å®šç¾©èªè¨€ï¼‰", "DMLï¼ˆè³‡æ–™æ“ä½œèªè¨€ï¼šSELECT, INSERT, UPDATE, DELETEï¼‰", "DCLï¼ˆå­˜å–æ§åˆ¶ï¼šGRANT, REVOKEï¼‰", "TCLï¼ˆäº¤æ˜“æ§åˆ¶ï¼šCOMMIT, ROLLBACKï¼‰", "èšåˆå‡½æ•¸ (COUNT, AVG, SUM, MAX, MIN)", "å­æŸ¥è©¢ (Subquery)", "JOIN (Inner, Outer, Cross)", "è¦–åœ– (View)", "ç¬¬ä¸€æ­£è¦åŒ– (1NF)", "ç¬¬äºŒæ­£è¦åŒ– (2NF)", "ç¬¬ä¸‰æ­£è¦åŒ– (3NF)", "BCNF", "åæ­£è¦åŒ– (Denormalization)", "äº¤æ˜“ (Transaction) èˆ‡å…¶ç‰¹æ€§ (ACID)", "é–å®šæ©Ÿåˆ¶ (Locking)", "ä½µç™¼æ§åˆ¶ (Concurrency Control)", "æ­»çµ (Deadlock) èˆ‡è§£æ±ºæ–¹æ³•", "ç´¢å¼• (B-Tree, Hash Index)", "æŸ¥è©¢æœ€ä½³åŒ– (Query Optimization)", "è³‡æ–™åº«å¿«å– (Buffer Pool)", "åˆ†å‰² (Partitioning) èˆ‡åˆ†ç‰‡ (Sharding)", "åˆ†æ•£å¼è³‡æ–™åº«æ¶æ§‹", "CAP ç†è«– (Consistency, Availability, Partition Tolerance)", "é›²ç«¯è³‡æ–™åº« (AWS RDS, Google Cloud Spanner)", "NoSQL (MongoDB, Cassandra, Redis)", "ä½¿ç”¨è€…æˆæ¬Šèˆ‡è§’è‰²", "SQL Injection èˆ‡é˜²ç¯„", "å‚™ä»½èˆ‡é‚„åŸ (Backup & Recovery)", "é«˜å¯ç”¨æ€§ (HA) èˆ‡ç½é›£å¾©åŸ (DR)", "è³‡æ–™æ¢å‹˜ (Data Mining)", "å¤§æ•¸æ“šè™•ç† (Big Data, Hadoop, Spark)", "è³‡æ–™å€‰å„² (Data Warehouse)", "ETL (Extract, Transform, Load)", "å•†æ¥­æ™ºæ…§ (Business Intelligence, BI)", "AI çš„å®šç¾©èˆ‡æ­·å²", "å¼±äººå·¥æ™ºæ…§ vs å¼·äººå·¥æ™ºæ…§", "æ©Ÿå™¨å­¸ç¿’ã€æ·±åº¦å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§çš„é—œä¿‚", "ç›£ç£å¼å­¸ç¿’ (Supervised Learning)", "éç›£ç£å¼å­¸ç¿’ (Unsupervised Learning)", "å¼·åŒ–å­¸ç¿’ (Reinforcement Learning)", "éæ“¬åˆèˆ‡æ¬ æ“¬åˆ", "ç·šæ€§å›æ­¸èˆ‡é‚è¼¯å›æ­¸", "æ±ºç­–æ¨¹èˆ‡éš¨æ©Ÿæ£®æ—", "æ”¯æ´å‘é‡æ©Ÿ (SVM)", "K-è¿‘é„°æ¼”ç®—æ³• (KNN)", "èšé¡æ¼”ç®—æ³• (K-Means, Hierarchical Clustering)", "ç¥ç¶“ç¶²è·¯åŸºç¤ (Perceptron, MLP)", "æ²ç©ç¥ç¶“ç¶²è·¯ (CNN)", "å¾ªç’°ç¥ç¶“ç¶²è·¯ (RNN, LSTM, GRU)", "Transformer èˆ‡æ³¨æ„åŠ›æ©Ÿåˆ¶ (Attention)", "è³‡æ–™å‰è™•ç† (Normalization, Standardization)", "ç‰¹å¾µé¸æ“‡èˆ‡é™ç¶­ (PCA, LDA)", "ç‰¹å¾µæŠ½å–èˆ‡è¡¨ç¤ºå­¸ç¿’", "è¨“ç·´é›†ã€é©—è­‰é›†ã€æ¸¬è©¦é›†", "è©•ä¼°æŒ‡æ¨™ (Accuracy, Precision, Recall, F1-score)", "äº¤å‰é©—è­‰ (Cross Validation)", "è‡ªç„¶èªè¨€è™•ç† (NLP)", "é›»è…¦è¦–è¦º (CV)", "èªéŸ³è¾¨è­˜", "ç”Ÿæˆå¼ AI (GAN, Diffusion Models)", "AI å€«ç†èˆ‡åå·®", "AI å®‰å…¨èˆ‡é¢¨éšª", "AI èˆ‡æœªä¾†å·¥ä½œ", "è³‡è¨Šå®‰å…¨çš„ CIA ä¸‰è¦ç´  (Confidentiality, Integrity, Availability)", "å¸¸è¦‹å¨è„… (æƒ¡æ„ç¨‹å¼ã€ç¤¾äº¤å·¥ç¨‹ã€ç¶²è·¯æ”»æ“Š)", "å°ç¨±å¼åŠ å¯† (AES, DES)", "éå°ç¨±å¼åŠ å¯† (RSA, ECC)", "é›œæ¹Šå‡½æ•¸ (MD5, SHA-2, SHA-3)", "æ•¸ä½ç°½ç« èˆ‡æ†‘è­‰", "é˜²ç«ç‰† (Firewall)", "å…¥ä¾µåµæ¸¬èˆ‡é˜²ç¦¦ç³»çµ± (IDS/IPS)", "VPN èˆ‡å®‰å…¨é€šè¨Šå”å®š (SSL/TLS, IPSec)", "ä½œæ¥­ç³»çµ±å®‰å…¨æ©Ÿåˆ¶", "ä½¿ç”¨è€…èªè­‰èˆ‡å­˜å–æ§åˆ¶", "æ¼æ´ç®¡ç†èˆ‡ä¿®è£œ", "Web å®‰å…¨ (SQL Injection, XSS, CSRF)", "è¡Œå‹•æ‡‰ç”¨ç¨‹å¼å®‰å…¨", "é›²ç«¯å®‰å…¨è­°é¡Œ", "é¢¨éšªè©•ä¼°", "ISO 27001 èˆ‡å®‰å…¨æ²»ç†", "äº‹ä»¶å›æ‡‰ (Incident Response)", "å‚™æ´èˆ‡ç½é›£å¾©åŸ", "å€å¡Šéˆèˆ‡å®‰å…¨", "é›¶ä¿¡ä»»æ¶æ§‹ (Zero Trust)", "AI åœ¨è³‡å®‰ä¸­çš„æ‡‰ç”¨", "é›²ç«¯è¨ˆç®—çš„å®šç¾©", "é›²ç«¯æœå‹™æ¨¡å¼ (IaaS, PaaS, SaaS)", "éƒ¨ç½²æ¨¡å¼ (å…¬æœ‰é›²ã€ç§æœ‰é›²ã€æ··åˆé›²ã€å¤šé›²)", "ç³»çµ±è™›æ“¬åŒ– (VMware, KVM, Hyper-V)", "å®¹å™¨åŒ–æŠ€è¡“ (Docker, LXC)", "å®¹å™¨ç·¨æ’ (Kubernetes)", "è³‡æ–™ä¸­å¿ƒ (Data Center)", "åˆ†æ•£å¼å„²å­˜ (HDFS, Ceph)", "è² è¼‰å¹³è¡¡ (Load Balancer)", "AWS æ ¸å¿ƒæœå‹™ (EC2, S3, RDS, Lambda)", "Google Cloud Platform (GCP)", "Microsoft Azure", "èº«åˆ†èˆ‡å­˜å–ç®¡ç† (IAM)", "é›²ç«¯è³‡å®‰æ¨™æº– (CIS, NIST)", "é›²ç«¯åŠ å¯†èˆ‡é˜²è­·", "Serverless æ¶æ§‹", "é‚Šç·£é‹ç®— (Edge Computing)", "é›²ç«¯èˆ‡ AI/å¤§æ•¸æ“šæ•´åˆ", "è³‡è¨Šç³»çµ±çš„å®šç¾©", "MIS çš„è§’è‰²èˆ‡åƒ¹å€¼", "çµ„ç¹”èˆ‡è³‡è¨Šç³»çµ±çš„äº’å‹•", "äº¤æ˜“è™•ç†ç³»çµ± (TPS)", "ç®¡ç†å ±è¡¨ç³»çµ± (MIS)", "æ±ºç­–æ”¯æ´ç³»çµ± (DSS)", "ä¼æ¥­è³‡æºè¦åŠƒ (ERP)", "ä¾›æ‡‰éˆç®¡ç† (SCM)", "é¡§å®¢é—œä¿‚ç®¡ç† (CRM)", "ç³»çµ±ç™¼å±•ç”Ÿå‘½é€±æœŸ (SDLC)", "æ•æ·å¼æ–¹æ³• (Agile)", "å°ˆæ¡ˆç®¡ç†èˆ‡è©•ä¼°", "IT å°çµ„ç¹”çš„å½±éŸ¿", "é›»å­å•†å‹™ (E-Commerce)", "çŸ¥è­˜ç®¡ç† (KM)", "å•†æ¥­æ™ºæ…§ (BI)", "è³‡æ–™å€‰å„²èˆ‡è³‡æ–™æ¢å‹˜", "å³æ™‚æ±ºç­–æ”¯æŒç³»çµ±", "æ•¸ä½è½‰å‹ (Digital Transformation)", "é›²ç«¯ MIS", "AI èˆ‡ MIS æ•´åˆ", "è»Ÿé«”å·¥ç¨‹çš„å®šç¾©", "è»Ÿé«”å·¥ç¨‹åŸå‰‡", "è»Ÿé«”ç”Ÿå‘½é€±æœŸ", "ç€‘å¸ƒæ¨¡å‹ (Waterfall)", "æ¼”åŒ–å¼æ¨¡å‹ (Evolutionary)", "æ•æ·é–‹ç™¼ (Agile, Scrum, XP)", "DevOps", "éœ€æ±‚å·¥ç¨‹ (Requirement Engineering)", "UML åœ– (Use Case, Class, Sequence, Activity)", "ç³»çµ±è¨­è¨ˆèˆ‡å»ºæ¨¡", "ç‰©ä»¶å°å‘ç¨‹å¼è¨­è¨ˆ (OOP) åŸºç¤ (Class, Inheritance, Polymorphism)", "ç‰©ä»¶å°å‘åˆ†æ (OOA)", "ç‰©ä»¶å°å‘è¨­è¨ˆ (OOD)", "æ¸¬è©¦å±¤æ¬¡ (Unit Test, Integration Test, System Test)", "æ¸¬è©¦æ–¹æ³• (Black Box, White Box)", "è‡ªå‹•åŒ–æ¸¬è©¦", "ç¶­è­·é¡å‹ (Corrective, Adaptive, Perfective, Preventive)", "è»Ÿé«”ç‰ˆæœ¬ç®¡ç† (Git, SVN)", "æŒçºŒæ•´åˆèˆ‡æŒçºŒéƒ¨ç½² (CI/CD)", "è»Ÿé«”å“è³ªæ¨¡å‹ (ISO 9126, ISO 25010)", "å“è³ªä¿è­‰æµç¨‹", "Code Review èˆ‡ Refactoring", "å°ˆæ¡ˆè¦åŠƒèˆ‡æ™‚ç¨‹ä¼°ç®— (PERT, Gantt)", "é¢¨éšªç®¡ç†", "æˆæœ¬ä¼°ç®— (COCOMO æ¨¡å‹)", "äºŒé€²åˆ¶ã€å…«é€²åˆ¶ã€åé€²åˆ¶ã€åå…­é€²åˆ¶", "äºŒè£œæ•¸ (Two's Complement)", "å¸ƒæ—ä»£æ•¸", "åŸºæœ¬é‚è¼¯é–˜", "çµ„åˆé‚è¼¯", "æ­£åå™¨ (Flip-Flop)", "æš«å­˜å™¨ (Register) èˆ‡è¨ˆæ•¸å™¨ (Counter)", "CPU æ¶æ§‹", "æŒ‡ä»¤é›†æ¶æ§‹ (ISA)", "åŒ¯æµæ’ (Bus)", "å¿«å–è¨˜æ†¶é«” (Cache)", "ä¸»è¨˜æ†¶é«” (RAM)", "å„²å­˜è£ç½® (Storage)", "ä½œæ¥­ç³»çµ±çš„åŠŸèƒ½", "æ ¸å¿ƒ (Kernel)", "è¡Œç¨‹ (Process)", "åŸ·è¡Œç·’ (Thread)", "è¡Œç¨‹æ’ç¨‹", "åŒæ­¥èˆ‡äº’æ–¥", "åˆ†é  (Paging)", "åˆ†æ®µ (Segmentation)", "è™›æ“¬è¨˜æ†¶é«” (Virtual Memory)", "æª”æ¡ˆç³»çµ±çš„çµæ§‹", "æª”æ¡ˆå­˜å–æ¬Šé™", "é©…å‹•ç¨‹å¼ (Driver)", "I/O ç®¡ç†", "é«˜éšèªè¨€ vs ä½éšèªè¨€", "ç·¨è­¯å¼èªè¨€ vs ç›´è­¯å¼èªè¨€", "ç‰©ä»¶å°å‘ç¨‹å¼è¨­è¨ˆ (OOP)", "å‡½æ•¸å¼ç¨‹å¼è¨­è¨ˆ (Functional Programming)", "è®Šæ•¸èˆ‡è³‡æ–™å‹æ…‹", "æ§åˆ¶çµæ§‹", "å‡½å¼èˆ‡æ¨¡çµ„", "éŒ¯èª¤è™•ç†èˆ‡ä¾‹å¤–", "å †ç–Š (Stack) èˆ‡å †ç© (Heap)", "åƒåœ¾å›æ”¶ (Garbage Collection)", "è³‡æ–™çµæ§‹çš„å®šç¾©èˆ‡é‡è¦æ€§", "é™£åˆ— (Array)", "éˆçµä¸²åˆ— (Linked List)", "å †ç–Š (Stack)", "ä½‡åˆ— (Queue)", "æ¨¹ (Tree)", "åœ– (Graph)", "é›œæ¹Šè¡¨ (Hash Table)", "æ’åºæ¼”ç®—æ³•", "æœå°‹æ¼”ç®—æ³•", "ADT çš„æ¦‚å¿µ", "ç¶²è·¯çš„å®šç¾©èˆ‡åˆ†é¡", "ç¶²è·¯æ‹“æ’² (Network Topology)", "OSI ä¸ƒå±¤æ¨¡å‹", "TCP/IP å”å®šå †ç–Š", "IP ä½å€èˆ‡ MAC ä½å€", "é›†ç·šå™¨ (Hub)ã€äº¤æ›å™¨ (Switch)ã€è·¯ç”±å™¨ (Router)", "DNSï¼ˆç¶²åŸŸåç¨±ç³»çµ±ï¼‰", "HTTP/HTTPS", "é›»å­éƒµä»¶å”å®š (SMTP, POP3, IMAP)", "é˜²ç«ç‰†èˆ‡ VPN", "DoS/DDoS æ”»æ“Š"]

# ====== ID æ˜ å°„ ======
domain_map, block_map, micro_map = {}, {}, {}
lock = threading.Lock()

def classify_question(q, max_retries=2):
    global api_error_count
    
    for attempt in range(max_retries):
        try:
            if api_error_count > max_api_errors:
                return create_random_classification(q)
                
            set_api_key()
            q_text = q.get("question_text", "")
            q_keys = q.get("key-points", [])
            q_options = q.get("options", [])

            prompt = f"""è¯·åˆ†æä»¥ä¸‹é¢˜ç›®å¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š
é¢˜ç›®: {q_text}
é€‰é¡¹: {q_options}
çŸ¥è¯†ç‚¹: {q_keys}

è¯·é€‰æ‹©æœ€åˆé€‚çš„åˆ†ç±»ï¼ˆå¿…é¡»ä»ç»™å®šåˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ï¼š
1. å¤§çŸ¥è¯†ç‚¹: {domains_list}
2. åŒºå—: {blocks_list}
3. å°çŸ¥è¯†ç‚¹: {micro_concepts_list}

è¿”å›æ ¼å¼: {{"domain": "åç§°", "block": "åç§°", "micro_concepts": ["åç§°1", "åç§°2"]}}
"""

            model = genai.GenerativeModel("gemini-1.5-flash")
            response = model.generate_content(prompt)
            parsed = safe_json_parse(response.text)
            
            if not parsed:
                api_error_count += 1
                raise ValueError("JSONè§£æå¤±è´¥")
            
            domain = match_from_list(parsed.get("domain",""), domains_list)
            block = match_from_list(parsed.get("block",""), blocks_list)
            mc_list = [match_from_list(mc, micro_concepts_list) for mc in parsed.get("micro_concepts", [])[:2]]
            
            if not mc_list:
                mc_list = random.sample(micro_concepts_list, k=min(1, len(micro_concepts_list)))

            with lock:
                if domain not in domain_map:
                    domain_map[domain] = str(ObjectId())
                domain_id = domain_map[domain]

                if block not in block_map:
                    block_map[block] = str(ObjectId())
                block_id = block_map[block]

                mc_ids = []
                for mc in mc_list:
                    if mc not in micro_map:
                        micro_map[mc] = str(ObjectId())
                    mc_ids.append(micro_map[mc])

            q_id = str(ObjectId())
            return {
                "domain": {"_id": domain_id, "name": domain},
                "block": {"_id": block_id, "domain_id": domain_id, "title": block},
                "micro_concepts": [{"_id": micro_map[mc], "block_id": block_id, "name": mc, "dependencies": []} for mc in mc_list],
                "question": {"_id": q_id, "text": q_text, "options": q_options, "micro_concepts": mc_ids}
            }
            
        except Exception as e:
            if attempt == max_retries - 1:
                return create_random_classification(q)
            time.sleep(1)

def create_random_classification(q):
    q_text = q.get("question_text", "")
    q_options = q.get("options", [])
    
    domain = random.choice(domains_list)
    block = random.choice(blocks_list)
    mc_list = random.sample(micro_concepts_list, k=min(1, len(micro_concepts_list)))
    
    with lock:
        if domain not in domain_map:
            domain_map[domain] = str(ObjectId())
        domain_id = domain_map[domain]

        if block not in block_map:
            block_map[block] = str(ObjectId())
        block_id = block_map[block]

        mc_ids = []
        for mc in mc_list:
            if mc not in micro_map:
                micro_map[mc] = str(ObjectId())
            mc_ids.append(micro_map[mc])

    q_id = str(ObjectId())
    return {
        "domain": {"_id": domain_id, "name": domain},
        "block": {"_id": block_id, "domain_id": domain_id, "title": block},
        "micro_concepts": [{"_id": micro_map[mc], "block_id": block_id, "name": mc, "dependencies": []} for mc in mc_list],
        "question": {"_id": q_id, "text": q_text, "options": q_options, "micro_concepts": mc_ids}
    }

def main():
    try:
        with open("error_questions.json", "r", encoding="utf-8") as f:
            questions = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
        return

    print(f"ğŸ“Š å¼€å§‹å¤„ç† {len(questions)} ä¸ªé—®é¢˜")
    
    results = []
    max_workers = min(4, len(API_KEYS))
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(classify_question, q) for q in questions[:100]]  # å…ˆæµ‹è¯•100ä¸ª
        for future in tqdm(as_completed(futures), total=len(futures), desc="åˆ†ç±»ä¸­"):
            results.append(future.result())

    # é‡å»ºæ•°æ®ç»“æ„ - è¿™æ˜¯å…³é”®ä¿®å¤
    domains_dict, blocks_dict, micros_dict = {}, {}, {}
    questions_out = []

    for r in results:
        # å¤„ç†é¢†åŸŸ
        domain = r["domain"]
        if domain["_id"] not in domains_dict:
            domains_dict[domain["_id"]] = {
                "_id": domain["_id"],
                "name": domain["name"],
                "blocks": set()
            }
        
        # å¤„ç†åŒºå—
        block = r["block"]
        if block["_id"] not in blocks_dict:
            blocks_dict[block["_id"]] = {
                "_id": block["_id"],
                "domain_id": block["domain_id"],
                "title": block["title"],
                "subtopics": set()
            }
        domains_dict[block["domain_id"]]["blocks"].add(block["_id"])
        
        # å¤„ç†å°çŸ¥è¯†ç‚¹
        for mc in r["micro_concepts"]:
            if mc["_id"] not in micros_dict:
                micros_dict[mc["_id"]] = {
                    "_id": mc["_id"],
                    "block_id": mc["block_id"],
                    "name": mc["name"],
                    "dependencies": []
                }
            blocks_dict[mc["block_id"]]["subtopics"].add(mc["_id"])
        
        # å¤„ç†é—®é¢˜
        q = r["question"]
        questions_out.append({
            "_id": q["_id"],
            "text": q["text"],
            "options": q["options"],
            "micro_concepts": q["micro_concepts"]
        })

    # è½¬æ¢setä¸ºlist
    domains = []
    for domain in domains_dict.values():
        domains.append({
            "_id": domain["_id"],
            "name": domain["name"],
            "blocks": list(domain["blocks"])
        })
    
    blocks = []
    for block in blocks_dict.values():
        blocks.append({
            "_id": block["_id"],
            "domain_id": block["domain_id"],
            "title": block["title"],
            "subtopics": list(block["subtopics"])
        })
    
    micros = list(micros_dict.values())

    out_file = "output_fixed.json"
    try:
        with open(out_file, "w", encoding="utf-8") as f:
            json.dump({
                "domains": domains,
                "blocks": blocks,
                "micro_concepts": micros,
                "questions": questions_out
            }, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²å®Œæˆ {out_file}")
        print(f"ğŸ“Š ç»Ÿè®¡: {len(domains)} é¢†åŸŸ, {len(blocks)} åŒºå—, {len(micros)} çŸ¥è¯†ç‚¹, {len(questions_out)} é—®é¢˜")
    except Exception as e:
        print(f"âŒ å†™å…¥é”™è¯¯: {e}")

if __name__ == "__main__":
    main()