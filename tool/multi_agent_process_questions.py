import os
import base64
import json
import requests
import google.generativeai as genai



# ========== Gemini API Key ==========
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyBad7mpaX-fPPtpjbcgZ1JpKOBPJZJkmf4")

# ========== æç¤ºè©å®šç¾© ==========
main_agent_prompt_template = """
ä½ æ˜¯ã€Œè¨ˆç®—æ©Ÿæ¦‚è«–åˆ¤é¡Œç³»çµ±ã€ä¸­çš„ä¸»ä»£ç†äºº Gemini 2.0ã€‚

è«‹æ ¹æ“šé¡Œç›®å…§å®¹ï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
1. åˆ¤æ–·æ­£ç¢ºç­”æ¡ˆç‚ºä½•ï¼Œä¸¦èªªæ˜ç†ç”±ã€‚
2. è«‹èªªæ˜æœ¬é¡Œå±¬æ–¼ä»¥ä¸‹å“ªä¸€ç¨®å›ºå®šé¡Œå‹ï¼Œä¸¦æŒ‡å‡ºæ˜¯å¦å­˜åœ¨é¡Œæ„éŒ¯èª¤æˆ–æ•˜è¿°æ¨¡ç³Šæƒ…å½¢ã€‚å¯ç”¨çš„é¡Œå‹å¦‚ä¸‹ï¼š
   - "single-choice"ï¼šå–®é¸é¡Œ  
   - "multiple-choice"ï¼šå¤šé¸é¡Œ  
   - "fill-in-the-blank"ï¼šå¡«ç©ºé¡Œ  
   - "true-false"ï¼šæ˜¯éé¡Œ  
   - "short-answer"ï¼šç°¡ç­”é¡Œï¼å•ç­”é¡Œ  
   - "long-answer"ï¼šç”³è«–é¡Œï¼é•·ç­”é¡Œ  
   - "choice-answer"ï¼šé¸å¡«é¡Œ  
   - "draw-answer"ï¼šç•«åœ–é¡Œ  
   - "coding-answer"ï¼šç¨‹å¼æ’°å¯«é¡Œ
3. åˆ¤æ–·é¡Œç›®æ•˜è¿°æ˜¯å¦æœ‰èª¤ï¼ˆè‹¥æœ‰éŒ¯èª¤è«‹æŒ‡å‡ºä¸¦èªªæ˜ï¼‰ã€‚
4. å¾ä»¥ä¸‹ 12 å€‹çŸ¥è­˜é»ä¸­ï¼Œé¸å‡ºæœ¬é¡Œæœ€ç›¸é—œçš„ä¸€é …ï¼š
   - åŸºæœ¬è¨ˆæ¦‚ã€æ•¸ä½é‚è¼¯ã€ä½œæ¥­ç³»çµ±ã€ç¨‹å¼èªè¨€ã€è³‡æ–™çµæ§‹ã€ç¶²è·¯ã€è³‡æ–™åº«ã€AIèˆ‡æ©Ÿå™¨å­¸ç¿’ã€è³‡è¨Šå®‰å…¨ã€é›²ç«¯èˆ‡è™›æ“¬åŒ–ã€MISã€è»Ÿé«”å·¥ç¨‹èˆ‡ç³»çµ±é–‹ç™¼
5. è©•ä¼°é›£æ˜“åº¦ï¼ˆç°¡å–®ã€ä¸­ç­‰ã€å›°é›£ï¼‰ã€‚
6. è©³ç´°èªªæ˜è§£æèˆ‡æ€è·¯ã€‚

ã€é‡è¦è¦æ±‚ã€‘
- è«‹ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰åˆ†æå…§å®¹
- ä¸è¦ä¿®æ”¹åŸå§‹é¡Œç›®å…§å®¹
- ä¿æŒé¡Œç›®çš„åŸå§‹èªè¨€ï¼ˆè‹±æ–‡é¡Œç›®ä¿æŒè‹±æ–‡ï¼Œä¸­æ–‡é¡Œç›®ä¿æŒä¸­æ–‡ï¼‰

ã€é¡Œç›®å…§å®¹ã€‘
{question_text}
"""

secondary_agent_prompt_template = """
ä½ æ˜¯ã€Œè¨ˆç®—æ©Ÿæ¦‚è«–åˆ¤é¡Œç³»çµ±ã€ä¸­çš„æ¬¡è¦ä»£ç†äºº Gemini 2.0ã€‚

è«‹é–±è®€ä»¥ä¸‹ä¸»ä»£ç†äºº Gemini 2.0 çš„åˆ†æçµæœï¼Œä¸¦ä¾ä¸‹åˆ—è¦å‰‡åšå‡ºå›æ‡‰ï¼š

ã€ä¸»ä»£ç†äººåˆ†æã€‘
{main_response}

ã€ä»»å‹™ã€‘
è«‹åˆ¤æ–·ä½ æ˜¯å¦åŒæ„ä¸»ä»£ç†äººçš„åˆ¤æ–·èˆ‡çµè«–ï¼Œå›è¦†æ ¼å¼å¦‚ä¸‹ï¼š

1. ä½ æ˜¯å¦åŒæ„ä¸»ä»£ç†äººçš„ã€Œæ­£ç¢ºç­”æ¡ˆã€åˆ¤æ–·ï¼Ÿï¼ˆåŒæ„ / ä¸åŒæ„ï¼‰è‹¥ä¸åŒæ„ï¼Œè«‹èªªæ˜ä½ èªç‚ºæ­£ç¢ºçš„é¸é …èˆ‡ç†ç”±ã€‚
2. ä½ æ˜¯å¦åŒæ„å…¶ã€Œé¡Œå‹åˆ¤å®šã€èˆ‡ã€Œé¡Œæ„æ˜¯å¦éŒ¯èª¤ã€çš„åˆ†æï¼Ÿ
3. ä½ æ˜¯å¦åŒæ„å…¶é¸å®šçš„ã€ŒçŸ¥è­˜åˆ†é¡ã€èˆ‡ã€Œé›£æ˜“åº¦ã€ï¼Ÿ
4. æœ‰ç„¡å…¶ä»–è£œå……æˆ–ç•°è­°ï¼Ÿ
"""

arbiter_agent_prompt_template = """
ä½ æ˜¯ã€Œè¨ˆç®—æ©Ÿæ¦‚è«–åˆ¤é¡Œç³»çµ±ã€ä¸­çš„ä»²è£ä»£ç†äººã€‚

è«‹æ ¹æ“šä»¥ä¸‹å…©ä½ä»£ç†äººçš„åˆ†æï¼Œè¼¸å‡ºä¸€å€‹JSONæ ¼å¼çš„é¡Œç›®çµæœã€‚

ã€ä¸»ä»£ç†äººåˆ†æã€‘
{main_response}

ã€æ¬¡ä»£ç†äººå›æ‡‰ã€‘
{secondary_response}

ã€ä»»å‹™ã€‘
è«‹æ•´åˆä¸Šè¿°åˆ†æï¼Œè¼¸å‡ºä¸€å€‹åŒ…å«å®Œæ•´é¡Œç›®è³‡è¨Šçš„JSONé™£åˆ—ã€‚

ã€é‡è¦è¦æ±‚ã€‘
1. ä¿æŒåŸå§‹é¡Œç›®å…§å®¹ä¸è®Šï¼ˆè‹±æ–‡é¡Œç›®ä¿æŒè‹±æ–‡ï¼Œä¸­æ–‡é¡Œç›®ä¿æŒä¸­æ–‡ï¼‰
2. ä¿æŒæ‰€æœ‰åŸå§‹æ¬„ä½ä¸è®Šï¼ˆschoolã€departmentã€yearã€question_numberç­‰ï¼‰
3. åªæœ‰ä»¥ä¸‹æ¬„ä½ä½¿ç”¨ä¸­æ–‡ï¼š
   - detail-answerï¼šå°æ–¼ç­”æ¡ˆçš„è©³ç´°è©³ç´°èªªæ˜è§£é‡‹ï¼ˆä¸­æ–‡ï¼‰
   - key-pointsï¼šçŸ¥è­˜é»åˆ†é¡ï¼ˆä¸­æ–‡ï¼‰
   - difficulty levelï¼šé›£åº¦ç­‰ç´šï¼ˆä¸­æ–‡ï¼‰
   - error reasonï¼šéŒ¯èª¤åŸå› ï¼ˆä¸­æ–‡ï¼‰
4. answeræ¬„ä½å¿…é ˆæ˜¯æ˜ç¢ºã€ç°¡çŸ­ã€ç›´æ¥çš„æ­£ç¢ºç­”æ¡ˆï¼Œ**ä¸èƒ½å‡ºç¾ã€Œè«‹åƒè€ƒè©³ç´°è§£ç­”ã€ã€ã€Œè¦‹ä¸Šã€ç­‰ç„¡æ„ç¾©å…§å®¹**ï¼Œè¦ç›´æ¥çµ¦å‡ºç­”æ¡ˆæœ¬èº«ã€‚
   - ç°¡ç­”é¡Œã€å•ç­”é¡Œï¼šç”¨ä¸­æ–‡ç›´æ¥çµ¦å‡ºæ­£ç¢ºç­”æ¡ˆ
   - é¸æ“‡é¡Œï¼šç›´æ¥çµ¦å‡ºæ­£ç¢ºé¸é …ï¼ˆå¦‚Aã€Bã€Trueã€Falseç­‰ï¼Œæˆ–é¸é …å…§å®¹ï¼‰
5. detail-answer æ˜¯å° answer çš„è©³ç´°èªªæ˜ã€æ¨å°ã€ç†ç”±ï¼Œä¸¦èªªæ˜ç‚ºä»€éº¼çŸ¥è­˜é»å¼è‘—å€‹è·Ÿç‚ºç”šéº¼é›£æ˜“åº¦æ˜¯é€™æ¨£ï¼ˆä¸­æ–‡ï¼‰
6. difficulty level åˆ¤æ–·åŸå‰‡ï¼š
   - è‹¥é¡Œç›®ç‚ºå®šç¾©ã€äº‹å¯¦ã€åŸºç¤çŸ¥è­˜ï¼Œè«‹å¡«ã€Œç°¡å–®ã€
   - è‹¥éœ€æ¨ç†ã€è¨ˆç®—ã€ç¶œåˆï¼Œè«‹å¡«ã€Œä¸­ç­‰ã€æˆ–ã€Œå›°é›£ã€
7. ä¸è¦ä¿®æ”¹æˆ–è¦†è“‹åŸå§‹æ¬„ä½

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹ç›´æ¥è¼¸å‡ºä»¥ä¸‹æ ¼å¼çš„JSONé™£åˆ—ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

[{{  
  "answer": "ç­”æ¡ˆï¼ˆæ˜ç¢ºç°¡çŸ­ç›´æ¥ï¼Œä¸èƒ½æ˜¯è«‹åƒè€ƒè©³ç´°è§£ç­”ï¼‰",
  "detail-answer": "è©³ç´°è§£ç­”ï¼ˆä¸­æ–‡ï¼‰",
  "key-points": "åŸºæœ¬è¨ˆæ¦‚",
  "difficulty level": "ç°¡å–®",
  "error reason": ""
}}]

æ³¨æ„ï¼š
1. åªè¼¸å‡ºæ–°å¢çš„æ¬„ä½ï¼Œä¸è¦åŒ…å«åŸå§‹æ¬„ä½
2. key-points å¿…é ˆå¾ä»¥ä¸‹é¸é …é¸æ“‡ï¼šåŸºæœ¬è¨ˆæ¦‚ã€æ•¸ä½é‚è¼¯ã€ä½œæ¥­ç³»çµ±ã€ç¨‹å¼èªè¨€ã€è³‡æ–™çµæ§‹ã€ç¶²è·¯ã€è³‡æ–™åº«ã€AIèˆ‡æ©Ÿå™¨å­¸ç¿’ã€è³‡è¨Šå®‰å…¨ã€é›²ç«¯èˆ‡è™›æ“¬åŒ–ã€MISã€è»Ÿé«”å·¥ç¨‹èˆ‡ç³»çµ±é–‹ç™¼
3. difficulty level åªèƒ½å¡«å…¥ï¼šç°¡å–®ã€ä¸­ç­‰ã€å›°é›£
4. ç›´æ¥è¼¸å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹æ–‡å­—
5. å¿…é ˆåŒ…å« key-points æ¬„ä½
6. ä¸è¦ä¿®æ”¹åŸå§‹é¡Œç›®å…§å®¹
"""




# ========== æ¨¡å‹åˆå§‹åŒ– ==========
# è¨­å®šé‡‘é‘°
genai.configure(api_key=GEMINI_API_KEY)

def read_image_base64(image_path):
    if not os.path.exists(image_path):
        return None
    with open(image_path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("utf-8")
        return encoded

def call_gemini_model(prompt, image_base64=None):
    model = genai.GenerativeModel("gemini-2.0-flash")

    if image_base64:
        import base64
        import io
        from PIL import Image

        image_data = base64.b64decode(image_base64)
        image = Image.open(io.BytesIO(image_data))

        response = model.generate_content([
            prompt,
            image  # æ³¨æ„é€™è£¡æ˜¯ç›´æ¥å‚³åœ–ç‰‡ç‰©ä»¶
        ])
    else:
        response = model.generate_content(prompt)

    return response.text.strip()

def call_llama_model(prompt):
    """èª¿ç”¨æ¬¡ä»£ç†äººæ¨¡å‹ï¼ˆæ”¹ç‚ºä½¿ç”¨ Geminiï¼‰"""
    try:
        # ä½¿ç”¨ Gemini ä½œç‚ºæ¬¡ä»£ç†äººï¼Œè€Œä¸æ˜¯æœ¬åœ° Ollama
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"âš ï¸ æ¬¡ä»£ç†äººèª¿ç”¨å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆï¼š{e}")
       

# ========== è™•ç† single ==========
def process_question(question):
    import copy
    question_text = question["question_text"]
    image_path = question.get("image_file")
    image_base64 = None

    if isinstance(image_path, list):
        image_file = image_path[0] if image_path else None
    else:
        image_file = image_path

    if image_file:
        image_base64 = read_image_base64(os.path.join("backend", "src", "picture", image_file))

    print(f"ğŸ”„ è™•ç†é¡Œç›®ï¼š{question_text[:50]}...")

    main_prompt = main_agent_prompt_template.format(question_text=question_text)
    main_response = call_gemini_model(main_prompt, image_base64=image_base64)
    print("âœ… ä¸»ä»£ç†äººåˆ†æå®Œæˆ")

    secondary_prompt = secondary_agent_prompt_template.format(main_response=main_response)
    secondary_response = call_llama_model(secondary_prompt)
    print("âœ… æ¬¡ä»£ç†äººåˆ†æå®Œæˆ")

    arbiter_prompt = arbiter_agent_prompt_template.format(
        main_response=main_response,
        secondary_response=secondary_response
    )
    arbiter_response = call_gemini_model(arbiter_prompt)
    print("âœ… ä»²è£ä»£ç†äººåˆ†æå®Œæˆ")

    try:
        # å˜—è©¦æ¸…ç†å›æ‡‰ï¼Œç§»é™¤å¯èƒ½çš„éJSONå…§å®¹
        arbiter_response = arbiter_response.strip()
        if arbiter_response.startswith('```json'):
            arbiter_response = arbiter_response[7:]
        if arbiter_response.endswith('```'):
            arbiter_response = arbiter_response[:-3]
        arbiter_response = arbiter_response.strip()
        
        print(f"ğŸ” ä»²è£å›æ‡‰ï¼š{arbiter_response[:100]}...")
        
        result = json.loads(arbiter_response)
        if isinstance(result, list) and result:
            # ç¢ºä¿çµæœåŒ…å«æ‰€æœ‰åŸå§‹æ¬„ä½
            processed_question = copy.deepcopy(question)
            processed_question.update(result[0])
            print("âœ… JSONè§£ææˆåŠŸ")
            return processed_question
        else:
            raise ValueError("ä»²è£è¼¸å‡ºæ ¼å¼ä¸æ­£ç¢º")
    except Exception as e:
        print(f"âš ï¸ JSONè§£æå¤±æ•—ï¼š{e}")
        # è‹¥è§£æå¤±æ•—ï¼Œå›å‚³åŸå§‹é¡Œç›®ä½†è£œé½Šæ–°æ¬„ä½
        fallback = copy.deepcopy(question)
        # ç¢ºä¿æ‰€æœ‰æ–°å¢æ¬„ä½éƒ½æœ‰é è¨­å€¼
        fallback.setdefault("answer", "")
        fallback.setdefault("detail-answer", "")
        fallback.setdefault("key-points", "")
        fallback.setdefault("difficulty level", "")
        fallback.setdefault("error reason", f"ä»²è£è§£æéŒ¯èª¤: {e}")
        print("âœ… ä½¿ç”¨fallbackæ©Ÿåˆ¶")
        return fallback
    
# ========== è™•ç† group ==========
def process_group_question(group):
    import copy
    group_copy = copy.deepcopy(group)
    processed_sub_questions = []

    print(f"ğŸ”„ è™•ç†ç¾¤çµ„é¡Œç›®ï¼š{group_copy.get('group_question_text', '')}")

    for i, sub_question in enumerate(group_copy["sub_questions"]):
        question_text = sub_question["question_text"]
        image_path = sub_question.get("image_file")
        image_base64 = None

        if isinstance(image_path, list):
            image_file = image_path[0] if image_path else None
        else:
            image_file = image_path

        if image_file:
            image_base64 = read_image_base64(os.path.join("backend", "src", "picture", image_file))

        print(f"ğŸ”„ è™•ç†å­é¡Œç›® {i+1}ï¼š{question_text[:50]}...")

        main_prompt = main_agent_prompt_template.format(question_text=question_text)
        main_response = call_gemini_model(main_prompt, image_base64=image_base64)
        print(f"âœ… å­é¡Œç›® {i+1} ä¸»ä»£ç†äººåˆ†æå®Œæˆ")

        secondary_prompt = secondary_agent_prompt_template.format(main_response=main_response)
        secondary_response = call_llama_model(secondary_prompt)
        print(f"âœ… å­é¡Œç›® {i+1} æ¬¡ä»£ç†äººåˆ†æå®Œæˆ")

        arbiter_prompt = arbiter_agent_prompt_template.format(
            main_response=main_response,
            secondary_response=secondary_response
        )
        arbiter_response = call_gemini_model(arbiter_prompt)
        print(f"âœ… å­é¡Œç›® {i+1} ä»²è£ä»£ç†äººåˆ†æå®Œæˆ")

        try:
            # å˜—è©¦æ¸…ç†å›æ‡‰ï¼Œç§»é™¤å¯èƒ½çš„éJSONå…§å®¹
            arbiter_response = arbiter_response.strip()
            if arbiter_response.startswith('```json'):
                arbiter_response = arbiter_response[7:]
            if arbiter_response.endswith('```'):
                arbiter_response = arbiter_response[:-3]
            arbiter_response = arbiter_response.strip()
            
            print(f"ğŸ” å­é¡Œç›® {i+1} ä»²è£å›æ‡‰ï¼š{arbiter_response[:100]}...")
            
            result = json.loads(arbiter_response)
            if isinstance(result, list) and result:
                # ç¢ºä¿çµæœåŒ…å«æ‰€æœ‰åŸå§‹æ¬„ä½
                processed_sub_question = copy.deepcopy(sub_question)
                processed_sub_question.update(result[0])
                print(f"âœ… å­é¡Œç›® {i+1} JSONè§£ææˆåŠŸ")
                processed_sub_questions.append(processed_sub_question)
            else:
                raise ValueError("ä»²è£è¼¸å‡ºæ ¼å¼éŒ¯èª¤")
        except Exception as e:
            print(f"âš ï¸ å­é¡Œç›® {i+1} JSONè§£æå¤±æ•—ï¼š{e}")
            fallback = copy.deepcopy(sub_question)
            # ç¢ºä¿æ‰€æœ‰æ–°å¢æ¬„ä½éƒ½æœ‰é è¨­å€¼
            fallback.setdefault("answer", "")
            fallback.setdefault("detail-answer", "")
            fallback.setdefault("key-points", "")
            fallback.setdefault("difficulty level", "")
            fallback.setdefault("error reason", f"ä»²è£è§£æéŒ¯èª¤: {e}")
            print(f"âœ… å­é¡Œç›® {i+1} ä½¿ç”¨fallbackæ©Ÿåˆ¶")
            processed_sub_questions.append(fallback)

    group_copy["sub_questions"] = processed_sub_questions
    return group_copy

# ========== åˆä½µ ==========
def process_all_questions(questions):
    results = []
    count = 0
    total_questions = len(questions)

    for i, q in enumerate(questions, 1):
        try:
            if q["type"] == "group":
                print(f"ğŸ”„ è™•ç†ç¾¤çµ„é¡Œç›® ({i}/{total_questions})ï¼š{q.get('group_question_text', '')}ï¼Œå…± {len(q['sub_questions'])} é¡Œ")
                group_result = process_group_question(q)
                results.append(group_result)
                count += len(q['sub_questions'])
                print(f"âœ… ç¾¤çµ„é¡Œç›®è™•ç†å®Œæˆï¼Œå·²è™•ç† {count} é¡Œ")
            else:
                count += 1
                print(f"ğŸ”„ è™•ç†ç¬¬ {count} é¡Œ ({i}/{total_questions})...")
                result = process_question(q)
                results.append(result)
                print(f"âœ… ç¬¬ {count} é¡Œè™•ç†å®Œæˆ")
        except Exception as e:
            print(f"âŒ è™•ç†ç¬¬ {i} é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            # ç¢ºä¿å³ä½¿å‡ºéŒ¯ä¹Ÿèƒ½ç¹¼çºŒè™•ç†å…¶ä»–é¡Œç›®
            if q["type"] == "group":
                results.append(q)  # ä¿ç•™åŸå§‹ç¾¤çµ„é¡Œç›®
            else:
                results.append(q)  # ä¿ç•™åŸå§‹é¡Œç›®

    return results




if __name__ == "__main__":
    with open("../data/grouped_exam_processed.json", "r", encoding="utf-8") as f:
        questions = json.load(f)

    results = process_all_questions(questions)
    with open("../data/results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print("\nâœ… æ‰€æœ‰é¡Œç›®è™•ç†å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³ results.json")
    print(f"ğŸ” å…±è™•ç† {len(results)} é¡Œç›®ã€‚")