from werkzeug.security import generate_password_hash
from flask_mail import Message
from flask import jsonify, request, redirect, url_for, Blueprint, current_app
import uuid
from accessories import mail, redis_client, mongo, save_json_to_mongo
from src.api import get_user_info, verify_token
from bson.objectid import ObjectId
import jwt
from datetime import datetime
import os
import base64
import google.generativeai as genai
import threading
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import random
import re

dashboard_bp = Blueprint('dashboard', __name__)

# é…ç½®å¤šå€‹ Gemini API Keys
API_KEYS = [
    "AIzaSyBfWLmPH5Z926UYLqotbwgQVmNondhUnsc",
    "AIzaSyBiJ7OJy-4ClQHW2ARGZ6200sQEe7HWoZ4",
    "AIzaSyBCFEh9O0WiGvlE5IXDEnx0tN_4Y_uxx3s",
    "AIzaSyB9RGnWIR_S73P2yv1OHA3ysygTNWXYBt4",
    "AIzaSyDLUJfWhn4OBs3M00qrfGqnYwHTQJZ3yt4",
    "AIzaSyA1SmwUEyBgMZrNByzIRW_8BI6sKYHA758",
    "AIzaSyCHbkAjiy2O6syJDU5g1GqmMjjS9rjwRAs",
    "AIzaSyAwJ_e-baluaPPe4NHU-GWR0vf6FXD-BG8"
]

def create_gemini_model(api_key):
    """ç‚ºæŒ‡å®šçš„API keyå‰µå»ºGeminiæ¨¡å‹"""
    try:    
        genai.configure(api_key=api_key)
        # ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹åç¨±
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # æ¸¬è©¦APIæ˜¯å¦å·¥ä½œ
        try:
            test_response = model.generate_content(
                "æ¸¬è©¦",
                generation_config={
                    'temperature': 0.1,
                    'max_output_tokens': 10,
                    'candidate_count': 1
                }
            )
            if test_response and hasattr(test_response, 'text'):
                print(f"âœ… API Key æ¸¬è©¦æˆåŠŸ: {api_key[:8]}...")
                return model
            else:
                print(f"âŒ API Key æ¸¬è©¦å¤±æ•— (ç„¡å›æ‡‰): {api_key[:8]}...")
                return None
        except Exception as test_error:
            print(f"âŒ API Key æ¸¬è©¦å¤±æ•—: {api_key[:8]}... - {str(test_error)}")
            return None
            
    except Exception as e:
        print(f"âŒ API Key åˆå§‹åŒ–å¤±æ•—: {api_key[:8]}... - {e}")
        return None

def init_gemini():
    """åˆå§‹åŒ–ä¸»è¦çš„Gemini APIï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    try:
        api_key = API_KEYS[0]  # ä½¿ç”¨ç¬¬ä¸€å€‹API key
        genai.configure(api_key=api_key)
        # ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹åç¨±
        model = genai.GenerativeModel('gemini-1.5-flash')
        print("âœ… Gemini API åˆå§‹åŒ–æˆåŠŸ")
        return model
    except Exception as e:
        print(f"âŒ Gemini API åˆå§‹åŒ–å¤±æ•—: {e}")
        return None

def grade_answer_with_gemini(model, user_answer, correct_answer, question_text, question_type):
    """ä½¿ç”¨Gemini AIä¾†è©•åˆ†ç­”æ¡ˆ"""
    try:
        # æ³¨æ„ï¼šç©ºç­”æ¡ˆå·²ç¶“åœ¨submit_answersä¸­è¢«éæ¿¾æ‰ï¼Œé€™è£¡ä¸æœƒæ”¶åˆ°ç©ºç­”æ¡ˆ
        
        # è™•ç†"ä¸æœƒ"ã€"ä¸çŸ¥é“"ç­‰ç„¡æ•ˆå›ç­”
        invalid_answers = ['ä¸æœƒ', 'ä¸çŸ¥é“', 'ä¸æ¸…æ¥š', 'ä¸æ‡‚', 'æ²’æœ‰', 'ç„¡', 'ï¼Ÿ', '?', 'idk', "i don't know", 'no idea']
        if user_answer.strip().lower() in [ans.lower() for ans in invalid_answers]:
            return {
                'score': 0,
                'is_correct': False,
                'feedback': 'å­¸ç”Ÿè¡¨ç¤ºä¸æœƒæˆ–ä¸çŸ¥é“ï¼Œçµ¦äºˆ0åˆ†',
                'grading_type': 'invalid_answer',
                'accuracy_percentage': 0,
                'key_elements_coverage': 0,
                'key_elements_in_standard': [],
                'key_elements_covered': [],
                'missing_key_elements': [],
                'accuracy_issues': ['å­¸ç”Ÿè¡¨ç¤ºä¸æœƒæˆ–ä¸çŸ¥é“']
            }
            
        if question_type == "single-choice" or question_type == "multiple-choice":
            # é¸æ“‡é¡Œæ¯”è¼ƒé‚è¼¯æ”¹é€²
            def extract_option_letter(answer_text):
                """å¾ç­”æ¡ˆä¸­æå–é¸é …å­—æ¯ (a, b, c, dç­‰)"""
                if not answer_text:
                    return ""
                answer_text = answer_text.strip().lower()
                
                # å¦‚æœç­”æ¡ˆåªæ˜¯å–®å€‹å­—æ¯
                if len(answer_text) == 1 and answer_text in 'abcdefghijklmnopqrstuvwxyz':
                    return answer_text
                
                # å¦‚æœç­”æ¡ˆæ˜¯ "a.", "b)", "(c)", "d. å…§å®¹" ç­‰æ ¼å¼
                match = re.match(r'^[(\[]?([a-z])[.\])]?', answer_text)
                if match:
                    return match.group(1)
                
                # å¦‚æœæ‰¾ä¸åˆ°å­—æ¯ï¼Œè¿”å›åŸå§‹ç­”æ¡ˆï¼ˆå»é™¤ç©ºç™½ä¸¦è½‰å°å¯«ï¼‰
                return answer_text
            
            user_option = extract_option_letter(user_answer)
            correct_option = extract_option_letter(correct_answer)
            
            is_correct = user_option == correct_option
            score = 100 if is_correct else 0
            feedback = "æ­£ç¢ºç­”æ¡ˆ" if is_correct else f"éŒ¯èª¤ã€‚æ­£ç¢ºç­”æ¡ˆæ˜¯ï¼š{correct_answer}"
            
            return {
                'score': score,
                'is_correct': is_correct,
                'feedback': feedback,
                'grading_type': 'automatic'
            }
        
        elif question_type == "true-false":
            # æ˜¯éé¡Œè™•ç†
            user_ans = user_answer.strip().lower()
            correct_ans = correct_answer.strip().lower()
            
            # è™•ç†ä¸­æ–‡ç­”æ¡ˆ
            if user_ans in ['æ˜¯', 'true', 't', 'å°', 'æ­£ç¢º'] and correct_ans in ['æ˜¯', 'true', 't', 'å°', 'æ­£ç¢º']:
                is_correct = True
            elif user_ans in ['å¦', 'false', 'f', 'éŒ¯', 'éŒ¯èª¤'] and correct_ans in ['å¦', 'false', 'f', 'éŒ¯', 'éŒ¯èª¤']:
                is_correct = True
            else:
                is_correct = False
                
            score = 100 if is_correct else 0
            feedback = "æ­£ç¢ºç­”æ¡ˆ" if is_correct else f"éŒ¯èª¤ã€‚æ­£ç¢ºç­”æ¡ˆæ˜¯ï¼š{correct_answer}"
            
            return {
                'score': score,
                'is_correct': is_correct,
                'feedback': feedback,
                'grading_type': 'automatic'
            }
            
        else:
            # å•ç­”é¡Œä½¿ç”¨Geminiè©•åˆ†
            prompt = f"""
ä½ æ˜¯ä¸€ä½åš´æ ¼çš„å°ˆæ¥­è€ƒè©¦è©•åˆ†è€å¸«ã€‚è«‹å®¢è§€ç†æ€§åœ°è©•åƒ¹å­¸ç”Ÿç­”æ¡ˆï¼Œçµ•å°ä¸èƒ½æœ‰ä»»ä½•åŒæƒ…å¿ƒæˆ–å¯¬å®¹æ…‹åº¦ã€‚

é¡Œç›®ï¼š{question_text}

æ¨™æº–ç­”æ¡ˆï¼š{correct_answer}

å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}

## é‡è¦åŸå‰‡ï¼š
1. **éƒ¨åˆ†åš´æ ¼**ï¼šéŒ¯èª¤å°±æ˜¯éŒ¯èª¤ï¼Œä¸å®Œæ•´å°±æ˜¯ä¸å®Œæ•´ï¼Œçµ•ä¸å¯¬å®¹ï¼Œå¦‚æœèªªå°å¯ä»¥çµ¦äºˆéƒ¨åˆ†åˆ†æ•¸
2. **å®¢è§€è©•åˆ†**ï¼šåªçœ‹ç­”æ¡ˆæœ¬èº«çš„æ­£ç¢ºæ€§ï¼Œä¸è€ƒæ…®ä»»ä½•ä¸»è§€å› ç´ 
3. **é›¶åˆ†æ¢ä»¶**ï¼š
   - å®Œå…¨ç­”éŒ¯ â†’ 0åˆ†
   - ç­”éæ‰€å• â†’ 0åˆ†
   - æ¦‚å¿µéŒ¯èª¤ â†’ åš´é‡æ‰£åˆ†
   - é—œéµè¦ç´ ç¼ºå¤± â†’ æŒ‰æ¯”ä¾‹æ‰£åˆ†
4.æœ‰è¬›åˆ°é—œéµè©å¯ä»¥çµ¦äºˆéƒ¨åˆ†åˆ†æ•¸

## è©•åˆ†æ¨™æº–ï¼š
1. **æ­£ç¢ºç‡ç™¾åˆ†æ¯”** (0-100%)ï¼š
   - 100%ï¼šå…§å®¹å®Œå…¨æ­£ç¢ºï¼Œç„¡ä»»ä½•éŒ¯èª¤
   - 80-99%ï¼šä¸»è¦å…§å®¹æ­£ç¢ºï¼Œæœ‰æ¥µå°‘æ•¸å°éŒ¯èª¤
   - 60-79%ï¼šå¤§éƒ¨åˆ†æ­£ç¢ºï¼Œä½†æœ‰æ˜é¡¯éŒ¯èª¤
   - 40-59%ï¼šéƒ¨åˆ†æ­£ç¢ºï¼Œä½†éŒ¯èª¤è¼ƒå¤š
   - 20-39%ï¼šå°‘éƒ¨åˆ†æ­£ç¢ºï¼ŒéŒ¯èª¤å¾ˆå¤š
   - 0-19%ï¼šå¹¾ä¹å…¨éŒ¯æˆ–å®Œå…¨éŒ¯èª¤

2. **é—œéµè¦ç´ è¦†è“‹åº¦** (0-100%)ï¼š
   - åˆ†ææ¨™æº–ç­”æ¡ˆåŒ…å«çš„æ‰€æœ‰é—œéµè¦ç´ 
   - åš´æ ¼æª¢æŸ¥å­¸ç”Ÿç­”æ¡ˆæ¶µè“‹äº†å¤šå°‘è¦ç´ 
   - æ¯éºæ¼ä¸€å€‹è¦ç´ éƒ½è¦æŒ‰æ¯”ä¾‹æ‰£åˆ†
   - éƒ¨åˆ†æ­£ç¢ºçš„è¦ç´ åªèƒ½å¾—åˆ°éƒ¨åˆ†åˆ†æ•¸

**æœ€çµ‚åˆ†æ•¸è¨ˆç®—ï¼š**
æœ€çµ‚åˆ†æ•¸ = (æ­£ç¢ºç‡ Ã— 0.6) + (é—œéµè¦ç´ è¦†è“‹åº¦ Ã— 0.4)

## æ³¨æ„ï¼šè©•åˆ†å¿…é ˆåš´æ ¼å®¢è§€ï¼Œå¯§å¯åš´æ ¼ä¹Ÿä¸è¦å¯¬é¬†ï¼

è«‹ä»¥JSONæ ¼å¼å›å¾©ï¼š
{{
    "accuracy_percentage": æ­£ç¢ºç‡ç™¾åˆ†æ¯”(0-100),
    "key_elements_coverage": é—œéµè¦ç´ è¦†è“‹åº¦(0-100),
    "score": æœ€çµ‚åˆ†æ•¸(0-100),
    "is_correct": true/false (åˆ†æ•¸>=70ç‚ºtrue),
    "feedback": "è©³ç´°çš„åš´æ ¼è©•åˆ†èªªæ˜",
    "key_elements_in_standard": ["æ¨™æº–ç­”æ¡ˆçš„é—œéµè¦ç´ "],
    "key_elements_covered": ["å­¸ç”Ÿç­”æ¡ˆæ¶µè“‹çš„é—œéµè¦ç´ "],
    "missing_key_elements": ["å­¸ç”Ÿç­”æ¡ˆéºæ¼çš„é—œéµè¦ç´ "],
    "accuracy_issues": ["å…§å®¹æ­£ç¢ºæ€§çš„å•é¡Œé»"]
}}

ç¢ºä¿å›å¾©æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
            
            # ä½¿ç”¨è¶…æ™‚å’Œé‡è©¦æ©Ÿåˆ¶
            max_retries = 3
            response = None
            
            for attempt in range(max_retries):
                try:
                    print(f"å˜—è©¦APIèª¿ç”¨ (ç¬¬{attempt + 1}æ¬¡)")
                    
                    # å‰µå»ºç”Ÿæˆé…ç½®
                    generation_config = {
                        'temperature': 0.1,  # é™ä½temperatureä½¿çµæœæ›´ç©©å®š
                        'max_output_tokens': 1500,  # å¢åŠ è¼¸å‡ºé•·åº¦
                        'candidate_count': 1
                    }
                    
                    # å‰µå»ºä¸€å€‹äº‹ä»¶ä¾†æ§åˆ¶è¶…æ™‚
                    import threading
                    import time
                    
                    result_container = {'response': None, 'error': None, 'completed': False}
                    
                    def api_call():
                        try:
                            result_container['response'] = model.generate_content(
                                prompt,
                                generation_config=generation_config
                            )
                            result_container['completed'] = True
                        except Exception as e:
                            result_container['error'] = e
                            result_container['completed'] = True
                    
                    # åœ¨æ–°ç·šç¨‹ä¸­åŸ·è¡ŒAPIèª¿ç”¨
                    api_thread = threading.Thread(target=api_call)
                    api_thread.daemon = True
                    api_thread.start()
                    
                    # ç­‰å¾…æœ€å¤š45ç§’
                    api_thread.join(timeout=45)
                    
                    if not result_container['completed']:
                        # è¶…æ™‚äº†
                        raise TimeoutError("APIèª¿ç”¨è¶…æ™‚")
                    elif result_container['error']:
                        # æœ‰éŒ¯èª¤
                        raise result_container['error']
                    else:
                        # æˆåŠŸ
                        response = result_container['response']
                    
                    if response and hasattr(response, 'text') and response.text:
                        print(f"APIèª¿ç”¨æˆåŠŸ")
                        break
                    else:
                        print(f"APIå›æ‡‰ç‚ºç©º (å˜—è©¦{attempt + 1})")
                        if attempt == max_retries - 1:
                            response = None
                            
                except TimeoutError:
                    print(f"APIèª¿ç”¨è¶…æ™‚ (å˜—è©¦{attempt + 1})")
                    if attempt == max_retries - 1:
                        response = None
                        break
                    time.sleep(2)  # ç­‰å¾…2ç§’å¾Œé‡è©¦
                     
                except Exception as api_error:
                    print(f"APIèª¿ç”¨éŒ¯èª¤ (å˜—è©¦{attempt + 1}): {str(api_error)}")
                    if attempt == max_retries - 1:
                        response = None
                        break
                    time.sleep(2)  # ç­‰å¾…2ç§’å¾Œé‡è©¦
            
            if response and hasattr(response, 'text') and response.text:
                try:
                    # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œç§»é™¤å¯èƒ½çš„markdownæ¨™è¨˜
                    clean_text = response.text.strip()
                    if clean_text.startswith('```json'):
                        clean_text = clean_text[7:]
                    if clean_text.endswith('```'):
                        clean_text = clean_text[:-3]
                    clean_text = clean_text.strip()
                    
                    import json
                    result = json.loads(clean_text)
                    
                    # ç¢ºä¿åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
                    processed_result = {
                        'score': result.get('score', 50),
                        'is_correct': result.get('is_correct', False),
                        'feedback': result.get('feedback', 'è©•åˆ†å®Œæˆ'),
                        'grading_type': 'ai_assisted',
                        'accuracy_percentage': result.get('accuracy_percentage', 50),
                        'key_elements_coverage': result.get('key_elements_coverage', 50),
                        'key_elements_in_standard': result.get('key_elements_in_standard', []),
                        'key_elements_covered': result.get('key_elements_covered', []),
                        'missing_key_elements': result.get('missing_key_elements', []),
                        'accuracy_issues': result.get('accuracy_issues', [])
                    }
                    
                    return processed_result
                except json.JSONDecodeError:
                    # å¦‚æœJSONè§£æå¤±æ•—ï¼Œä½¿ç”¨åŸºæœ¬è©•åˆ†
                    return {
                        'score': 50,
                        'is_correct': False,
                        'feedback': f"AIè©•åˆ†æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹äººå·¥æª¢æŸ¥ã€‚å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}",
                        'grading_type': 'fallback',
                        'accuracy_percentage': 50,
                        'key_elements_coverage': 50,
                        'key_elements_in_standard': [],
                        'key_elements_covered': [],
                        'missing_key_elements': [],
                        'accuracy_issues': ['JSONè§£æå¤±æ•—']
                    }
            else:
                return {
                    'score': 50,
                    'is_correct': False,
                    'feedback': "AIè©•åˆ†æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨",
                    'grading_type': 'fallback',
                    'accuracy_percentage': 50,
                    'key_elements_coverage': 50,
                    'key_elements_in_standard': [],
                    'key_elements_covered': [],
                    'missing_key_elements': [],
                    'accuracy_issues': ['AIæœå‹™ç„¡å›æ‡‰']
                }
                
    except Exception as e:
        print(f"Geminiè©•åˆ†éŒ¯èª¤: {e}")
        return {
            'score': 50,
            'is_correct': False,
            'feedback': f"è©•åˆ†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
            'grading_type': 'error',
            'accuracy_percentage': 50,
            'key_elements_coverage': 50,
            'key_elements_in_standard': [],
            'key_elements_covered': [],
            'missing_key_elements': [],
            'accuracy_issues': [f'ç³»çµ±éŒ¯èª¤: {str(e)}']
        }

def process_single_answer(args):
    """è™•ç†å–®å€‹ç­”æ¡ˆçš„åŒ…è£å‡½æ•¸ï¼Œç”¨æ–¼ä¸¦è¡Œè™•ç†"""
    answer, api_key_index, total_count = args
    api_key = API_KEYS[api_key_index % len(API_KEYS)]
    
    try:
        # ç‚ºé€™å€‹workerå‰µå»ºå°ˆç”¨çš„Geminiæ¨¡å‹
        model = create_gemini_model(api_key)
        if not model:
            return create_error_result(answer, "APIæ¨¡å‹åˆå§‹åŒ–å¤±æ•—")
        
        # é€éå…±åŒå­—æ®µæŸ¥æ‰¾æ­£ç¢ºç­”æ¡ˆ
        query = {
            'school': answer.get('school'),
            'year': answer.get('year'),
            'question_number': answer.get('question_number')
        }
        
        exam_question = mongo.db.exam.find_one(query)
        
        if not exam_question:
            return create_not_found_result(answer)
        
        # ä½¿ç”¨Geminiè©•åˆ†
        grading_result = grade_answer_with_gemini(
            model,
            answer.get('answer', ''),
            exam_question.get('answer', ''),
            exam_question.get('question_text', ''),
            exam_question.get('type', '')
        )
        
        # æ•´åˆç­”æ¡ˆå’Œè©•åˆ†çµæœ
        graded_answer = {
            **answer,
            'correct_answer': exam_question.get('answer', ''),
            'score': grading_result['score'],
            'is_correct': grading_result['is_correct'],
            'feedback': grading_result['feedback'],
            'grading_type': grading_result['grading_type'],
            'question_found': True
        }
        
        # å¦‚æœæ˜¯AIè¼”åŠ©è©•åˆ†ï¼Œæ·»åŠ è©³ç´°åˆ†æ
        if grading_result['grading_type'] == 'ai_assisted':
            graded_answer.update({
                'accuracy_percentage': grading_result.get('accuracy_percentage', 50),
                'key_elements_coverage': grading_result.get('key_elements_coverage', 50),
                'key_elements_in_standard': grading_result.get('key_elements_in_standard', []),
                'key_elements_covered': grading_result.get('key_elements_covered', []),
                'missing_key_elements': grading_result.get('missing_key_elements', []),
                'accuracy_issues': grading_result.get('accuracy_issues', [])
            })
        
        return graded_answer
        
    except Exception as e:
        return create_error_result(answer, f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def create_error_result(answer, error_msg):
    """å‰µå»ºéŒ¯èª¤çµæœ"""
    # æ³¨æ„ï¼šç©ºç­”æ¡ˆå·²ç¶“è¢«éæ¿¾æ‰ï¼Œé€™è£¡åªè™•ç†æœ‰å…§å®¹ä½†å‡ºéŒ¯çš„ç­”æ¡ˆ
    return {
        **answer,
        'score': 0,
        'is_correct': False,
        'feedback': error_msg,
        'grading_type': 'error',
        'question_found': False
    }

def create_not_found_result(answer):
    """å‰µå»ºæœªæ‰¾åˆ°é¡Œç›®çš„çµæœ"""
    # æ³¨æ„ï¼šç©ºç­”æ¡ˆå·²ç¶“è¢«éæ¿¾æ‰ï¼Œé€™è£¡åªè™•ç†æœ‰å…§å®¹ä½†æ‰¾ä¸åˆ°é¡Œç›®çš„ç­”æ¡ˆ
    return {
        **answer,
        'score': 0,
        'is_correct': False,
        'feedback': 'ç„¡æ³•æ‰¾åˆ°å°æ‡‰çš„é¡Œç›®é€²è¡Œè©•åˆ†',
        'grading_type': 'not_found',
        'question_found': False
    }

@dashboard_bp.route('/get-user-name', methods=['POST', 'OPTIONS'])
def get_user_name():
    if request.method == 'OPTIONS':
        return '', 204
    auth_header = request.headers.get('Authorization')
    if not auth_header:
        return jsonify({'message': 'æœªæä¾›token'}), 401
    # æª¢æŸ¥Authorization headeræ ¼å¼
    if not auth_header.startswith('Bearer '):
        return jsonify({'message': 'Tokenæ ¼å¼éŒ¯èª¤'}), 401
    token = auth_header.split(" ")[1]
    
    try:
        user_name = get_user_info(token, 'name')
        return jsonify({'name': user_name}), 200
    except ValueError as e:
        error_msg = str(e)
        if "expired" in error_msg.lower():
            return jsonify({'message': 'Tokenå·²éæœŸï¼Œè«‹é‡æ–°ç™»éŒ„', 'code': 'TOKEN_EXPIRED'}), 401
        elif "invalid" in error_msg.lower():
            return jsonify({'message': 'ç„¡æ•ˆçš„token', 'code': 'TOKEN_INVALID'}), 401
        else:
            return jsonify({'message': 'èªè­‰å¤±æ•—', 'code': 'AUTH_FAILED'}), 401
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶åç¨±æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return jsonify({'message': 'æœå‹™å™¨å…§éƒ¨éŒ¯èª¤', 'code': 'SERVER_ERROR'}), 500

# æ³¨æ„ï¼šget-examå’Œget-exam-to-objectå‡½æ•¸å·²ç§»å‹•åˆ°quiz.py

@dashboard_bp.route('/submit-answers', methods=['POST', 'OPTIONS'])
def submit_answers():
    if request.method == 'OPTIONS':
        return '', 204

    auth_header = request.headers.get('Authorization')
    token = auth_header.split(" ")[1]
     
    try:
        decoded_token = jwt.decode(token, current_app.config['SECRET_KEY'], algorithms=["HS256"])
        user_email = decoded_token['user']
        user = mongo.db.students.find_one({"email": user_email})
        user_name = get_user_info(token, 'name')
    except:
        return jsonify({'message': 'ç„¡æ•ˆçš„token'}), 401

    answers = request.json.get('answers')
    print("æ”¶åˆ°çš„ç­”æ¡ˆè³‡æ–™:", answers)
    
    if not answers or len(answers) == 0:
        return jsonify({'message': 'æ²’æœ‰æ”¶åˆ°ç­”æ¡ˆè³‡æ–™'}), 400

    # éæ¿¾æ‰ç©ºç­”æ¡ˆï¼Œåªè™•ç†æœ‰å…§å®¹çš„ç­”æ¡ˆ
    original_count = len(answers)
    filtered_answers = []
    skipped_count = 0
    
    for answer in answers:
        user_answer = answer.get('answer', '')
        if user_answer and user_answer.strip():
            # æœ‰å…§å®¹çš„ç­”æ¡ˆï¼Œä¿ç•™è™•ç†
            filtered_answers.append(answer)
        else:
            # ç©ºç­”æ¡ˆï¼Œå®Œå…¨è·³é
            skipped_count += 1
            print(f"è·³éç©ºç­”æ¡ˆé¡Œç›®: {answer.get('question_number', 'æœªçŸ¥')}")
    
    print(f"åŸå§‹é¡Œç›®æ•¸: {original_count}, æœ‰ä½œç­”: {len(filtered_answers)}, è·³éç©ºç­”æ¡ˆ: {skipped_count}")
    
    if len(filtered_answers) == 0:
        return jsonify({
            'message': 'æ‰€æœ‰é¡Œç›®éƒ½æ˜¯ç©ºç­”æ¡ˆï¼Œç„¡éœ€è™•ç†',
            'total_questions': original_count,
            'answered_questions': 0,
            'skipped_questions': skipped_count
        }), 200

    # ä½¿ç”¨éæ¿¾å¾Œçš„ç­”æ¡ˆé€²è¡Œå¾ŒçºŒè™•ç†
    answers = filtered_answers
  
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
    submission_id = str(uuid.uuid4())
    
    school = answers[0].get('school', '') if answers else ''
    year = answers[0].get('year', '') if answers else ''
    subject = answers[0].get('subject', '') if answers else ''
    department = answers[0].get('department', '') if answers else ''
    
    # æ‰¹æ”¹ç­”æ¡ˆ - ä½¿ç”¨ä¸¦è¡Œè™•ç†
    print(f"ğŸš€ é–‹å§‹ä¸¦è¡Œæ‰¹æ”¹ {len(answers)} é“é¡Œç›®...")
    
    # æº–å‚™ä¸¦è¡Œè™•ç†çš„åƒæ•¸
    max_workers = min(len(API_KEYS), len(answers), 8)  # æœ€å¤š8å€‹ä¸¦è¡Œworker
    task_args = [(answer, i, len(answers)) for i, answer in enumerate(answers)]
    
    graded_answers = []
    
    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_index = {executor.submit(process_single_answer, args): i 
                          for i, args in enumerate(task_args)}
        
        # æ”¶é›†çµæœ
        completed_count = 0
        for future in concurrent.futures.as_completed(future_to_index):
            completed_count += 1
            try:
                graded_answer = future.result()
                graded_answers.append((future_to_index[future], graded_answer))
                
                print(f"âœ… å®Œæˆ {completed_count}/{len(answers)} é¡Œ")
                
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•—: {e}")
                error_answer = create_error_result(
                    answers[future_to_index[future]], 
                    f"ä¸¦è¡Œè™•ç†å¤±æ•—: {str(e)}"
                )
                graded_answers.append((future_to_index[future], error_answer))
    
    # æŒ‰åŸé †åºæ’åºçµæœ
    graded_answers.sort(key=lambda x: x[0])
    graded_answers = [answer for _, answer in graded_answers]
    
    print(f"ğŸ‰ æ‰€æœ‰é¡Œç›®æ‰¹æ”¹å®Œæˆï¼")
    
    # è¨ˆç®—æ•´é«”æˆç¸¾ - ç¾åœ¨åªåŒ…å«æœ‰ä½œç­”çš„é¡Œç›®
    # çµ±è¨ˆå„ç¨®è©•åˆ†çµæœ
    successful_questions = [answer for answer in graded_answers 
                          if answer.get('grading_type') in ['automatic', 'ai_assisted']]
    invalid_answer_questions = [answer for answer in graded_answers 
                              if answer.get('grading_type') == 'invalid_answer']
    error_questions = [answer for answer in graded_answers 
                     if answer.get('grading_type') in ['error', 'not_found', 'fallback']]
    
    # è¨ˆç®—åˆ†æ•¸ï¼ˆåŒ…å«æ‰€æœ‰å¯¦éš›ä½œç­”çš„é¡Œç›®ï¼ŒåŒ…æ‹¬å›ç­”"ä¸çŸ¥é“"çš„ï¼‰
    total_score = 0
    correct_count = 0
    
    # æ‰€æœ‰å¯¦éš›ä½œç­”çš„é¡Œç›®éƒ½åƒèˆ‡çµ±è¨ˆï¼ˆåŒ…æ‹¬invalid_answerï¼‰
    for answer in graded_answers:
        if answer.get('score') is not None:
            total_score += answer['score']
        if answer.get('is_correct'):
            correct_count += 1
    
    # çµ±è¨ˆåŸºæ–¼å¯¦éš›è™•ç†çš„é¡Œç›®æ•¸é‡
    processed_count = len(graded_answers)
    average_score = total_score / processed_count if processed_count > 0 else 0
    accuracy_rate = (correct_count / processed_count) * 100 if processed_count > 0 else 0
    
    answer_stats = {}
    grading_stats = {}
    for answer in graded_answers:
        answer_type = answer.get('type', 'unknown')
        if answer_type not in answer_stats:
            answer_stats[answer_type] = 0
        answer_stats[answer_type] += 1
        
        grading_type = answer.get('grading_type', 'unknown')
        if grading_type not in grading_stats:
            grading_stats[grading_type] = 0
        grading_stats[grading_type] += 1
    
    # æ•´åˆçš„ç­”æ¡ˆæ–‡ä»¶çµæ§‹ï¼ˆåŒ…å«è©•åˆ†ç»“æœï¼‰
    integrated_submission = {
        'submission_id': submission_id,
        'user_name': user_name,
        'user_email': user_email,
        'submit_time': current_time,
        'school': school,
        'department': department,
        'year': year,
        'subject': subject,
        'answer_summary': {
            'original_questions': original_count,  # åŸå§‹é¡Œç›®ç¸½æ•¸
            'processed_questions': len(answers),   # å¯¦éš›è™•ç†çš„é¡Œç›®æ•¸
            'skipped_questions': skipped_count,    # è·³éçš„ç©ºç­”æ¡ˆé¡Œç›®æ•¸
            'answer_stats': answer_stats,
            'grading_stats': grading_stats
        },
        'grading_results': {
            'total_score': total_score,
            'average_score': round(average_score, 2),
            'correct_count': correct_count,
            'accuracy_rate': round(accuracy_rate, 2),
            'processed_count': processed_count,  # å¯¦éš›è©•åˆ†çš„é¡Œç›®æ•¸
            'skipped_count': skipped_count,      # è·³éçš„é¡Œç›®æ•¸
            'error_count': len(error_questions),  # éŒ¯èª¤é¡Œç›®æ•¸
            'graded_at': current_time,
            'grading_method': 'gemini_ai'
        },
        'answers': graded_answers,  # åªåŒ…å«å¯¦éš›è™•ç†çš„ç­”æ¡ˆ
        'status': 'graded'
    }
    
    try:
        result = mongo.db.user_answer.insert_one(integrated_submission)
        print(f"æˆåŠŸæäº¤ä¸¦è©•åˆ†ç­”æ¡ˆï¼Œsubmission_id: {submission_id}")
        print(f"è©•åˆ†çµæœ: å¹³å‡åˆ†æ•¸ {average_score:.2f}, æ­£ç¢ºç‡ {accuracy_rate:.2f}%")
        print(f"çµ±è¨ˆ: åŸå§‹é¡Œç›® {original_count}, å¯¦éš›è™•ç† {processed_count}, è·³éç©ºç­”æ¡ˆ {skipped_count}, éŒ¯èª¤ {len(error_questions)}")
        
        return jsonify({
            'message': 'ç­”æ¡ˆæäº¤ä¸¦è©•åˆ†æˆåŠŸ',
            'submission_id': submission_id,
            'original_questions': original_count,
            'processed_questions': processed_count,
            'skipped_questions': skipped_count,
            'grading_results': {
                'total_score': total_score,
                'average_score': round(average_score, 2),
                'correct_count': correct_count,
                'accuracy_rate': round(accuracy_rate, 2),
                'note': f'çµ±è¨ˆåŸºæ–¼å¯¦éš›è™•ç†çš„ {processed_count} é“é¡Œç›®ï¼ˆå·²è·³é {skipped_count} é“ç©ºç­”æ¡ˆï¼‰'
            }
        }), 200
        
    except Exception as e:
        print(f"æäº¤ç­”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return jsonify({'message': 'ç­”æ¡ˆæäº¤å¤±æ•—'}), 500

@dashboard_bp.route('/getUserSubmissions', methods=['POST', 'OPTIONS'])
def getUserSubmissions():
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        auth_header = request.headers.get('Authorization')
        if not auth_header:
            return jsonify({'message': 'æœªæä¾›æˆæ¬Šæ¨™é ­'}), 401
            
        token = auth_header.split(" ")[1]
        decoded_token = jwt.decode(token, current_app.config['SECRET_KEY'], algorithms=["HS256"])
        user_email = decoded_token['user']
        
        # ç²å–ç”¨æˆ¶è³‡è¨Š
        try:
            user_name = get_user_info(token, 'name')
        except Exception as e:
            print(f"ç²å–ç”¨æˆ¶è³‡è¨ŠéŒ¯èª¤: {str(e)}")
            user_name = user_email  # ä½¿ç”¨ email ä½œç‚ºå‚™ç”¨
        
        # ç²å–è«‹æ±‚åƒæ•¸
        data = request.json or {}
        target_email = data.get('target_email', user_email)  # å¦‚æœæ²’æœ‰æŒ‡å®šï¼ŒæŸ¥çœ‹è‡ªå·±çš„
        submission_id = data.get('submission_id', None)  # å¯é¸ï¼šæŸ¥çœ‹ç‰¹å®šæäº¤
        
        # å»ºç«‹æŸ¥è©¢æ¢ä»¶
        query = {"user_email": target_email}
        if submission_id:
            query["submission_id"] = submission_id
        
        # æŸ¥è©¢æäº¤è¨˜éŒ„
        submissions = list(mongo.db.user_answer.find(query).sort("submit_time", -1))
        
        if not submissions:
            return jsonify({
                'message': 'æœªæ‰¾åˆ°æäº¤è¨˜éŒ„',
                'submissions': [],
                'count': 0
            }), 200
        
        # æ ¼å¼åŒ–è¿”å›è³‡æ–™
        formatted_submissions = []
        for submission in submissions:
            # è½‰æ›ObjectIdç‚ºå­—ä¸²
            submission['_id'] = str(submission['_id'])
            
            # åŠ å·¥ç­”æ¡ˆè³‡æ–™ï¼Œæä¾›æ›´æ¸…æ™°çš„åˆ†æ
            answers = submission.get('answers', [])
            
            # åˆ†æç­”æ¡ˆé¡å‹åˆ†ä½ˆ
            answer_analysis = {
                'total_questions': len(answers),
                'by_type': {},
                'by_grading_result': {},
                'by_score_range': {
                    'excellent': 0,    # 90-100åˆ†
                    'good': 0,         # 70-89åˆ†
                    'average': 0,      # 50-69åˆ†
                    'poor': 0,         # 30-49åˆ†
                    'failed': 0        # 0-29åˆ†
                }
            }
            
            for answer in answers:
                # æŒ‰é¡Œç›®é¡å‹çµ±è¨ˆ
                q_type = answer.get('type', 'unknown')
                if q_type not in answer_analysis['by_type']:
                    answer_analysis['by_type'][q_type] = {
                        'count': 0, 'correct': 0, 'avg_score': 0, 'total_score': 0
                    }
                answer_analysis['by_type'][q_type]['count'] += 1
                if answer.get('is_correct'):
                    answer_analysis['by_type'][q_type]['correct'] += 1
                score = answer.get('score', 0)
                answer_analysis['by_type'][q_type]['total_score'] += score
                
                # æŒ‰è©•åˆ†çµæœçµ±è¨ˆ
                grading_type = answer.get('grading_type', 'unknown')
                if grading_type not in answer_analysis['by_grading_result']:
                    answer_analysis['by_grading_result'][grading_type] = 0
                answer_analysis['by_grading_result'][grading_type] += 1
                
                # æŒ‰åˆ†æ•¸ç¯„åœçµ±è¨ˆ
                if score >= 90:
                    answer_analysis['by_score_range']['excellent'] += 1
                elif score >= 70:
                    answer_analysis['by_score_range']['good'] += 1
                elif score >= 50:
                    answer_analysis['by_score_range']['average'] += 1
                elif score >= 30:
                    answer_analysis['by_score_range']['poor'] += 1
                else:
                    answer_analysis['by_score_range']['failed'] += 1
            
            # è¨ˆç®—æ¯ç¨®é¡Œå‹çš„å¹³å‡åˆ†
            for type_info in answer_analysis['by_type'].values():
                if type_info['count'] > 0:
                    type_info['avg_score'] = round(type_info['total_score'] / type_info['count'], 2)
            
            # å„ªåŒ–ç­”æ¡ˆé¡¯ç¤ºæ ¼å¼
            detailed_answers = []
            for i, answer in enumerate(answers, 1):
                detailed_answer = {
                    'question_number': answer.get('question_number', str(i)),
                    'type': answer.get('type', 'unknown'),
                    'question_text': answer.get('question_text', ''),
                    'student_answer': answer.get('answer', ''),
                    'correct_answer': answer.get('correct_answer', ''),
                    'score': answer.get('score', 0),
                    'is_correct': answer.get('is_correct', False),
                    'feedback': answer.get('feedback', ''),
                    'grading_type': answer.get('grading_type', 'unknown'),
                    'options': answer.get('options', [])
                }
                
                # å¦‚æœæ˜¯AIè©•åˆ†ï¼Œæ·»åŠ è©³ç´°åˆ†æ
                if answer.get('grading_type') == 'ai_assisted':
                    detailed_answer.update({
                        'ai_analysis': {
                            'accuracy_percentage': answer.get('accuracy_percentage', 0),
                            'key_elements_coverage': answer.get('key_elements_coverage', 0),
                            'key_elements_in_standard': answer.get('key_elements_in_standard', []),
                            'key_elements_covered': answer.get('key_elements_covered', []),
                            'missing_key_elements': answer.get('missing_key_elements', []),
                            'accuracy_issues': answer.get('accuracy_issues', [])
                        }
                    })
                
                detailed_answers.append(detailed_answer)
            
            formatted_submission = {
                '_id': submission['_id'],
                'submission_id': submission.get('submission_id', ''),
                'user_name': submission.get('user_name', ''),
                'user_email': submission.get('user_email', ''),
                'submit_time': submission.get('submit_time', ''),
                'basic_info': {
                    'school': submission.get('school', ''),
                    'department': submission.get('department', ''),
                    'year': submission.get('year', ''),
                    'subject': submission.get('subject', '')
                },
                'grading_results': submission.get('grading_results', {}),
                'answer_summary': submission.get('answer_summary', {}),
                'answer_analysis': answer_analysis,
                'answers': detailed_answers,
                'status': submission.get('status', 'unknown')
            }
            
            formatted_submissions.append(formatted_submission)
        
        return jsonify({
            'message': 'æŸ¥è©¢æˆåŠŸ',
            'submissions': formatted_submissions,
            'count': len(formatted_submissions),
            'query_info': {
                'target_email': target_email,
                'submission_id': submission_id,
                'queried_by': user_email
            }
        }), 200
        
    except jwt.InvalidTokenError:
        return jsonify({'message': 'ç„¡æ•ˆçš„token'}), 401
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶æäº¤è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return jsonify({'message': f'æŸ¥è©¢å¤±æ•—: {str(e)}'}), 500

# æ–°å¢ï¼šæ ¹æ“šsubmission_idæŸ¥è©¢ç‰¹å®šæäº¤çš„è©³ç´°è³‡æ–™
@dashboard_bp.route('/getSubmissionDetail', methods=['POST', 'OPTIONS'])
def getSubmissionDetail():
    if request.method == 'OPTIONS':
        return '', 204
    
    auth_header = request.headers.get('Authorization')
    token = auth_header.split(" ")[1]
    
    try:
        decoded_token = jwt.decode(token, current_app.config['SECRET_KEY'], algorithms=["HS256"])
        user_email = decoded_token['user']
        
        data = request.json or {}
        submission_id = data.get('submission_id')
        
        if not submission_id:
            return jsonify({'message': 'è«‹æä¾›submission_id'}), 400
        
        # æŸ¥è©¢ç‰¹å®šæäº¤
        submission = mongo.db.user_answer.find_one({"submission_id": submission_id})
        
        if not submission:
            return jsonify({'message': 'æœªæ‰¾åˆ°è©²æäº¤è¨˜éŒ„'}), 404
        
        # è½‰æ›ObjectIdç‚ºå­—ä¸²
        submission['_id'] = str(submission['_id'])
        
        # è©³ç´°çš„é¡Œç›®åˆ†æ
        answers = submission.get('answers', [])
        question_details = []
        
        for answer in answers:
            question_detail = {
                'question_number': answer.get('question_number', ''),
                'type': answer.get('type', ''),
                'question_text': answer.get('question_text', ''),
                'options': answer.get('options', []),
                'student_answer': answer.get('answer', ''),
                'correct_answer': answer.get('correct_answer', ''),
                'score': answer.get('score', 0),
                'is_correct': answer.get('is_correct', False),
                'feedback': answer.get('feedback', ''),
                'grading_type': answer.get('grading_type', 'unknown'),
                'question_found': answer.get('question_found', True)
            }
            
            # æ ¹æ“šé¡Œç›®é¡å‹æä¾›ä¸åŒçš„åˆ†æ
            if answer.get('type') in ['single-choice', 'multiple-choice', 'true-false']:
                question_detail['comparison'] = {
                    'student_chose': answer.get('answer', ''),
                    'correct_option': answer.get('correct_answer', ''),
                    'match_result': answer.get('is_correct', False)
                }
            elif answer.get('grading_type') == 'ai_assisted':
                question_detail['ai_analysis'] = {
                    'accuracy_percentage': answer.get('accuracy_percentage', 0),
                    'key_elements_coverage': answer.get('key_elements_coverage', 0),
                    'key_elements_in_standard': answer.get('key_elements_in_standard', []),
                    'key_elements_covered': answer.get('key_elements_covered', []),
                    'missing_key_elements': answer.get('missing_key_elements', []),
                    'accuracy_issues': answer.get('accuracy_issues', [])
                }
            
            question_details.append(question_detail)
        
        return jsonify({
            'message': 'æŸ¥è©¢æˆåŠŸ',
            'submission': {
                '_id': submission['_id'],
                'submission_id': submission.get('submission_id', ''),
                'user_info': {
                    'name': submission.get('user_name', ''),
                    'email': submission.get('user_email', ''),
                    'school': submission.get('school', ''),
                    'department': submission.get('department', ''),
                    'year': submission.get('year', ''),
                    'subject': submission.get('subject', '')
                },
                'submit_time': submission.get('submit_time', ''),
                'grading_results': submission.get('grading_results', {}),
                'answer_summary': submission.get('answer_summary', {}),
                'question_details': question_details,
                'status': submission.get('status', 'unknown')
            }
        }), 200
        
    except jwt.InvalidTokenError:
        return jsonify({'message': 'ç„¡æ•ˆçš„token'}), 401
    except Exception as e:
        print(f"ç²å–æäº¤è©³æƒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return jsonify({'message': f'æŸ¥è©¢å¤±æ•—: {str(e)}'}), 500