#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIç­”æ¡ˆè©•åˆ†æ¨¡çµ„ - ä½¿ç”¨Gemini APIé€²è¡Œæ™ºèƒ½è©•åˆ†ï¼Œæ”¯æ´ä¸¦è¡Œè™•ç†
"""

import json
import re
import concurrent.futures
from typing import List, Dict, Any, Tuple
import google.generativeai as genai
from tool.api_keys import get_api_key, get_api_keys_count

class AnswerGrader:
    """ç­”æ¡ˆæ‰¹æ”¹å™¨ - ç°¡åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        # åˆå§‹åŒ–Gemini API
        try:
            api_key = get_api_key()
            genai.configure(api_key=api_key)
            # ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹åç¨±
            self.model = genai.GenerativeModel('gemini-2.5-flash')
            print("âœ… Gemini API åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Gemini API åˆå§‹åŒ–å¤±æ•—: {e}")
            self.model = None
    
    def batch_grade_ai_questions(self, questions_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡è©•åˆ†AIé¡Œç›® - ä¸¦è¡Œè™•ç†ç‰ˆæœ¬"""
        if not questions_data:
            return []
        
        # ç²å–å¯ç”¨çš„APIé‡‘é‘°æ•¸é‡
        api_keys_count = get_api_keys_count()
        total_questions = len(questions_data)
        
        print(f"ğŸš€ é–‹å§‹ä¸¦è¡ŒAIè©•åˆ†ï¼š{total_questions} é¡Œï¼Œ{api_keys_count} å€‹APIé‡‘é‘°")
        
        # è¨ˆç®—æ¯å€‹APIé‡‘é‘°è™•ç†çš„é¡Œç›®æ•¸é‡
        questions_per_key = total_questions // api_keys_count
        remainder = total_questions % api_keys_count
        
        print(f"ğŸ“Š ä¸¦è¡Œè™•ç†é…ç½®ï¼šæ¯å€‹é‡‘é‘°è™•ç† {questions_per_key} é¡Œï¼Œå‰©é¤˜ {remainder} é¡Œ")
        
        # åˆ†é…é¡Œç›®çµ¦ä¸åŒçš„APIé‡‘é‘°
        all_results = [None] * total_questions  # é åˆ†é…çµæœé™£åˆ—
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=api_keys_count) as executor:
            futures = []
            start_index = 0
            
            for i in range(api_keys_count):
                # è¨ˆç®—é€™å€‹é‡‘é‘°è¦è™•ç†çš„é¡Œç›®æ•¸é‡
                batch_size = questions_per_key + (1 if i < remainder else 0)
                end_index = start_index + batch_size
                
                # æå–é€™æ‰¹é¡Œç›®
                questions_batch = questions_data[start_index:end_index]
                batch_indices = list(range(start_index, end_index))  # è¨˜éŒ„åŸå§‹ç´¢å¼•
                
                print(f"ğŸ”‘ APIé‡‘é‘° {i+1}: è™•ç†é¡Œç›® {start_index+1}-{end_index} (å…± {batch_size} é¡Œ)")
                
                # æäº¤ä»»å‹™
                future = executor.submit(
                    self._process_questions_batch, 
                    questions_batch, 
                    batch_indices,
                    i
                )
                futures.append(future)
                
                start_index = end_index
            
            # æ”¶é›†çµæœ
            for future in concurrent.futures.as_completed(futures):
                try:
                    batch_results = future.result()
                    # å°‡çµæœæ”¾å…¥æ­£ç¢ºçš„ä½ç½®
                    for result in batch_results:
                        if result and 'original_index' in result:
                            original_idx = result.pop('original_index')
                            all_results[original_idx] = result
                except Exception as e:
                    print(f"âŒ ä¸¦è¡Œè™•ç†æ‰¹æ¬¡å¤±æ•—: {e}")
        
        # éæ¿¾æ‰Noneå€¼ï¼ˆå¦‚æœæœ‰éŒ¯èª¤çš„è©±ï¼‰
        final_results = [result for result in all_results if result is not None]
        print(f"âœ… ä¸¦è¡ŒAIè©•åˆ†å®Œæˆï¼šæˆåŠŸè™•ç† {len(final_results)}/{total_questions} é¡Œ")
        
        return final_results
    
    def _process_questions_batch(self, questions_batch: List[Dict], batch_indices: List[int], api_key_index: int) -> List[Dict]:
        """è™•ç†ä¸€æ‰¹é¡Œç›®ï¼ˆå–®å€‹APIé‡‘é‘°ï¼‰"""
        results = []
        
        for i, question_data in enumerate(questions_batch):
            try:
                original_index = batch_indices[i]
                print(f"  ğŸ” APIé‡‘é‘° {api_key_index+1} è©•åˆ†é¡Œç›® {original_index+1}")
                
                # ç‚ºé€™å€‹æ‰¹æ¬¡å‰µå»ºå°ˆç”¨çš„Geminiæ¨¡å‹å¯¦ä¾‹
                batch_model = self._create_batch_model(api_key_index)
                
                user_answer = question_data['user_answer']
                question_type = question_data['question_type']
                
                is_correct, score, feedback = self._ai_grade_answer_with_model(
                    batch_model,
                    user_answer, 
                    question_data.get('question_text', ''),
                    question_data.get('correct_answer', ''),
                    question_data.get('options', []),
                    question_type
                )
                
                result = {
                    'question_id': question_data['question_id'],
                    'is_correct': is_correct,
                    'score': score,
                    'feedback': feedback,
                    'original_index': original_index,  # ä¿æŒåŸå§‹é †åº
                    'api_key_used': api_key_index + 1  # è¨˜éŒ„ä½¿ç”¨çš„APIé‡‘é‘°
                }
                results.append(result)
                
            except Exception as e:
                print(f"  âŒ APIé‡‘é‘° {api_key_index+1} è©•åˆ†é¡Œç›® {batch_indices[i]+1} å¤±æ•—: {e}")
                # å‰µå»ºéŒ¯èª¤çµæœ
                error_result = {
                    'question_id': question_data.get('question_id', ''),
                    'is_correct': False,
                    'score': 0,
                    'feedback': {'error': f'è©•åˆ†å¤±æ•—: {str(e)}'},
                    'original_index': batch_indices[i],
                    'api_key_used': api_key_index + 1
                }
                results.append(error_result)
        
        return results
    
    def _create_batch_model(self, api_key_index: int):
        """ç‚ºæ‰¹æ¬¡å‰µå»ºå°ˆç”¨çš„Geminiæ¨¡å‹å¯¦ä¾‹"""
        try:
            # ä½¿ç”¨æŒ‡å®šçš„APIé‡‘é‘°ç´¢å¼•
            api_key = self._get_api_key_by_index(api_key_index)
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-2.5-flash')
            return model
        except Exception as e:
            print(f"âŒ å‰µå»ºæ‰¹æ¬¡æ¨¡å‹å¤±æ•—: {e}")
            return self.model  # å›é€€åˆ°ä¸»æ¨¡å‹
    
    def _get_api_key_by_index(self, index: int) -> str:
        """æ ¹æ“šç´¢å¼•ç²å–ç‰¹å®šçš„APIé‡‘é‘°"""
        try:
            from tool.api_keys import api_key_manager
            # ç²å–æ‰€æœ‰å¯ç”¨çš„APIé‡‘é‘°
            all_keys = api_key_manager.api_keys
            if 0 <= index < len(all_keys):
                return all_keys[index]
            else:
                # å¦‚æœç´¢å¼•è¶…å‡ºç¯„åœï¼Œä½¿ç”¨éš¨æ©Ÿé¸æ“‡
                return get_api_key()
        except Exception as e:
            print(f"âš ï¸ ç²å–æŒ‡å®šç´¢å¼•APIé‡‘é‘°å¤±æ•—ï¼Œä½¿ç”¨éš¨æ©Ÿé¸æ“‡: {e}")
            return get_api_key()
    
    def _ai_grade_answer_with_model(self, model, user_answer: Any, question_text: str, correct_answer: str, 
                                    options: List[str], question_type: str) -> Tuple[bool, float, Dict[str, Any]]:
        """ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹é€²è¡ŒAIè©•åˆ†"""
        try:
            print(f"ğŸ” AIè©•åˆ† - é¡Œç›®é¡å‹: {question_type}")
            print(f"ğŸ” ç”¨æˆ¶ç­”æ¡ˆ: {user_answer}")
            print(f"ğŸ” æ­£ç¢ºç­”æ¡ˆ: {correct_answer}")
            print(f"ğŸ” é¸é …: {options}")
            print(f"ğŸ” é¡Œç›®å…§å®¹: {question_text[:100]}...")
            
            prompt = self._build_grading_prompt(user_answer, question_text, correct_answer, options, question_type)
            
            if model:
                response = model.generate_content(prompt)
                result = self._parse_ai_response(response.text)
                if result:
                    return result['is_correct'], result['score'], result['feedback']
            
            return False, 0, {'error': 'AIè©•åˆ†å¤±æ•—'}
            
        except Exception as e:
            print(f"âŒ AIè©•åˆ†ç•°å¸¸: {str(e)}")
            return False, 0, {'error': f'è©•åˆ†å¤±æ•—: {str(e)}'}
    
    
    def _ai_grade_answer(self, user_answer: Any, question_text: str, correct_answer: str, 
                         options: List[str], question_type: str) -> Tuple[bool, float, Dict[str, Any]]:
        """AIçµ±ä¸€è©•åˆ† - æ ¸å¿ƒå‡½æ•¸"""
        try:
            print(f"ğŸ” AIè©•åˆ† - é¡Œç›®é¡å‹: {question_type}")
            print(f"ğŸ” ç”¨æˆ¶ç­”æ¡ˆ: {user_answer}")
            print(f"ğŸ” æ­£ç¢ºç­”æ¡ˆ: {correct_answer}")
            print(f"ğŸ” é¸é …: {options}")
            print(f"ğŸ” é¡Œç›®å…§å®¹: {question_text[:100]}...")
            
            # æ§‹å»ºAIè©•åˆ†æç¤º
            prompt = self._build_grading_prompt(user_answer, question_text, correct_answer, options, question_type)
            
            # èª¿ç”¨AIè©•åˆ†
            if self.model:
                response = self.model.generate_content(prompt)
                result = self._parse_ai_response(response.text)
                if result:
                    # ç¢ºä¿è©•åˆ†é‚è¼¯ä¸€è‡´æ€§ï¼šåˆ†æ•¸ â‰¥ 80 çš„ç­”æ¡ˆè¢«æ¨™è¨˜ç‚ºæ­£ç¢º
                    score = result.get('score', 0)
                    is_correct = score >= 80
                    
                    # å¦‚æœAIçš„åˆ¤æ–·èˆ‡æˆ‘å€‘çš„æ¨™æº–ä¸ä¸€è‡´ï¼Œé€²è¡Œä¿®æ­£
                    if result.get('is_correct') != is_correct:
                        print(f"ğŸ”§ ä¿®æ­£è©•åˆ†é‚è¼¯ï¼šAIåˆ¤æ–· {result.get('is_correct')}ï¼Œåˆ†æ•¸ {score}ï¼Œä¿®æ­£ç‚º {is_correct}")
                        result['is_correct'] = is_correct
                    
                    return result['is_correct'], result['score'], result['feedback']
            
            # å¦‚æœAIè©•åˆ†å¤±æ•—ï¼Œè¿”å›é»˜èªçµæœ
            return False, 0, {'error': 'AIè©•åˆ†å¤±æ•—'}
            
        except Exception as e:
            print(f"âŒ AIè©•åˆ†ç•°å¸¸: {str(e)}")
            return False, 0, {'error': f'è©•åˆ†å¤±æ•—: {str(e)}'}
    
    def _build_grading_prompt(self, user_answer: str, question_text: str, correct_answer: str, 
                             options: List[str], question_type: str) -> str:
        """æ§‹å»ºAIè©•åˆ†æç¤º"""
        prompt = f"""
è«‹ä½œç‚ºä¸€ä½å°ˆæ¥­çš„MISèª²ç¨‹æ•™å¸«ï¼Œå°ä»¥ä¸‹å­¸ç”Ÿç­”æ¡ˆé€²è¡Œè©•åˆ†ã€‚

é¡Œç›®é¡å‹ï¼š{question_type}
é¡Œç›®å…§å®¹ï¼š{question_text}

å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}
æ­£ç¢ºç­”æ¡ˆï¼š{correct_answer}
é¸é …ï¼š{options if options else 'ç„¡'}

è©•åˆ†è¦æ±‚ï¼š
1. ä»”ç´°åˆ†æå­¸ç”Ÿç­”æ¡ˆçš„å…§å®¹å’Œé‚è¼¯
2. åˆ¤æ–·ç­”æ¡ˆæ˜¯å¦æ­£ç¢ºæˆ–éƒ¨åˆ†æ­£ç¢º
3. çµ¦å‡º0-100çš„åˆ†æ•¸
4. æä¾›å…·é«”çš„è©•åˆ†ç†ç”±å’Œæ”¹é€²å»ºè­°

è©•åˆ†æ¨™æº–ï¼š
- 90-100åˆ†ï¼šå®Œå…¨æ­£ç¢ºï¼Œç­”æ¡ˆå®Œæ•´ä¸”æº–ç¢º
- 80-89åˆ†ï¼šæ¥è¿‘æ­£ç¢ºï¼Œä¸»è¦æ¦‚å¿µæ­£ç¢ºä½†æœ‰å°éŒ¯èª¤
- 60-79åˆ†ï¼šå‹‰å¼·åŠæ ¼ï¼Œéƒ¨åˆ†æ­£ç¢ºä½†ç†è§£ä¸å¤ æ·±å…¥
- 40-59åˆ†ï¼šéƒ¨åˆ†æ­£ç¢ºï¼Œæœ‰åŸºæœ¬æ¦‚å¿µä½†éŒ¯èª¤è¼ƒå¤š
- 0-39åˆ†ï¼šéŒ¯èª¤ï¼Œä¸»è¦æ¦‚å¿µéŒ¯èª¤æˆ–ç­”æ¡ˆä¸å®Œæ•´

æ­£ç¢ºæ€§åˆ¤æ–·æ¨™æº–ï¼š
- åˆ†æ•¸ â‰¥ 80åˆ†ï¼šç­”æ¡ˆè¢«èªç‚ºæ˜¯æ­£ç¢ºçš„ (is_correct: true)
- åˆ†æ•¸ < 80åˆ†ï¼šç­”æ¡ˆè¢«èªç‚ºæ˜¯ä¸æ­£ç¢ºçš„ (is_correct: false)

è«‹ä»¥JSONæ ¼å¼è¿”å›è©•åˆ†çµæœï¼š
{{
    "is_correct": true/false,
    "score": åˆ†æ•¸(0-100),
    "feedback": {{
        "explanation": "è©•åˆ†èªªæ˜",
        "strengths": "å„ªé»",
        "weaknesses": "éœ€è¦æ”¹é€²çš„åœ°æ–¹",
        "suggestions": "å­¸ç¿’å»ºè­°"
    }}
}}

æ³¨æ„ï¼š
1. è«‹æ ¹æ“šç­”æ¡ˆçš„å¯¦éš›å…§å®¹å’Œè³ªé‡é€²è¡Œè©•åˆ†ï¼Œä¸è¦ç°¡å–®åœ°æ¯”è¼ƒå­—ç¬¦ä¸²
2. å°æ–¼ç¶²è·¯æ‹“æ¨¸ç­‰æ¦‚å¿µæ€§é¡Œç›®ï¼Œå¦‚æœå­¸ç”Ÿèƒ½æ­£ç¢ºåˆ—å‡ºä¸»è¦é¡å‹ä¸¦èªªæ˜ç‰¹é»ï¼Œå³ä½¿æ ¼å¼ä¸å®Œç¾ï¼Œä¹Ÿæ‡‰è©²çµ¦äºˆè¼ƒé«˜åˆ†æ•¸
3. åˆ†æ•¸ â‰¥ 80åˆ†æ™‚ï¼Œis_correct å¿…é ˆè¨­ç‚º true
"""
        return prompt
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æAIå›æ‡‰"""
        try:
            # å˜—è©¦æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                
                # é©—è­‰å¿…è¦å­—æ®µ
                if all(key in result for key in ['is_correct', 'score', 'feedback']):
                    return result
                else:
                    print("âš ï¸ AIå›æ‡‰ç¼ºå°‘å¿…è¦å­—æ®µ")
                    return None
            else:
                print("âš ï¸ ç„¡æ³•å¾AIå›æ‡‰ä¸­æå–JSON")
                return None
                
        except Exception as e:
            print(f"âš ï¸ è§£æAIå›æ‡‰å¤±æ•—: {e}")
            return None

# å‰µå»ºå…¨å±€å¯¦ä¾‹
grader = AnswerGrader()

def batch_grade_ai_questions(questions_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ‰¹é‡æ‰¹æ”¹AIé¡Œç›®çš„ä¾¿æ·å‡½æ•¸"""
    return grader.batch_grade_ai_questions(questions_data)
