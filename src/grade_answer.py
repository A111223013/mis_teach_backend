import json
import re
import concurrent.futures
from typing import List, Dict, Any, Tuple
from tool.api_keys import get_api_key, get_api_keys_count
from accessories import init_gemini

class AnswerGrader:
    """ç­”æ¡ˆæ‰¹æ”¹å™¨ - ç°¡åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        # åˆå§‹åŒ–Gemini API
        self.model = init_gemini('gemini-2.0-flash')
    
    def batch_grade_ai_questions(self, questions_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡è©•åˆ†AIé¡Œç›® - ä¸¦è¡Œè™•ç†ç‰ˆæœ¬"""
        if not questions_data:
            return []
        
        # ç²å–å¯ç”¨çš„APIé‡‘é‘°æ•¸é‡
        api_keys_count = get_api_keys_count()
        total_questions = len(questions_data)

        # è¨ˆç®—æ¯å€‹APIé‡‘é‘°è™•ç†çš„é¡Œç›®æ•¸é‡
        questions_per_key = total_questions // api_keys_count
        remainder = total_questions % api_keys_count

        # åˆ†é…é¡Œç›®çµ¦ä¸åŒçš„APIé‡‘é‘°
        all_results = [None] * total_questions  # é åˆ†é…çµæœé™£åˆ—
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=api_keys_count) as executor:
            futures = []
            start_index = 0
            
            for i in range(api_keys_count):
                # è¨ˆç®—é€™å€‹é‡‘é‘°è¦è™•ç†çš„é¡Œç›®æ•¸é‡
                batch_size = questions_per_key + (1 if i < remainder else 0)
                end_index = start_index + batch_size
                
                # æå–é€™æ‰¹é¡Œç›®
                questions_batch = questions_data[start_index:end_index]
                batch_indices = list(range(start_index, end_index))  # è¨˜éŒ„åŸå§‹ç´¢å¼•
                
                # æäº¤ä»»å‹™
                future = executor.submit(
                    self._process_questions_batch, 
                    questions_batch, 
                    batch_indices,
                    i
                )
                futures.append(future)
                
                start_index = end_index
            
            # æ”¶é›†çµæœ
            for future in concurrent.futures.as_completed(futures):
                try:
                    batch_results = future.result()
                    # å°‡çµæœæ”¾å…¥æ­£ç¢ºçš„ä½ç½®
                    for result in batch_results:
                        if result and 'original_index' in result:
                            original_idx = result.pop('original_index')
                            all_results[original_idx] = result
                except Exception as e:
                    print(f"âŒ ä¸¦è¡Œè™•ç†æ‰¹æ¬¡å¤±æ•—: {e}")
        
        # éæ¿¾æ‰Noneå€¼ï¼ˆå¦‚æœæœ‰éŒ¯èª¤çš„è©±ï¼‰
        final_results = [result for result in all_results if result is not None]

        return final_results
    
    def _process_questions_batch(self, questions_batch: List[Dict], batch_indices: List[int], api_key_index: int) -> List[Dict]:
        """è™•ç†ä¸€æ‰¹é¡Œç›®ï¼ˆå–®å€‹APIé‡‘é‘°ï¼‰"""
        results = []
        
        for i, question_data in enumerate(questions_batch):
            try:
                original_index = batch_indices[i]
                
                # ç‚ºé€™å€‹æ‰¹æ¬¡å‰µå»ºå°ˆç”¨çš„Geminiæ¨¡å‹å¯¦ä¾‹
                batch_model = self._create_batch_model(api_key_index)
                
                user_answer = question_data['user_answer']
                question_type = question_data['question_type']
                
                is_correct, score, feedback = self._ai_grade_answer_with_model(
                    batch_model,
                    user_answer, 
                    question_data.get('question_text', ''),
                    question_data.get('correct_answer', ''),
                    question_data.get('options', []),
                    question_type
                )
                
                result = {
                    'question_id': question_data['question_id'],
                    'is_correct': is_correct,
                    'score': score,
                    'feedback': feedback,
                    'original_index': original_index,  # ä¿æŒåŸå§‹é †åº
                    'api_key_used': api_key_index + 1  # è¨˜éŒ„ä½¿ç”¨çš„APIé‡‘é‘°
                }
                results.append(result)
                
            except Exception as e:
                print(f"  âŒ APIé‡‘é‘° {api_key_index+1} è©•åˆ†é¡Œç›® {batch_indices[i]+1} å¤±æ•—: {e}")
                # å‰µå»ºéŒ¯èª¤çµæœ
                error_result = {
                    'question_id': question_data.get('question_id', ''),
                    'is_correct': False,
                    'score': 0,
                    'feedback': {'error': f'è©•åˆ†å¤±æ•—: {str(e)}'},
                    'original_index': batch_indices[i],
                    'api_key_used': api_key_index + 1
                }
                results.append(error_result)
        
        return results
    
    def _create_batch_model(self, api_key_index: int):
        """ç‚ºæ‰¹æ¬¡å‰µå»ºå°ˆç”¨çš„Geminiæ¨¡å‹å¯¦ä¾‹"""
        try:
            # ä½¿ç”¨æŒ‡å®šçš„APIé‡‘é‘°ç´¢å¼•
            api_key = self._get_api_key_by_index(api_key_index)
            # ä½¿ç”¨ accessories ä¸­çš„ init_gemini å‡½æ•¸
            model = init_gemini('gemini-2.0-flash')
            return model
        except Exception as e:
            print(f"âŒ å‰µå»ºæ‰¹æ¬¡æ¨¡å‹å¤±æ•—: {e}")
            return self.model  # å›é€€åˆ°ä¸»æ¨¡å‹
    
    def _get_api_key_by_index(self, index: int) -> str:
        """æ ¹æ“šç´¢å¼•ç²å–ç‰¹å®šçš„APIé‡‘é‘°"""
        try:
            from tool.api_keys import api_key_manager
            # ç²å–æ‰€æœ‰å¯ç”¨çš„APIé‡‘é‘°
            all_keys = api_key_manager.api_keys
            if 0 <= index < len(all_keys):
                return all_keys[index]
            else:
                # å¦‚æœç´¢å¼•è¶…å‡ºç¯„åœï¼Œä½¿ç”¨éš¨æ©Ÿé¸æ“‡
                return get_api_key()
        except Exception as e:
            print(f"âš ï¸ ç²å–æŒ‡å®šç´¢å¼•APIé‡‘é‘°å¤±æ•—ï¼Œä½¿ç”¨éš¨æ©Ÿé¸æ“‡: {e}")
            return get_api_key()
    
    def _ai_grade_answer_with_model(self, model, user_answer: Any, question_text: str, correct_answer: str, 
                                    options: List[str], question_type: str) -> Tuple[bool, float, Dict[str, Any]]:
        """ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹é€²è¡ŒAIè©•åˆ†"""
        try:
            prompt = self._build_grading_prompt(user_answer, question_text, correct_answer, options, question_type)
            
            if model:
                # å¦‚æœæ˜¯ç¹ªåœ–é¡Œï¼Œéœ€è¦ç‰¹æ®Šè™•ç†base64åœ–ç‰‡
                if isinstance(user_answer, str) and user_answer.startswith('data:image/'):
                    try:
                        import base64
                        from google.generativeai.types import HarmCategory, HarmBlockThreshold
                        
                        # æå–base64æ•¸æ“šéƒ¨åˆ†
                        base64_data = user_answer.split(',')[1] if ',' in user_answer else user_answer
                        
                        # è§£ç¢¼base64æ•¸æ“š
                        image_data = base64.b64decode(base64_data)
                        
                        # å‰µå»ºåœ–ç‰‡å…§å®¹
                        image_content = {
                            "mime_type": "image/png",
                            "data": image_data
                        }
                        
                        # ä½¿ç”¨åœ–ç‰‡å’Œæ–‡å­—æç¤º
                        response = model.generate_content([
                            image_content,
                            prompt
                        ])
                        
                        print(f"ğŸ” ä½¿ç”¨åœ–ç‰‡åˆ†ææ¨¡å¼")
                        
                    except Exception as e:
                        print(f"âŒ åœ–ç‰‡è™•ç†å¤±æ•—ï¼Œä½¿ç”¨æ–‡å­—æ¨¡å¼: {e}")
                        response = model.generate_content(prompt)
                else:
                    response = model.generate_content(prompt)
                

                
                result = self._parse_ai_response(response.text)
                if result:
                    # ç¢ºä¿è©•åˆ†é‚è¼¯ä¸€è‡´æ€§ï¼šåˆ†æ•¸ â‰¥ 85 çš„ç­”æ¡ˆè¢«æ¨™è¨˜ç‚ºæ­£ç¢º
                    score = result.get('score', 0)
                    is_correct = score >= 85
                    # å¦‚æœAIçš„åˆ¤æ–·èˆ‡æˆ‘å€‘çš„æ¨™æº–ä¸ä¸€è‡´ï¼Œé€²è¡Œä¿®æ­£
                    if result.get('is_correct') != is_correct:
                        print(f"âš ï¸ AIåˆ¤æ–·èˆ‡ç³»çµ±æ¨™æº–ä¸ä¸€è‡´ï¼Œé€²è¡Œä¿®æ­£")
                        result['is_correct'] = is_correct
                    
                    return result['is_correct'], result['score'], result['feedback']
                else:
                    print(f"âŒ AIå›æ‡‰è§£æå¤±æ•—")
            
            return False, 0, {'error': 'AIè©•åˆ†å¤±æ•—'}
            
        except Exception as e:
            print(f"âŒ AIè©•åˆ†ç•°å¸¸: {str(e)}")
            return False, 0, {'error': f'è©•åˆ†å¤±æ•—: {str(e)}'}
    
    def _build_grading_prompt(self, user_answer: str, question_text: str, correct_answer: str, 
                             options: List[str], question_type: str) -> str:
        """æ§‹å»ºAIè©•åˆ†æç¤º"""
        # æ ¹æ“šé¡Œç›®é¡å‹æ·»åŠ ç‰¹å®šçš„è©•åˆ†æŒ‡å°
        type_guidance = self._get_type_specific_guidance(question_type)
        
        prompt = f"""
è«‹ä½œç‚ºä¸€ä½å°ˆæ¥­çš„MISèª²ç¨‹æ•™å¸«ï¼Œå°ä»¥ä¸‹å­¸ç”Ÿç­”æ¡ˆé€²è¡Œè©•åˆ†ã€‚

**è©•åˆ†ä»»å‹™èªªæ˜**ï¼š
è«‹è¨˜ä½ä½ åªéœ€è¦è©•åˆ†å­¸ç”Ÿçš„ç­”æ¡ˆï¼Œä¸è¦è©•åˆ†æ­£ç¢ºç­”æ¡ˆã€‚æ­£ç¢ºç­”æ¡ˆåªæ˜¯ç”¨ä¾†åƒè€ƒæ¯”è¼ƒçš„æ¨™æº–ã€‚

**é¡Œç›®è³‡è¨Š**ï¼š
é¡Œç›®é¡å‹ï¼š{question_type}
é¡Œç›®å…§å®¹ï¼š{question_text}

**éœ€è¦è©•åˆ†çš„å…§å®¹**ï¼š
å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}

**åƒè€ƒæ¨™æº–ï¼ˆä¸è¦è©•åˆ†é€™å€‹ï¼‰**ï¼š
æ­£ç¢ºç­”æ¡ˆï¼š{correct_answer}
é¸é …ï¼š{options if options else 'ç„¡'}

**é‡è¦èªªæ˜**ï¼š
- å¦‚æœå­¸ç”Ÿç­”æ¡ˆæ˜¯base64ç·¨ç¢¼çš„åœ–ç‰‡ï¼ˆä»¥data:image/é–‹é ­ï¼‰ï¼Œè«‹ç›´æ¥åˆ†æåœ–ç‰‡å…§å®¹
- å°æ–¼ç¹ªåœ–é¡Œï¼Œè«‹æ ¹æ“šåœ–ç‰‡å…§å®¹èˆ‡é¡Œç›®è¦æ±‚çš„åŒ¹é…åº¦é€²è¡Œè©•åˆ†
- åœ–ç‰‡å…§å®¹æ‡‰è©²èˆ‡é¡Œç›®ç›¸é—œï¼ŒåŒ…å«å¿…è¦çš„åœ–å½¢å…ƒç´ å’Œçµæ§‹

{type_guidance}

**é€šç”¨è©•åˆ†é‡é»**ï¼š
1. **åªè©•åˆ†å­¸ç”Ÿç­”æ¡ˆçš„å…§å®¹**ï¼Œèˆ‡æ­£ç¢ºç­”æ¡ˆé€²è¡Œæ¯”è¼ƒ
2. **å­¸ç”Ÿç­”æ¡ˆå¿…é ˆèˆ‡é¡Œç›®å…§å®¹ç›¸é—œ**ï¼Œä¸èƒ½æ˜¯ç„¡æ„ç¾©çš„æ•¸å­—æˆ–ç¬¦è™Ÿ
3. å¦‚æœå­¸ç”Ÿç­”æ¡ˆèˆ‡é¡Œç›®è¦æ±‚å®Œå…¨ç„¡é—œï¼Œå¿…é ˆçµ¦0åˆ†

**è©•åˆ†è¦æ±‚**ï¼š
1. ä»”ç´°åˆ†æå­¸ç”Ÿç­”æ¡ˆçš„å…§å®¹å’Œé‚è¼¯
2. åˆ¤æ–·ç­”æ¡ˆæ˜¯å¦æ­£ç¢ºæˆ–éƒ¨åˆ†æ­£ç¢º
3. çµ¦å‡º0-100çš„åˆ†æ•¸
4. æä¾›å…·é«”çš„è©•åˆ†ç†ç”±å’Œæ”¹é€²å»ºè­°
5. å¿…é ˆå¡«å¯«å„ªé»ã€éœ€è¦æ”¹é€²çš„åœ°æ–¹å’Œå­¸ç¿’å»ºè­°ï¼Œä¸èƒ½ç•™ç©º

**æ­£ç¢ºæ€§åˆ¤æ–·**ï¼š
- åˆ†æ•¸ â‰¥ 85åˆ†ï¼šç­”æ¡ˆè¢«èªç‚ºæ˜¯æ­£ç¢ºçš„ (is_correct: true)
- åˆ†æ•¸ < 85åˆ†ï¼šç­”æ¡ˆè¢«èªç‚ºæ˜¯ä¸æ­£ç¢ºçš„ (is_correct: false)

è«‹å‹™å¿…ä»¥åš´æ ¼è¦ç¯„çš„JSONæ ¼å¼è¿”å›è©•åˆ†çµæœï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
    "is_correct": true/false,
    "score": åˆ†æ•¸(0-100),
    "feedback": {{
        "explanation": "è©•åˆ†èªªæ˜",
        "strengths": "å„ªé»",
        "weaknesses": "éœ€è¦æ”¹é€²çš„åœ°æ–¹",
        "suggestions": "å­¸ç¿’å»ºè­°"
    }}
}}

**è©•åˆ†ç¤ºä¾‹**ï¼š
é¡Œç›®ï¼šèªªæ˜CPUä¸­Instruction RegisteråŠProgram Counterçš„ç”¨é€”
å­¸ç”Ÿç­”æ¡ˆï¼š10
æ­£ç¢ºç­”æ¡ˆï¼šInstruction Register (IR)ï¼šå­˜æ”¾ç›®å‰æ­£åœ¨åŸ·è¡Œçš„æŒ‡ä»¤ã€‚Program Counter (PC)ï¼šå­˜æ”¾ä¸‹ä¸€å€‹è¦åŸ·è¡Œçš„æŒ‡ä»¤çš„è¨˜æ†¶é«”ä½å€
è©•åˆ†ï¼š0åˆ†ï¼Œis_correct: falseï¼ˆå› ç‚º"10"åªæ˜¯æ•¸å­—ï¼Œèˆ‡é¡Œç›®å®Œå…¨ç„¡é—œï¼Œä¸åŒ…å«ä»»ä½•CPUæ¦‚å¿µï¼‰

é¡Œç›®ï¼šLinuxæª”æ¡ˆç³»çµ±ä¸­ï¼Œ"rwx"ä»£è¡¨ä½•æ„ç¾©ï¼Ÿ
å­¸ç”Ÿç­”æ¡ˆï¼š100
æ­£ç¢ºç­”æ¡ˆï¼šrä»£è¡¨è®€å–æ¬Šé™ï¼Œwä»£è¡¨å¯«å…¥æ¬Šé™ï¼Œxä»£è¡¨åŸ·è¡Œæ¬Šé™
è©•åˆ†ï¼š0åˆ†ï¼Œis_correct: falseï¼ˆå› ç‚º"100"åªæ˜¯æ•¸å­—ï¼Œèˆ‡é¡Œç›®å®Œå…¨ç„¡é—œï¼Œä¸åŒ…å«ä»»ä½•æ¬Šé™æ¦‚å¿µï¼‰

é¡Œç›®ï¼šèªªæ˜CPUä¸­Instruction RegisteråŠProgram Counterçš„ç”¨é€”
å­¸ç”Ÿç­”æ¡ˆï¼šInstruction Registerå­˜æ”¾æŒ‡ä»¤ï¼ŒProgram Counterå­˜æ”¾ä¸‹ä¸€å€‹æŒ‡ä»¤çš„ä½å€
æ­£ç¢ºç­”æ¡ˆï¼šInstruction Register (IR)ï¼šå­˜æ”¾ç›®å‰æ­£åœ¨åŸ·è¡Œçš„æŒ‡ä»¤ã€‚Program Counter (PC)ï¼šå­˜æ”¾ä¸‹ä¸€å€‹è¦åŸ·è¡Œçš„æŒ‡ä»¤çš„è¨˜æ†¶é«”ä½å€
è©•åˆ†ï¼š85åˆ†ï¼Œis_correct: trueï¼ˆå› ç‚ºå­¸ç”Ÿç­”æ¡ˆåŒ…å«äº†æ­£ç¢ºçš„æ ¸å¿ƒæ¦‚å¿µï¼‰
"""
        return prompt
    
    def _get_type_specific_guidance(self, question_type: str) -> str:
        """æ ¹æ“šé¡Œç›®é¡å‹è¿”å›ç‰¹å®šçš„è©•åˆ†æŒ‡å°"""
        
        if question_type == 'draw-answer' or 'draw' in question_type.lower():
            return """
**ç¹ªåœ–é¡Œè©•åˆ†æ¨™æº–**ï¼š
- 90-100åˆ†ï¼šå®Œå…¨æ­£ç¢º - ç¹ªåœ–å®Œå…¨æ­£ç¢ºï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦å…ƒç´ ï¼Œçµæ§‹æ¸…æ™°ï¼Œç¬¦åˆé¡Œç›®è¦æ±‚
- 70-89åˆ†ï¼šæ¥è¿‘æ­£ç¢º - ç¹ªåœ–åŸºæœ¬æ­£ç¢ºï¼Œä¸»è¦å…ƒç´ é½Šå…¨ï¼Œçµæ§‹åˆç†ï¼Œæœ‰è¼•å¾®éŒ¯èª¤
- 50-69åˆ†ï¼šç­”æ¡ˆå°ä¸€åŠ - ç¹ªåœ–åŒ…å«éƒ¨åˆ†å¿…è¦å…ƒç´ ï¼Œä½†çµæ§‹ä¸å®Œæ•´æˆ–æœ‰æ˜é¡¯éŒ¯èª¤
- 0-49åˆ†ï¼šç­”æ¡ˆéŒ¯èª¤ - ç¹ªåœ–èˆ‡é¡Œç›®è¦æ±‚ç„¡é—œï¼Œæˆ–åªæ˜¯éš¨æ„å¡—é´‰ï¼Œæ²’æœ‰å¯¦è³ªå…§å®¹

**ç¹ªåœ–é¡Œç‰¹åˆ¥æ³¨æ„**ï¼š
- å¿…é ˆæª¢æŸ¥ç¹ªåœ–æ˜¯å¦èˆ‡é¡Œç›®å…§å®¹ç›¸é—œ
- å¦‚æœåªæ˜¯éš¨æ„ç•«ç·šã€å¡—é´‰æˆ–èˆ‡é¡Œç›®ç„¡é—œçš„åœ–å½¢ï¼Œå¿…é ˆçµ¦0åˆ†
- ç¹ªåœ–å¿…é ˆåŒ…å«é¡Œç›®è¦æ±‚çš„æ ¸å¿ƒå…ƒç´ å’Œçµæ§‹
- ä¸èƒ½å› ç‚ºå­¸ç”Ÿæœ‰ç•«åœ–å°±çµ¦åˆ†ï¼Œå¿…é ˆçœ‹å…§å®¹æ˜¯å¦æ­£ç¢º
- å¦‚æœç¹ªåœ–å…§å®¹èˆ‡æ­£ç¢ºç­”æ¡ˆå®Œå…¨ä¸ç¬¦ï¼Œå¿…é ˆçµ¦ä½åˆ†ï¼ˆ0-39åˆ†ï¼‰
- å°æ–¼ç©ºç™½æˆ–å¹¾ä¹ç©ºç™½çš„åœ–ç‰‡ï¼Œå¿…é ˆçµ¦0åˆ†
- å°æ–¼åªæœ‰ç°¡å–®ç·šæ¢æˆ–ç„¡æ„ç¾©åœ–å½¢çš„åœ–ç‰‡ï¼Œæœ€å¤šçµ¦30åˆ†
- è©•åˆ†è¦å®¢è§€å…¬æ­£ï¼Œåš´æ ¼æŒ‰ç…§ç¹ªåœ–å…§å®¹èˆ‡é¡Œç›®è¦æ±‚çš„åŒ¹é…åº¦çµ¦åˆ†
- å°æ–¼è¤‡é›œçš„ç¹ªåœ–é¡Œç›®ï¼Œè¦ä»”ç´°åˆ†ææ¯å€‹å¿…è¦å…ƒç´ æ˜¯å¦æ­£ç¢ºå‘ˆç¾

**åš´æ ¼è©•åˆ†è¦æ±‚**ï¼š
- å°æ–¼æ•¸å­¸è¨ˆç®—é¡Œçš„ç¹ªåœ–ï¼Œå¿…é ˆåŒ…å«å…·é«”çš„è¨ˆç®—éç¨‹å’Œçµæœ
- å¦‚æœåªæ˜¯ç•«äº†å¹¾æ¢ç·šæˆ–ç°¡å–®åœ–å½¢ï¼Œæ²’æœ‰æ•¸å­¸å…§å®¹ï¼Œæœ€å¤šçµ¦20åˆ†
- å¿…é ˆæª¢æŸ¥ç¹ªåœ–æ˜¯å¦çœŸçš„å›ç­”äº†é¡Œç›®çš„å•é¡Œ
- å°æ–¼éš¨æ„å¡—é´‰ã€ç„¡æ„ç¾©ç·šæ¢ã€æˆ–èˆ‡é¡Œç›®å®Œå…¨ç„¡é—œçš„å…§å®¹ï¼Œå¿…é ˆçµ¦0åˆ†
- è©•åˆ†æ™‚è¦éå¸¸åš´æ ¼ï¼Œå¯§å¯çµ¦ä½åˆ†ä¹Ÿä¸è¦çµ¦é«˜åˆ†
"""
        
        elif question_type == 'coding-answer' or 'code' in question_type.lower():
            return """
**ç¨‹å¼æ’°å¯«é¡Œè©•åˆ†æ¨™æº–**ï¼š
- 90-100åˆ†ï¼šå®Œå…¨æ­£ç¢º - ç¨‹å¼ç¢¼å®Œå…¨æ­£ç¢ºï¼Œé‚è¼¯æ¸…æ™°ï¼Œèªæ³•æ­£ç¢ºï¼Œèƒ½æ­£å¸¸é‹è¡Œ
- 70-89åˆ†ï¼šæ¥è¿‘æ­£ç¢º - ç¨‹å¼ç¢¼åŸºæœ¬æ­£ç¢ºï¼Œé‚è¼¯åˆç†ï¼Œæœ‰è¼•å¾®èªæ³•éŒ¯èª¤ä½†ä¸å½±éŸ¿åŠŸèƒ½
- 50-69åˆ†ï¼šç­”æ¡ˆå°ä¸€åŠ - ç¨‹å¼ç¢¼éƒ¨åˆ†æ­£ç¢ºï¼Œé‚è¼¯æœ‰å•é¡Œä½†åŸºæœ¬çµæ§‹æ­£ç¢º
- 0-49åˆ†ï¼šç­”æ¡ˆéŒ¯èª¤ - ç¨‹å¼ç¢¼èˆ‡é¡Œç›®è¦æ±‚ç„¡é—œï¼Œæˆ–å®Œå…¨ç„¡æ³•é‹è¡Œ

**ç¨‹å¼é¡Œç‰¹åˆ¥æ³¨æ„**ï¼š
- å¿…é ˆæª¢æŸ¥ç¨‹å¼ç¢¼æ˜¯å¦èˆ‡é¡Œç›®è¦æ±‚ç›¸é—œ
- å¦‚æœåªæ˜¯éš¨æ„è¼¸å…¥æ–‡å­—æˆ–ç„¡é—œä»£ç¢¼ï¼Œå¿…é ˆçµ¦0åˆ†
- ç¨‹å¼ç¢¼å¿…é ˆèƒ½è§£æ±ºé¡Œç›®æå‡ºçš„å•é¡Œ
- èªæ³•æ­£ç¢ºæ€§å’Œé‚è¼¯æ­£ç¢ºæ€§éƒ½è¦è€ƒæ…®
- å°æ–¼"hello world"ç­‰ç„¡é—œæ–‡å­—ï¼Œå¿…é ˆçµ¦0åˆ†
- å°æ–¼æ²’æœ‰å‡½æ•¸å®šç¾©ã€æ²’æœ‰é‚è¼¯çµæ§‹çš„ä»£ç¢¼ï¼Œæœ€å¤šçµ¦10åˆ†
"""
        
        elif question_type in ['short-answer', 'long-answer', 'fill-in-the-blank']:
            return """
**å•ç­”é¡Œè©•åˆ†æ¨™æº–**ï¼š
- 90-100åˆ†ï¼šå®Œå…¨æ­£ç¢º - ç­”æ¡ˆå®Œå…¨æ­£ç¢ºï¼Œå…§å®¹å®Œæ•´ä¸”æº–ç¢ºï¼ŒåŒ…å«æ‰€æœ‰é—œéµæ¦‚å¿µ
- 70-89åˆ†ï¼šæ¥è¿‘æ­£ç¢º - ç­”æ¡ˆåŸºæœ¬æ­£ç¢ºï¼Œä¸»è¦æ¦‚å¿µæ­£ç¢ºä½†æœ‰å°éŒ¯èª¤æˆ–éºæ¼
- 50-69åˆ†ï¼šç­”æ¡ˆå°ä¸€åŠ - ç­”æ¡ˆåŒ…å«éƒ¨åˆ†é—œéµæ¦‚å¿µä½†ç†è§£ä¸å¤ æ·±å…¥
- 0-49åˆ†ï¼šç­”æ¡ˆéŒ¯èª¤ - ç­”æ¡ˆéŒ¯èª¤ï¼Œä¸»è¦æ¦‚å¿µéŒ¯èª¤æˆ–èˆ‡é¡Œç›®ç„¡é—œ

**å•ç­”é¡Œç‰¹åˆ¥æ³¨æ„**ï¼š
- å­¸ç”Ÿç­”æ¡ˆå¿…é ˆåŒ…å«æ­£ç¢ºç­”æ¡ˆçš„æ ¸å¿ƒæ¦‚å¿µå’Œé—œéµä¿¡æ¯
- å¦‚æœå­¸ç”Ÿåªå›ç­”æ•¸å­—ã€ç¬¦è™Ÿæˆ–èˆ‡é¡Œç›®ç„¡é—œçš„å…§å®¹ï¼Œå¿…é ˆçµ¦0åˆ†
- ç­”æ¡ˆå¿…é ˆèˆ‡é¡Œç›®å…§å®¹æœ‰å¯¦è³ªé—œè¯
- ä¸èƒ½å› ç‚ºå­¸ç”ŸåŠªåŠ›å°±çµ¦é«˜åˆ†ï¼Œå¿…é ˆçœ‹å…§å®¹æ­£ç¢ºæ€§
- å°æ–¼"æ¸¬è©¦"ã€"ä¸çŸ¥é“"ã€"éš¨ä¾¿"ç­‰ç„¡é—œå›ç­”ï¼Œå¿…é ˆçµ¦0åˆ†
- å°æ–¼åªæœ‰ä¸€å€‹æ•¸å­—æˆ–ç¬¦è™Ÿçš„å›ç­”ï¼Œå¿…é ˆçµ¦0åˆ†
"""
        
        elif question_type in ['single-choice', 'multiple-choice', 'true-false']:
            return """
**é¸æ“‡é¡Œè©•åˆ†æ¨™æº–**ï¼š
- 100åˆ†ï¼šç­”æ¡ˆå®Œå…¨æ­£ç¢º
- 0åˆ†ï¼šç­”æ¡ˆéŒ¯èª¤æˆ–æœªä½œç­”

**é¸æ“‡é¡Œç‰¹åˆ¥æ³¨æ„**ï¼š
- é¸æ“‡é¡Œåªæœ‰å°éŒ¯ï¼Œæ²’æœ‰éƒ¨åˆ†åˆ†æ•¸
- å¿…é ˆèˆ‡æ­£ç¢ºç­”æ¡ˆå®Œå…¨ä¸€è‡´æ‰ç®—æ­£ç¢º
- å¦‚æœç­”æ¡ˆæ ¼å¼ä¸æ­£ç¢ºæˆ–ç„¡æ³•è­˜åˆ¥ï¼Œè¦–ç‚ºéŒ¯èª¤
- å°æ–¼ç©ºç™½ç­”æ¡ˆæˆ–ç„¡é—œå›ç­”ï¼Œå¿…é ˆçµ¦0åˆ†
- åš´æ ¼æŒ‰ç…§æ­£ç¢ºç­”æ¡ˆé€²è¡Œè©•åˆ†ï¼Œä¸å…è¨±ä»»ä½•åå·®
- ç­”æ¡ˆå¿…é ˆå®Œå…¨åŒ¹é…ï¼ŒåŒ…æ‹¬å¤§å°å¯«ã€æ ¼å¼ã€é †åºç­‰
"""
        
        else:
            return """
**é€šç”¨è©•åˆ†æ¨™æº–**ï¼š
- 90-100åˆ†ï¼šå®Œå…¨æ­£ç¢º - ç­”æ¡ˆå®Œå…¨æ­£ç¢ºï¼Œå…§å®¹å®Œæ•´ä¸”æº–ç¢º
- 70-89åˆ†ï¼šæ¥è¿‘æ­£ç¢º - ç­”æ¡ˆåŸºæœ¬æ­£ç¢ºï¼Œä¸»è¦æ¦‚å¿µæ­£ç¢ºä½†æœ‰å°éŒ¯èª¤
- 50-69åˆ†ï¼šç­”æ¡ˆå°ä¸€åŠ - ç­”æ¡ˆåŒ…å«éƒ¨åˆ†æ­£ç¢ºæ¦‚å¿µä½†ç†è§£ä¸å¤ æ·±å…¥
- 0-49åˆ†ï¼šç­”æ¡ˆéŒ¯èª¤ - ç­”æ¡ˆéŒ¯èª¤ï¼Œä¸»è¦æ¦‚å¿µéŒ¯èª¤æˆ–èˆ‡é¡Œç›®ç„¡é—œ

**ç‰¹åˆ¥æ³¨æ„**ï¼š
- è©•åˆ†è¦å®¢è§€å…¬æ­£ï¼Œä¸èƒ½å› ç‚ºå­¸ç”ŸåŠªåŠ›å°±çµ¦é«˜åˆ†
- å¦‚æœå­¸ç”Ÿç­”æ¡ˆèˆ‡é¡Œç›®å…§å®¹å®Œå…¨ç„¡é—œï¼Œå¿…é ˆçµ¦0åˆ†
- åªæœ‰ç•¶å­¸ç”Ÿç­”æ¡ˆåœ¨å…§å®¹ä¸Šèˆ‡é¡Œç›®æœ‰å¯¦è³ªé—œè¯æ™‚ï¼Œæ‰èƒ½çµ¦åˆ†æ•¸
- å°æ–¼ç„¡æ„ç¾©çš„æ•¸å­—ã€ç¬¦è™Ÿã€é‡è¤‡å­—ç¬¦ï¼Œå¿…é ˆçµ¦0åˆ†
- å°æ–¼"ä¸çŸ¥é“"ã€"éš¨ä¾¿"ã€"æ¸¬è©¦"ç­‰ç„¡é—œå›ç­”ï¼Œå¿…é ˆçµ¦0åˆ†
"""
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æAIå›æ‡‰"""
        try:
            # å˜—è©¦æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                
                # é©—è­‰å¿…è¦å­—æ®µ
                if all(key in result for key in ['is_correct', 'score', 'feedback']):
                    # ç¢ºä¿ feedback å­—æ®µå®Œæ•´
                    feedback = result.get('feedback', {})
                    if not feedback.get('strengths') or feedback.get('strengths') == 'ç„¡':
                        feedback['strengths'] = 'å‹‡æ–¼å˜—è©¦ï¼ŒèªçœŸä½œç­”'
                    if not feedback.get('weaknesses') or feedback.get('weaknesses') == 'ç„¡':
                        feedback['weaknesses'] = 'éœ€è¦åŠ å¼·å°ç›¸é—œæ¦‚å¿µçš„ç†è§£'
                    if not feedback.get('suggestions') or feedback.get('suggestions') == 'ç„¡':
                        feedback['suggestions'] = 'å»ºè­°è¤‡ç¿’ç›¸é—œç« ç¯€ï¼Œå¤šåšç·´ç¿’é¡Œ'
                    
                    result['feedback'] = feedback
                    return result
                else:
                    print("âš ï¸ AIå›æ‡‰ç¼ºå°‘å¿…è¦å­—æ®µ")
                    return None
            else:
                print("âš ï¸ ç„¡æ³•å¾AIå›æ‡‰ä¸­æå–JSON")
                return None
                
        except Exception as e:
            print(f"âš ï¸ è§£æAIå›æ‡‰å¤±æ•—: {e}")
            return None

# å‰µå»ºå…¨å±€å¯¦ä¾‹
grader = AnswerGrader()

def batch_grade_ai_questions(questions_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ‰¹é‡æ‰¹æ”¹AIé¡Œç›®çš„ä¾¿æ·å‡½æ•¸"""
    return grader.batch_grade_ai_questions(questions_data)
