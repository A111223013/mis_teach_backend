"""
RAG å‘é‡è³‡æ–™åº«å»ºç½®æ¨¡çµ„
è² è²¬è™•ç† PDF æ–‡ä»¶ã€å»ºç«‹å‘é‡è³‡æ–™åº«ã€çŸ¥è­˜é»æå–ç­‰åŠŸèƒ½
"""

import os
import json
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import fitz  # PyMuPDF
import google.generativeai as genai
from .config import Config

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGBuilder:
    """RAG å‘é‡è³‡æ–™åº«å»ºç½®å™¨"""
    
    def __init__(self, config: Config):
        """åˆå§‹åŒ–å»ºç½®å™¨"""
        self.config = config
        self.embedding_model = None
        self.chroma_client = None
        self.collection = None
        self._init_components()
    
    def _init_components(self):
        """åˆå§‹åŒ–çµ„ä»¶"""
        try:
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            self.embedding_model = SentenceTransformer(
                self.config.EMBEDDING_MODEL_NAME,
                device=self.config.DEVICE
            )
            
            # åˆå§‹åŒ– ChromaDB
            self.chroma_client = chromadb.PersistentClient(
                path=self.config.CHROMA_DB_PATH,
                settings=Settings(anonymized_telemetry=False)
            )
            
            # ç²å–æˆ–å‰µå»ºé›†åˆ
            try:
                self.collection = self.chroma_client.get_collection(
                    name=self.config.COLLECTION_NAME
                )
            except:
                self.collection = self.chroma_client.create_collection(
                    name=self.config.COLLECTION_NAME,
                    metadata={"description": "MISæ•™å­¸çŸ¥è­˜åº«"}
                )
            
            # é…ç½® Gemini API
            if self.config.GEMINI_API_KEY:
                genai.configure(api_key=self.config.GEMINI_API_KEY)
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–çµ„ä»¶å¤±æ•—: {e}")
            raise
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """å¾ PDF æå–æ–‡æœ¬"""
        try:
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        except Exception as e:
            logger.error(f"âŒ PDF æ–‡æœ¬æå–å¤±æ•— {pdf_path}: {e}")
            return ""
    
    def extract_knowledge_points(self, text: str, chapter_info: str = "") -> List[Dict]:
        """ä½¿ç”¨ AI æå–çŸ¥è­˜é»"""
        try:
            prompt = f"""
            è«‹å¾ä»¥ä¸‹æ•™å­¸ææ–™ä¸­æå–çµæ§‹åŒ–çš„çŸ¥è­˜é»ã€‚
            
            ç« ç¯€è³‡è¨Šï¼š{chapter_info}
            
            æ•™å­¸å…§å®¹ï¼š
            {text[:3000]}  # é™åˆ¶é•·åº¦é¿å…è¶…å‡º token é™åˆ¶
            
            è«‹ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
            {{
                "knowledge_points": [
                    {{
                        "title": "çŸ¥è­˜é»æ¨™é¡Œ",
                        "content": "è©³ç´°å…§å®¹èªªæ˜",
                        "keywords": ["é—œéµè©1", "é—œéµè©2"],
                        "difficulty": 1-5,
                        "category": "åˆ†é¡",
                        "examples": ["ç¯„ä¾‹1", "ç¯„ä¾‹2"]
                    }}
                ]
            }}
            
            è«‹ç¢ºä¿è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚
            """
            
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(prompt)
            
            # è§£æ JSON å›æ‡‰
            try:
                result = json.loads(response.text)
                return result.get('knowledge_points', [])
            except json.JSONDecodeError:
                # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œè¿”å›åŸºæœ¬çµæ§‹
                return [{
                    "title": f"çŸ¥è­˜é» - {chapter_info}",
                    "content": text[:500],
                    "keywords": [],
                    "difficulty": 3,
                    "category": "ä¸€èˆ¬",
                    "examples": []
                }]
                
        except Exception as e:
            logger.error(f"âŒ çŸ¥è­˜é»æå–å¤±æ•—: {e}")
            return []
    
    def process_pdf_files(self, pdf_directory: str) -> Dict[str, Any]:
        """è™•ç† PDF æ–‡ä»¶ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«"""
        results = {
            "processed_files": 0,
            "total_knowledge_points": 0,
            "errors": [],
            "start_time": datetime.now().isoformat()
        }
        
        try:
            pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]
            logger.info(f"ğŸ” æ‰¾åˆ° {len(pdf_files)} å€‹ PDF æ–‡ä»¶")
            
            all_knowledge_points = []
            
            for pdf_file in pdf_files:
                try:
                    pdf_path = os.path.join(pdf_directory, pdf_file)
                    logger.info(f"ğŸ“– è™•ç†æ–‡ä»¶: {pdf_file}")
                    
                    # æå–æ–‡æœ¬
                    text = self.extract_text_from_pdf(pdf_path)
                    if not text.strip():
                        logger.warning(f"âš ï¸ æ–‡ä»¶ç„¡å…§å®¹: {pdf_file}")
                        continue
                    
                    # æå–çŸ¥è­˜é»
                    chapter_info = pdf_file.replace('.pdf', '')
                    knowledge_points = self.extract_knowledge_points(text, chapter_info)
                    
                    # ç‚ºæ¯å€‹çŸ¥è­˜é»æ·»åŠ å…ƒæ•¸æ“š
                    for i, kp in enumerate(knowledge_points):
                        kp.update({
                            "source_file": pdf_file,
                            "chapter": chapter_info,
                            "id": f"{chapter_info}_{i}",
                            "processed_time": datetime.now().isoformat()
                        })
                        all_knowledge_points.append(kp)
                    
                    results["processed_files"] += 1
                    results["total_knowledge_points"] += len(knowledge_points)
                    
                    logger.info(f"âœ… å®Œæˆè™•ç†: {pdf_file} ({len(knowledge_points)} å€‹çŸ¥è­˜é»)")
                    
                except Exception as e:
                    error_msg = f"è™•ç†æ–‡ä»¶ {pdf_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
                    logger.error(f"âŒ {error_msg}")
                    results["errors"].append(error_msg)
            
            # å»ºç«‹å‘é‡è³‡æ–™åº«
            if all_knowledge_points:
                self._build_vector_database(all_knowledge_points)
                
                # ä¿å­˜çŸ¥è­˜é»åˆ° JSON æ–‡ä»¶
                output_path = os.path.join(self.config.OUTPUT_DIR, "knowledge_points.json")
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(all_knowledge_points, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ’¾ çŸ¥è­˜é»å·²ä¿å­˜åˆ°: {output_path}")
            
            results["end_time"] = datetime.now().isoformat()
            results["success"] = True
            
        except Exception as e:
            logger.error(f"âŒ è™•ç† PDF æ–‡ä»¶å¤±æ•—: {e}")
            results["success"] = False
            results["error"] = str(e)
        
        return results
    
    def _build_vector_database(self, knowledge_points: List[Dict]):
        """å»ºç«‹å‘é‡è³‡æ–™åº«"""
        try:
            logger.info("ğŸ”„ å»ºç«‹å‘é‡è³‡æ–™åº«...")
            
            # æº–å‚™æ–‡æœ¬å’Œå…ƒæ•¸æ“š
            texts = []
            metadatas = []
            ids = []
            
            for kp in knowledge_points:
                # çµ„åˆæ–‡æœ¬ç”¨æ–¼åµŒå…¥
                combined_text = f"{kp['title']} {kp['content']} {' '.join(kp.get('keywords', []))}"
                texts.append(combined_text)
                
                # æº–å‚™å…ƒæ•¸æ“š
                metadata = {
                    "title": kp['title'],
                    "category": kp.get('category', ''),
                    "difficulty": kp.get('difficulty', 3),
                    "source_file": kp.get('source_file', ''),
                    "chapter": kp.get('chapter', '')
                }
                metadatas.append(metadata)
                ids.append(kp['id'])
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            logger.info("ğŸ”„ ç”ŸæˆåµŒå…¥å‘é‡...")
            embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
            
            # æ·»åŠ åˆ° ChromaDB
            logger.info("ğŸ”„ æ·»åŠ åˆ°å‘é‡è³‡æ–™åº«...")
            self.collection.add(
                embeddings=embeddings.tolist(),
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼Œå…± {len(texts)} å€‹çŸ¥è­˜é»")
            
        except Exception as e:
            logger.error(f"âŒ å»ºç«‹å‘é‡è³‡æ–™åº«å¤±æ•—: {e}")
            raise
    
    def search_knowledge(self, query: str, n_results: int = 5) -> List[Dict]:
        """æœç´¢çŸ¥è­˜åº«"""
        try:
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            query_embedding = self.embedding_model.encode([query])
            
            # æœç´¢ç›¸ä¼¼çŸ¥è­˜é»
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=n_results
            )
            
            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            for i in range(len(results['documents'][0])):
                formatted_results.append({
                    "content": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "similarity": 1 - results['distances'][0][i] if 'distances' in results else 0.0
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è­˜æœç´¢å¤±æ•—: {e}")
            return []
    
    def get_database_stats(self) -> Dict[str, Any]:
        """ç²å–è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        try:
            count = self.collection.count()
            return {
                "total_knowledge_points": count,
                "collection_name": self.config.COLLECTION_NAME,
                "embedding_model": self.config.EMBEDDING_MODEL_NAME,
                "database_path": self.config.CHROMA_DB_PATH
            }
        except Exception as e:
            logger.error(f"âŒ ç²å–çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
            return {}
