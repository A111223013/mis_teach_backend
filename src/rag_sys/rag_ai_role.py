import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import google.generativeai as genai

# å°å…¥é…ç½®
try:
    from . import config
    from .config import Config
    GEMINI_AVAILABLE = True
except ImportError:
    import config
    from config import Config
    GEMINI_AVAILABLE = True

# å»¶é²å°å…¥ RAGBuilder ä»¥é¿å…å¾ªç’°å°å…¥
RAGBuilder = None

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==================== MultiAITutor é¡åˆ¥ ====================

class MultiAITutor:
    """Geminiæ™ºèƒ½æ•™å¸«"""

    def __init__(self, rag_processor=None):
        """åˆå§‹åŒ–æ•™å¸«"""
        # è¨­ç½®æ—¥èªŒç´šåˆ¥
        logging.getLogger('sentence_transformers').setLevel(logging.WARNING)
        logging.getLogger('chromadb').setLevel(logging.WARNING)

        # åˆå§‹åŒ–AIå›æ‡‰å™¨
        self.ai_responder = AIResponder(language='chinese', rag_processor=rag_processor)

        # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«é€£æ¥
        self._init_vector_database()

        # åˆå§‹åŒ–Geminiæ¨¡å‹
        self._init_gemini()

        # æ•™å­¸æœƒè©±ç®¡ç†
        self.learning_sessions = {}  # å­˜å„²å­¸ç¿’æœƒè©±

        # æ ¸å¿ƒè®Šæ•¸
        self.original_question = ""
        self.context = ""
        self.topic_knowledge = ""

        # æ•™å­¸é¢¨æ ¼æç¤ºè©
        self.TEACHER_STYLE = """ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„è³‡ç®¡ç³»æ•™æˆï¼Œæ­£åœ¨ä¸€å°ä¸€è¼”å°å­¸ç”Ÿï¼Œå¹«åŠ©å­¸ç”Ÿé€éé€æ­¥å¼•å°æ–¹å¼ç†è§£è€ƒé¡Œèˆ‡è³‡ç®¡ç³»ç›¸é—œçŸ¥è­˜ï¼Œç¢ºä¿å­¸ç”ŸçœŸæ­£æŒæ¡æ¦‚å¿µï¼Œè€Œä¸åªæ˜¯èƒŒèª¦ç­”æ¡ˆã€‚


**ä½ çš„æ•™å­¸åŸå‰‡**ï¼š
- **å¼•å°å¼å°è©±**ï¼šé€éä¸€æ­¥æ­¥æå•ï¼Œå¼•å°å­¸ç”Ÿè‡ªè¡Œæ€è€ƒä¸¦å¾—å‡ºç­”æ¡ˆï¼Œè€Œéç›´æ¥çµ¦äºˆè§£ç­”ã€‚
- **é‡å°æ€§åé¥‹**ï¼šç²¾æº–è©•åƒ¹å­¸ç”Ÿå›ç­”ï¼Œè‚¯å®šå…¶æ­£ç¢ºéƒ¨åˆ†ï¼Œä¸¦ç¦®è²Œåœ°æŒ‡å‡ºéœ€è¦è£œå……æˆ–ç³¾æ­£ä¹‹è™•ã€‚
- **æ¦‚å¿µæ‹†è§£èˆ‡é¡æ¯”**ï¼šç•¶å­¸ç”Ÿä¸ç†è§£æ™‚ï¼Œå°‡è¤‡é›œæ¦‚å¿µæ‹†è§£ç‚ºæ›´å°æ­¥é©Ÿï¼Œä¸¦ä½¿ç”¨ç”Ÿæ´»åŒ–ä¾‹å­æˆ–é¡æ¯”å¹«åŠ©ç†è§£ã€‚
- **å‹•æ…‹èª¿æ•´é›£åº¦**ï¼šæ ¹æ“šå­¸ç”Ÿå›ç­”åˆ¤æ–·å…¶æŒæ¡åº¦ï¼Œéˆæ´»èª¿æ•´å•é¡Œé›£åº¦ï¼Œä¿ƒé€²æ·±åº¦å­¸ç¿’ã€‚
- **é¿å…é‡è¤‡**ï¼šå›ç­”ä¸­çµ•ä¸é‡è¤‡å­¸ç”Ÿå·²ç¶“èªªéæˆ–ä½ ä¹‹å‰èªªéçš„å…§å®¹ï¼ŒåŠ›æ±‚ç°¡æ½”æœ‰æ•ˆã€‚

**å›æ‡‰è¦æ±‚**ï¼š
- èªæ°£è¦ªåˆ‡è‡ªç„¶ï¼Œå¦‚åŒçœŸæ­£çš„è€å¸«ã€‚
- å›ç­”å¾Œï¼Œå¿…é ˆæå‡ºä¸€å€‹æ¸…æ™°çš„å¼•å°å•é¡Œï¼Œæ¨é€²å­¸ç”Ÿå°ç•¶å‰æ¦‚å¿µçš„ç†è§£ã€‚
- åš´ç¦ä½¿ç”¨ä»»ä½•æ ¼å¼åŒ–æ¨™é¡Œï¼ˆå¦‚ "ğŸ’¡ è©³ç´°å›ç­”"ï¼‰ï¼Œç›´æ¥ä»¥è‡ªç„¶æ®µè½å‘ˆç¾å…§å®¹ã€‚
- ç¦æ­¢æš´éœ²ä½ çš„æ€è€ƒéç¨‹ã€‚

ç¾åœ¨ï¼Œè®“æˆ‘å€‘é–‹å§‹ä¸€å ´æœ‰æ·±åº¦çš„å­¸ç¿’å°è©±ã€‚
"""

    def _init_gemini(self):
        """åˆå§‹åŒ–Geminiæ¨¡å‹"""
        if not GEMINI_AVAILABLE:
            raise ImportError("Geminiä¸å¯ç”¨ï¼Œè«‹å®‰è£google-generativeai")

        try:
            # å¾GEMINI_CONFIGä¸­ç²å–API key
            api_key = config.GEMINI_CONFIG.get('api_key')
            if not api_key:
                raise ValueError("æœªè¨­ç½®Gemini API Key")

            genai.configure(api_key=api_key)
            self.gemini_model = genai.GenerativeModel(config.GEMINI_CONFIG.get('model', 'gemini-1.5-flash'))
            self.model_config = config.GEMINI_CONFIG
        except Exception as e:
            logging.error(f"âŒ Geminiåˆå§‹åŒ–å¤±æ•—: {e}")
            raise RuntimeError(f"Geminiåˆå§‹åŒ–å¤±æ•—: {e}")

    def _init_vector_database(self):
        """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«é€£æ¥"""
        try:
            import chromadb
            from chromadb.config import Settings

            self.chroma_client = chromadb.PersistentClient(
                path=config.CHROMA_DB_PATH,
                settings=Settings(anonymized_telemetry=False)
            )

            # å˜—è©¦ç²å–ç¾æœ‰é›†åˆ
            try:
                self.collection = self.chroma_client.get_collection(config.COLLECTION_NAME)
                count = self.collection.count()
            except Exception:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°ç¾æœ‰å‘é‡è³‡æ–™åº«")
                self.collection = None

        except Exception as e:
            logger.error(f"âŒ å‘é‡è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            self.collection = None

    def _should_search_database(self, question: str) -> bool:
        """æ™ºèƒ½åˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢å‘é‡è³‡æ–™åº«"""
        try:
            # ä½¿ç”¨Geminiåˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢è³‡æ–™åº«
            prompt = f"""
ä½ æ˜¯ä¸€å€‹æ™ºèƒ½åŠ©ç†ï¼Œéœ€è¦åˆ¤æ–·å­¸ç”Ÿçš„å•é¡Œæ˜¯å¦éœ€è¦æŸ¥è©¢MISï¼ˆè³‡è¨Šç®¡ç†ç³»ï¼‰çš„å­¸è¡“è³‡æ–™åº«ã€‚

å•é¡Œï¼šã€Œ{question}ã€

è«‹ä»”ç´°åˆ†æé€™å€‹å•é¡Œï¼Œç„¶å¾Œæ ¹æ“šä»¥ä¸‹æ¨™æº–åˆ¤æ–·ï¼š

**éœ€è¦æŸ¥è©¢è³‡æ–™åº«çš„æƒ…æ³**ï¼ˆå­¸è¡“å•é¡Œï¼‰ï¼š
- è©¢å•MISç›¸é—œçš„æŠ€è¡“æ¦‚å¿µï¼šä½œæ¥­ç³»çµ±ã€è³‡æ–™åº«ã€ç¶²è·¯ã€æ¼”ç®—æ³•ã€ç¨‹å¼è¨­è¨ˆ
- è©¢å•å…·é«”æŠ€è¡“è¡“èªï¼šFIFOã€LIFOã€æ­»é–ã€æ’ç¨‹ã€è¨˜æ†¶é«”ç®¡ç†ç­‰
- è©¢å•ç³»çµ±åˆ†æã€è³‡è¨Šç®¡ç†ã€é›»è…¦ç§‘å­¸ç›¸é—œæ¦‚å¿µ
- ä»¥ã€Œä»€éº¼æ˜¯...ã€é–‹é ­çš„æŠ€è¡“å•é¡Œ
- è©¢å•æŠ€è¡“åŸç†ã€æ–¹æ³•ã€æ‡‰ç”¨çš„å•é¡Œ

**ä¸éœ€è¦æŸ¥è©¢è³‡æ–™åº«çš„æƒ…æ³**ï¼ˆéå­¸è¡“å•é¡Œï¼‰ï¼š
- å•å€™èªï¼šä½ å¥½ã€æ—©å®‰ã€æ™šå®‰
- è‡ªæˆ‘ä»‹ç´¹ç›¸é—œï¼šä½ æ˜¯èª°ã€è‡ªæˆ‘ä»‹ç´¹ã€ä½ å«ä»€éº¼åå­—
- æ„Ÿè¬èªï¼šè¬è¬ã€ä¸å®¢æ°£
- æ—¥å¸¸å°è©±ï¼šå¤©æ°£ã€å¿ƒæƒ…ã€é–’èŠ
- åŸºæœ¬æ•¸å­¸ï¼š1+1ã€ç°¡å–®è¨ˆç®—
- ä¸€èˆ¬å¸¸è­˜ï¼šä¸æ¶‰åŠMISå°ˆæ¥­çŸ¥è­˜çš„å•é¡Œ
-å›ç­”AIçš„æå•

è«‹åªå›ç­”ã€Œéœ€è¦æŸ¥è©¢ã€æˆ–ã€Œä¸éœ€è¦æŸ¥è©¢ã€ï¼Œä¸è¦è§£é‡‹ã€‚
"""

            response = self.gemini_model.generate_content(prompt)
            if response and hasattr(response, 'text') and response.text:
                result = response.text.strip()

                # ä¿®å¾©å­—ç¬¦ä¸²åŒ¹é…é‚è¼¯ - å…ˆæª¢æŸ¥ã€Œä¸éœ€è¦æŸ¥è©¢ã€
                should_search = False  # é è¨­ä¸æŸ¥è©¢

                if "ä¸éœ€è¦æŸ¥è©¢" in result:
                    should_search = False
                elif "éœ€è¦æŸ¥è©¢" in result:
                    should_search = True
                else:
                    should_search = False  # é è¨­ä¸æŸ¥è©¢
                return should_search
            else:
                logging.warning("âš ï¸ AIç„¡å›æ‡‰ï¼Œä½¿ç”¨å‚™ç”¨åˆ¤æ–·")
                return False
        except Exception as e:
            logging.warning(f"AIåˆ¤æ–·å¤±æ•—: {e}")
            # é è¨­æƒ…æ³ä¸‹ï¼Œåªå°æ˜ç¢ºçš„å­¸è¡“é—œéµè©é€²è¡ŒæŸ¥è©¢
            academic_keywords = [
                'ä½œæ¥­ç³»çµ±', 'operating system', 'è³‡æ–™åº«', 'database',
                'ç¶²è·¯', 'network', 'FIFO', 'LIFO', 'æ¼”ç®—æ³•', 'algorithm',
                'ç¨‹å¼è¨­è¨ˆ', 'programming', 'æ­»é–', 'deadlock', 'æ’ç¨‹', 'scheduling',
                'è¨˜æ†¶é«”', 'memory', 'cpu', 'è™•ç†å™¨', 'processor'
            ]
            # æ’é™¤ä¸€èˆ¬å°è©±é—œéµè©
            general_keywords = [
                'ä½ å¥½', 'hello', 'ä½ æ˜¯èª°', 'who are you', 'è¬è¬', 'thank you',
                'è‡ªæˆ‘ä»‹ç´¹', 'introduce', 'å¤©æ°£', 'weather', 'å¿ƒæƒ…', 'mood'
            ]

            question_lower = question.lower()

            # å¦‚æœåŒ…å«ä¸€èˆ¬å°è©±é—œéµè©ï¼Œä¸æŸ¥è©¢
            if any(keyword in question_lower for keyword in general_keywords):
                return False

            # å¦‚æœåŒ…å«å­¸è¡“é—œéµè©ï¼ŒæŸ¥è©¢
            should_search = any(keyword in question_lower for keyword in academic_keywords)
            return should_search

    def get_topic_knowledge(self, question: str) -> str:
        """æ™ºèƒ½ç²å–ä¸»é¡Œç›¸é—œçŸ¥è­˜"""
        try:
            # æ™ºèƒ½åˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢å‘é‡è³‡æ–™åº«
            if not self._should_search_database(question):
                return ""

            # å…ˆç¿»è­¯æˆè‹±æ–‡æœç´¢ï¼Œå› ç‚ºå‘é‡è³‡æ–™åº«æ˜¯è‹±æ–‡æ•™æ
            english_question = self._translate_to_english(question)

            # ä½¿ç”¨å‘é‡è³‡æ–™åº«æœç´¢
            search_results = self.search_knowledge(english_question, top_k=3)

            if search_results:
                # æå–å‰3å€‹çµæœçš„å…§å®¹
                knowledge = "\n".join([
                    result.get('content', '')[:400]
                    for result in search_results[:4]
                ])
                return knowledge
            else:
                logging.info("âš ï¸ æœªæ‰¾åˆ°ç›¸é—œçŸ¥è­˜é»")
        except Exception as e:
            logging.warning(f"ç²å–ä¸»é¡ŒçŸ¥è­˜å¤±æ•—: {e}")
        return ""

    def _translate_to_english(self, text: str) -> str:
        """ç¿»è­¯æˆè‹±æ–‡"""
        try:
            prompt = f"Translate to English: {text}"
            response = self.gemini_model.generate_content(prompt)
            if response and hasattr(response, 'text') and response.text:
                return response.text.strip()
        except Exception as e:
            logging.warning(f"ç¿»è­¯å¤±æ•—: {e}")
        return text

    def create_learning_session(self, user_id: str, wrong_questions: List[Dict]) -> Dict[str, Any]:
        """å‰µå»ºå­¸ç¿’æœƒè©±"""
        session_id = f"learning_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        session = {
            'session_id': session_id,
            'user_id': user_id,
            'wrong_questions': wrong_questions,
            'current_question_index': 0,
            'completed_questions': [],
            'start_time': datetime.now().isoformat(),
            'status': 'active',
            'student_level': 'beginner',
            'conversation_history': [],
            'current_topic_understanding': 0
        }

        self.learning_sessions[session_id] = session

        return {
            'success': True,
            'session_id': session_id,
            'total_wrong_questions': len(wrong_questions),
            'current_question': wrong_questions[0] if wrong_questions else None,
            'message': f'é–‹å§‹å­¸ç¿’ {len(wrong_questions)} é“éŒ¯é¡Œ'
        }

    def handle_tutoring_conversation(self, session_id: str, question: str, user_id: str) -> str:
        """è™•ç†æ•™å­¸å°è©±"""
        session = self.learning_sessions.get(session_id)
        if not session:
            return "å­¸ç¿’æœƒè©±ä¸å­˜åœ¨ï¼Œè«‹é‡æ–°é–‹å§‹ã€‚"

        current_question = session['wrong_questions'][session['current_question_index']]
        conversation_history = session.get('conversation_history', [])
        student_level = session.get('student_level', 'beginner')
        understanding_level = session.get('current_topic_understanding', 0)

        # æ§‹å»ºæ™ºèƒ½æ•™å­¸æç¤ºè©
        teaching_prompt = f"""
ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„è³‡ç®¡ç³»æ•™æˆï¼Œæ­£åœ¨é€²è¡Œä¸€å°ä¸€éŒ¯é¡Œè¼”å°ã€‚

**ç•¶å‰éŒ¯é¡Œä¿¡æ¯**ï¼š
- é¡Œç›®ï¼š{current_question['question_text']}
- å­¸ç”Ÿçš„éŒ¯èª¤ç­”æ¡ˆï¼š{current_question['user_answer']}
- æ­£ç¢ºç­”æ¡ˆï¼š{current_question['correct_answer']}
- ä¸»é¡Œï¼š{current_question.get('topic', 'è³‡ç®¡æ¦‚å¿µ')}

**é‡è¦èƒŒæ™¯**ï¼šå­¸ç”ŸåŸæœ¬å›ç­”ã€Œ{current_question['user_answer']}ã€ï¼Œä½†æ­£ç¢ºç­”æ¡ˆæ˜¯ã€Œ{current_question['correct_answer']}ã€ã€‚

**å­¸ç”Ÿç‹€æ…‹**ï¼š
- ç¨‹åº¦ï¼š{student_level}
- ç•¶å‰ç†è§£åº¦ï¼š{understanding_level}%
- å°è©±è¼ªæ¬¡ï¼š{len(conversation_history)}

**å­¸ç”Ÿç•¶å‰å•é¡Œ**ï¼š{question}

**æ•™å­¸ç­–ç•¥**ï¼š
1. å§‹çµ‚è¨˜ä½å­¸ç”Ÿçš„åŸå§‹éŒ¯èª¤ç­”æ¡ˆï¼Œç•¶å­¸ç”Ÿå•ã€Œç‚ºä»€éº¼æˆ‘çš„ç­”æ¡ˆä¸å°ã€æ™‚ï¼Œè¦å…·é«”è§£é‡‹
2. å¦‚æœå­¸ç”Ÿå•ç‚ºä»€éº¼æŸå€‹ç­”æ¡ˆä¸æ­£ç¢ºï¼Œè¦è§£é‡‹è©²ç­”æ¡ˆçš„å•é¡Œæ‰€åœ¨
3. ä½¿ç”¨å°æ¯”æ–¹å¼èªªæ˜éŒ¯èª¤ç­”æ¡ˆvsæ­£ç¢ºç­”æ¡ˆçš„å·®ç•°
4. å¼•å°å­¸ç”Ÿç†è§£æ¦‚å¿µçš„ç²¾ç¢ºå®šç¾©
5. ç¢ºä¿æ¯æ¬¡å›ç­”éƒ½æ¨é€²å­¸ç”Ÿå°ç•¶å‰éŒ¯é¡Œçš„ç†è§£

**ç‰¹åˆ¥æ³¨æ„**ï¼š
- å¦‚æœå­¸ç”Ÿå•ã€Œç‚ºä»€éº¼ç­”æ¡ˆä¸æ˜¯...ã€ï¼Œè¦è§£é‡‹ç‚ºä»€éº¼é‚£å€‹ç­”æ¡ˆä¸å¤ æº–ç¢ºæˆ–å®Œæ•´
- è¦å…·é«”æŒ‡å‡ºå­¸ç”ŸåŸç­”æ¡ˆçš„ä¸è¶³ä¹‹è™•
- å¹«åŠ©å­¸ç”Ÿç†è§£æ­£ç¢ºç­”æ¡ˆçš„é—œéµè¦ç´ 

è«‹å›æ‡‰å­¸ç”Ÿçš„å•é¡Œï¼š
"""

        try:
            response = self.gemini_model.generate_content(teaching_prompt)
            if response and hasattr(response, 'text') and response.text:
                ai_response = response.text.strip()

                # æ›´æ–°æœƒè©±è¨˜éŒ„
                self._update_learning_progress(session_id, question, ai_response)

                return ai_response
        except Exception as e:
            logger.error(f"æ™ºèƒ½æ•™å­¸å›æ‡‰å¤±æ•—: {e}")

        # å‚™ç”¨å›æ‡‰
        return f"é—œæ–¼ã€Œ{current_question['question_text']}ã€é€™å€‹å•é¡Œï¼Œè®“æˆ‘å€‘ä¸€èµ·æ·±å…¥æ¢è¨ã€‚æ‚¨å‰›æ‰æåˆ°çš„ã€Œ{question}ã€æ˜¯ä¸€å€‹å¾ˆå¥½çš„åˆ‡å…¥é»ã€‚æ‚¨èƒ½å‘Šè¨´æˆ‘æ‚¨å°é€™å€‹æ¦‚å¿µçš„ç†è§£å—ï¼Ÿ"

    def _update_learning_progress(self, session_id: str, question: str, response: str):
        """æ›´æ–°å­¸ç¿’é€²åº¦"""
        session = self.learning_sessions.get(session_id)
        if not session:
            return

        # æ·»åŠ å°è©±è¨˜éŒ„
        session['conversation_history'].append({
            'question': question,
            'response': response,
            'timestamp': datetime.now().isoformat()
        })

        # ç°¡å–®çš„ç†è§£åº¦è©•ä¼°ï¼ˆåŸºæ–¼å°è©±è¼ªæ¬¡ï¼‰
        conversation_count = len(session['conversation_history'])
        if conversation_count >= 3:
            session['current_topic_understanding'] = min(80, conversation_count * 20)

        # å‹•æ…‹èª¿æ•´å­¸ç”Ÿç¨‹åº¦
        if conversation_count >= 2:
            if 'å¾ˆå¥½' in response or 'æ­£ç¢º' in response:
                session['student_level'] = 'intermediate'
            elif conversation_count >= 4:
                session['student_level'] = 'advanced'

    def search_knowledge(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸é—œçŸ¥è­˜é»

        Args:
            query: æœç´¢æŸ¥è©¢
            top_k: è¿”å›çµæœæ•¸é‡

        Returns:
            List[Dict]: æœç´¢çµæœåˆ—è¡¨
        """
        if not self.collection:
            logger.warning("âš ï¸ å‘é‡è³‡æ–™åº«æœªåˆå§‹åŒ–")
            return []

        try:
            # ä½¿ç”¨ChromaDBæœç´¢
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k
            )

            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {}
                    distance = results['distances'][0][i] if results['distances'] and results['distances'][0] else 0

                    formatted_results.append({
                        'content': doc,
                        'metadata': metadata,
                        'similarity': 1 - distance,  # è½‰æ›ç‚ºç›¸ä¼¼åº¦
                        'title': metadata.get('title', 'ç›¸é—œçŸ¥è­˜'),
                        'source': metadata.get('source_file', 'æ•™å­¸è³‡æ–™'),
                        'chapter': metadata.get('chapter', 'ç›¸é—œç« ç¯€'),
                        'keywords': metadata.get('keywords', [])
                    })
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ æœç´¢çŸ¥è­˜é»æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def ask_ai(self, student_input: str, is_new_question: bool = False) -> str:
        """çµ±ä¸€çš„AIå›æ‡‰å‡½å¼"""

        # æ§‹å»ºæç¤ºè©
        if is_new_question:
            prompt = f"""{self.TEACHER_STYLE}

ä½ ç•¶å‰çš„å°è©±æ­·å²å¦‚ä¸‹ï¼š
{self.context}

å­¸ç”Ÿæå‡ºæ–°å•é¡Œï¼š{student_input}

{f"ç›¸é—œçŸ¥è­˜ï¼š{self.topic_knowledge}" if self.topic_knowledge else "è«‹æ†‘é€šç”¨çŸ¥è­˜å›ç­”ã€‚"}

è«‹å…ˆç¢ºèªé¡Œç›®æ–¹å‘ï¼Œç„¶å¾Œ**ç°¡æ½”åœ°è§£é‡‹é€™å€‹æ¦‚å¿µçš„æ ¸å¿ƒè¦é»**ã€‚
éš¨å¾Œï¼Œè«‹å¾æœ€åŸºç¤çš„ç›¸é—œæ¦‚å¿µé–‹å§‹ï¼Œæå‡ºä¸€å€‹å¼•å°æ€§å•é¡Œã€‚
ä¾‹å¦‚ï¼šå¦‚æœå•ã€ŒéŠ€è¡Œå®¶æ¼”ç®—æ³•ã€ï¼Œä½ å¯ä»¥å…ˆç°¡è¿°å®ƒæ˜¯é¿å…æ­»é–çš„æ¼”ç®—æ³•ï¼Œç„¶å¾Œå•å­¸ç”Ÿã€Œä½ çŸ¥é“ä»€éº¼æ˜¯æ­»é–å—ï¼Ÿã€
è«‹ç¢ºä¿ä½ çš„å›ç­”èªæ°£è¦ªåˆ‡ã€å°ˆæ¥­ï¼Œä¸¦ä¸”**ä¸è¦ä½¿ç”¨ä»»ä½•æ ¼å¼åŒ–æ¨™é¡Œ**ã€‚
"""
        else:
            # åˆ†æå°è©±é€²åº¦ï¼Œé¿å…é‡è¤‡
            conversation_turns = len(self.context.split('\n\n')) // 2 if self.context else 0

            prompt = f"""{self.TEACHER_STYLE}

ä½ ç•¶å‰çš„å°è©±æ­·å²å¦‚ä¸‹ï¼š
{self.context}

åŸå§‹å•é¡Œï¼šã€Œ{self.original_question}ã€
å­¸ç”Ÿå°ä½ ä¸Šä¸€å€‹å¼•å°å•é¡Œçš„å›ç­”æ˜¯ï¼š{student_input}
å°è©±è¼ªæ¬¡ï¼šç¬¬{conversation_turns + 1}è¼ª

{f"ç›¸é—œçŸ¥è­˜ï¼š{self.topic_knowledge}" if self.topic_knowledge else "è«‹æ†‘é€šç”¨çŸ¥è­˜å›ç­”ã€‚"}

**é‡è¦æŒ‡å°åŸå‰‡**ï¼š
- é€™æ˜¯ç¬¬{conversation_turns + 1}è¼ªå°è©±ï¼Œè«‹æ ¹æ“šå°è©±é€²åº¦èª¿æ•´æ•™å­¸ç­–ç•¥
- çµ•å°ä¸è¦é‡è¤‡ä¹‹å‰å·²ç¶“å•éçš„å•é¡Œæˆ–è¦æ±‚ç›¸åŒé¡å‹çš„ä¾‹å­
- è¦æ ¹æ“šå­¸ç”Ÿçš„å›ç­”ç¨‹åº¦æ±ºå®šæ˜¯å¦æ·±å…¥æˆ–è½‰æ›è§’åº¦

**æ•™å­¸ç­–ç•¥**ï¼š
1. **è©•ä¼°å­¸ç”Ÿå›ç­”**ï¼š
   - å¦‚æœå­¸ç”Ÿå›ç­”æ­£ç¢ºä¸”å……åˆ†ï¼šçµ¦äºˆè‚¯å®šï¼Œç„¶å¾Œ**æ·±å…¥æ¢è¨åŸç†ã€æ‡‰ç”¨æˆ–é€²éšæ¦‚å¿µï¼Œæ¯æ¬¡çš„æå•éƒ½è¦ç¹¼çºŒæ·±å…¥å•é¡Œ**
   - å¦‚æœå­¸ç”Ÿå›ç­”éƒ¨åˆ†æ­£ç¢ºï¼šè‚¯å®šæ­£ç¢ºéƒ¨åˆ†ï¼Œè£œå……ä¸è¶³ï¼Œç„¶å¾Œ**å¾ä¸åŒè§’åº¦ç¹¼çºŒ**
   - å¦‚æœå­¸ç”Ÿå›ç­”éŒ¯èª¤æˆ–ä¸æ¸…æ¥šï¼šæä¾›ç°¡å–®è§£é‡‹ï¼Œç„¶å¾Œ**é™ä½é›£åº¦é‡æ–°å¼•å°**

2. **é€²éšå¼•å°æ–¹å‘**ï¼ˆæ ¹æ“šå°è©±è¼ªæ¬¡é¸æ“‡ï¼‰ï¼š
   - ç¬¬1-2è¼ªï¼šåŸºæœ¬æ¦‚å¿µå’Œç”Ÿæ´»ä¾‹å­
   - ç¬¬3-4è¼ªï¼šæŠ€è¡“åŸç†å’Œå¯¦ä½œç´°ç¯€
   - ç¬¬5è¼ªä»¥ä¸Šï¼šæ‡‰ç”¨å ´æ™¯ã€å„ªç¼ºé»ã€æ¯”è¼ƒåˆ†æ

3. **é¿å…é‡è¤‡**ï¼š
   - ä¸è¦å†å•ã€Œé‚„æœ‰ä»€éº¼ä¾‹å­ã€æˆ–ã€Œé™¤äº†...é‚„æœ‰ã€
   - ä¸è¦é‡è¤‡è¦æ±‚ç›¸åŒé¡å‹çš„å›ç­”
   - è¦å¾åŸç†ã€æ‡‰ç”¨ã€æ¯”è¼ƒç­‰ä¸åŒç¶­åº¦æ·±å…¥

è«‹æ ¹æ“šä»¥ä¸ŠåŸå‰‡ï¼Œè©•ä¼°å­¸ç”Ÿå›ç­”ä¸¦æå‡º**ä¸åŒæ–¼ä¹‹å‰çš„**æ·±å…¥å•é¡Œã€‚
"""

        return self._call_ai(prompt)

    def _call_ai(self, prompt: str) -> str:
        """èª¿ç”¨Gemini AI"""
        try:
            response = self.gemini_model.generate_content(prompt)
            if response and hasattr(response, 'text') and response.text:
                return response.text.strip()
            else:
                return "æŠ±æ­‰ï¼ŒGeminiæ¨¡å‹ç„¡æ³•å›æ‡‰ï¼Œå¯èƒ½èˆ‡å®‰å…¨è¨­ç½®æœ‰é—œã€‚"

        except Exception as e:
            logging.error(f"èª¿ç”¨Geminiæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return "è«‹ç¨ç­‰ï¼Œè®“æˆ‘é‡æ–°æ€è€ƒä¸€ä¸‹ã€‚"

    def start_new_question(self, question: str) -> str:
        """é–‹å§‹æ–°å•é¡Œ"""
        self.original_question = question
        self.context = ""
        self.topic_knowledge = self.get_topic_knowledge(question)

        response = self.ask_ai(question, is_new_question=True)
        self.context = f"å­¸ç”Ÿå•ï¼š{question}\nè€å¸«ï¼š{response}"

        return response

    def continue_conversation(self, student_answer: str) -> str:
        """ç¹¼çºŒå°è©±"""
        if not self.original_question:
            return "è«‹å…ˆæå‡ºä¸€å€‹å•é¡Œé–‹å§‹å­¸ç¿’ã€‚"
        response = self.ask_ai(student_answer, is_new_question=False)

        # æ›´æ–°ä¸Šä¸‹æ–‡
        self.context += f"\n\nå­¸ç”Ÿï¼š{student_answer}\nè€å¸«ï¼š{response}"

        # ä¿æŒä¸Šä¸‹æ–‡åœ¨åˆç†é•·åº¦
        if len(self.context) > 1500:
            parts = self.context.split('\n\n')
            if len(parts) > 6:
                self.context = '\n\n'.join(parts[-6:])

        return response

    def reset(self):
        """é‡ç½®å°è©±"""
        self.original_question = ""
        self.context = ""
        self.topic_knowledge = ""

# ==================== AIResponder é¡åˆ¥ ====================

class AIResponder:

    def __init__(self, language: str = 'chinese', rag_processor: Optional[Any] = None, ai_model: str = None):
        """
        åˆå§‹åŒ–AIå›æ‡‰å™¨

        Args:
            language: èªè¨€è¨­å®šï¼ˆå›ºå®šç‚ºä¸­æ–‡ï¼‰
            rag_processor: RAGè™•ç†å™¨å¯¦ä¾‹ï¼ˆå·²å»¢æ£„ï¼Œä¿ç•™å‘å¾Œå…¼å®¹ï¼‰
            ai_model: AIæ¨¡å‹åç¨±
        """
        self.ai_model = ai_model

        # åˆå§‹åŒ– Gemini æ¨¡å‹
        try:
            api_key = config.GEMINI_CONFIG.get('api_key')
            if api_key:
                genai.configure(api_key=api_key)
                self.gemini_model = genai.GenerativeModel(config.GEMINI_CONFIG.get('model', 'gemini-1.5-flash'))
            else:
                self.gemini_model = None
        except Exception as e:
            logger.warning(f"Gemini åˆå§‹åŒ–å¤±æ•—: {e}")
            self.gemini_model = None

        # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«é€£æ¥
        self._init_vector_database()

    def _init_vector_database(self):
        """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«é€£æ¥"""
        try:
            import chromadb
            from chromadb.config import Settings

            self.chroma_client = chromadb.PersistentClient(
                path=config.CHROMA_DB_PATH,
                settings=Settings(anonymized_telemetry=False)
            )

            # å˜—è©¦ç²å–ç¾æœ‰é›†åˆ
            try:
                self.collection = self.chroma_client.get_collection(config.COLLECTION_NAME)
            except Exception:
                logger.warning("âš ï¸ AIResponder æœªæ‰¾åˆ°å‘é‡è³‡æ–™åº«")
                self.collection = None

        except Exception as e:
            logger.error(f"âŒ AIResponder å‘é‡è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            self.collection = None

    def answer_question(self, question: str, use_ai: bool = True) -> Dict[str, Any]:
        """
        å›ç­”å•é¡Œçš„ä¸»è¦æ–¹æ³•

        Args:
            question: ç”¨æˆ¶å•é¡Œ
            use_ai: æ˜¯å¦ä½¿ç”¨AIï¼ˆä¿ç•™åƒæ•¸ï¼Œå¯¦éš›ç¸½æ˜¯ä½¿ç”¨AIï¼‰

        Returns:
            Dict: åŒ…å«å›ç­”å’Œç›¸é—œä¿¡æ¯çš„å­—å…¸
        """
        try:
            # 1. AIæ™ºèƒ½å•é¡Œåˆ†é¡ - åˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢è³‡æ–™åº«
            question_category = self._classify_question_intent(question)

            # 2. æ ¹æ“šå•é¡Œé¡å‹æ±ºå®šè™•ç†æ–¹å¼
            if question_category == 'non_academic':
                # éå­¸è¡“å•é¡Œï¼Œä¸éœ€è¦æŸ¥è©¢è³‡æ–™åº«
                return self._handle_non_academic(question)
            else:
                return self._handle_academic(question)

        except Exception as e:
            logger.error(f"âŒ å›ç­”å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {
                "è©³ç´°å›ç­”": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚é‡åˆ°äº†æŠ€è¡“å•é¡Œã€‚è«‹ç¨å¾Œå†è©¦ï¼Œæˆ–è€…æ›å€‹æ–¹å¼æå•ã€‚",
            }

    def _classify_question_intent(self, question: str) -> str:
        """
        ä½¿ç”¨AIæ™ºèƒ½åˆ†é¡å•é¡Œæ„åœ–ï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢è³‡æ–™åº«

        Args:
            question: ç”¨æˆ¶å•é¡Œ

        Returns:
            str: å•é¡Œé¡å‹ ('non_academic', 'mis_academic')
        """
        try:
            if not self.gemini_model:
                # å¦‚æœæ²’æœ‰ Gemini æ¨¡å‹ï¼Œä½¿ç”¨ç°¡å–®çš„é—œéµè©åˆ¤æ–·
                return self._simple_classify(question)

            # ä½¿ç”¨ Gemini é€²è¡Œå•é¡Œåˆ†é¡
            classification_prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ•™å­¸åŠ©ç†ã€‚è«‹åˆ†æä»¥ä¸‹å•é¡Œï¼Œåˆ¤æ–·å®ƒæ˜¯å¦ç‚ºè³‡ç®¡å­¸è¡“å•é¡Œï¼š

å•é¡Œï¼š{question}

åˆ†é¡æ¨™æº–ï¼š
- mis_academicï¼ˆè³‡ç®¡å­¸è¡“ï¼‰ï¼šè³‡è¨Šç®¡ç†ã€ä½œæ¥­ç³»çµ±ã€è³‡æ–™åº«ã€ç¶²è·¯ã€ç¨‹å¼è¨­è¨ˆã€æ¼”ç®—æ³•ã€è³‡æ–™çµæ§‹ã€ç³»çµ±åˆ†æã€è»Ÿé«”å·¥ç¨‹ç­‰å°ˆæ¥­å•é¡Œ
- non_academicï¼ˆéå­¸è¡“ï¼‰ï¼šå•å€™èªã€èº«ä»½è©¢å•ã€èƒ½åŠ›è©¢å•ã€æ„Ÿè¬ã€é“åˆ¥ã€ä¸€èˆ¬çŸ¥è­˜ç­‰å…¶ä»–å•é¡Œ

è«‹åªå›ç­”ï¼šmis_academic æˆ– non_academic"""

            response = self.gemini_model.generate_content(classification_prompt)

            if response and hasattr(response, 'text') and response.text:
                ai_response = response.text.strip().lower()
                if 'mis_academic' in ai_response or 'è³‡ç®¡å­¸è¡“' in ai_response:
                    return 'mis_academic'
                else:
                    return 'non_academic'

        except Exception as e:
            logger.warning(f"AIåˆ†é¡å¤±æ•—: {e}")
            return self._simple_classify(question)

    def _handle_non_academic(self, question: str) -> Dict[str, Any]:
        """
        è™•ç†éå­¸è¡“å•é¡Œï¼Œä½¿ç”¨AIç›´æ¥å›ç­”ï¼Œä¸æŸ¥è©¢è³‡æ–™åº«
        """
        try:
            if self.gemini_model:
                prompt = f"""ä½ æ˜¯ä¸€ä½å‹å–„çš„è³‡ç®¡ç³»æ™ºèƒ½æ•™å­¸åŠ©ç†ã€‚è«‹å›ç­”ä»¥ä¸‹å•é¡Œï¼š

å•é¡Œï¼š{question}

è«‹æä¾›è‡ªç„¶ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæ˜¯å•å€™æˆ–èº«ä»½è©¢å•ï¼Œè«‹ä»‹ç´¹è‡ªå·±æ˜¯è³‡ç®¡ç³»AIæ•™å­¸åŠ©ç†ã€‚
å¦‚æœæ˜¯ä¸€èˆ¬çŸ¥è­˜å•é¡Œï¼Œè«‹æä¾›ç°¡æ½”çš„å›ç­”"""
                response = self.gemini_model.generate_content(prompt)
                if response and hasattr(response, 'text') and response.text:
                    detailed_answer = response.text.strip()
        except Exception as e:
            logger.warning(f"AIå›ç­”éå­¸è¡“å•é¡Œå¤±æ•—: {e}")
            detailed_answer = f"æ‚¨å¥½ï¼æˆ‘æ˜¯è³‡ç®¡ç³»æ™ºèƒ½æ•™å­¸åŠ©ç†ã€‚é—œæ–¼ã€Œ{question}ã€ï¼Œæˆ‘å¾ˆæ¨‚æ„ç‚ºæ‚¨è§£ç­”ã€‚æœ‰ä»€éº¼è³‡ç®¡ç›¸é—œå•é¡Œæƒ³è¦è¨è«–å—ï¼Ÿ"
        return {
            "è©³ç´°å›ç­”": detailed_answer,
            "æ™‚é–“æˆ³": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    def _handle_academic(self, question: str) -> Dict[str, Any]:
        """
        è™•ç†è³‡ç®¡å­¸è¡“å•é¡Œï¼ŒæŸ¥è©¢å‘é‡è³‡æ–™åº«
        """
        # ä½¿ç”¨æ•´åˆçš„å‘é‡è³‡æ–™åº«æœç´¢
        if self.collection:
            try:
                # æœç´¢ç›¸é—œçŸ¥è­˜
                search_results = self._search_knowledge(question, top_k=5)
                if search_results:
                    # åŸºæ–¼æœç´¢çµæœç”Ÿæˆå›ç­”
                    return self._generate_answer_from_search(question, search_results)
            except Exception as e:
                logger.warning(f"âš ï¸ å‘é‡è³‡æ–™åº«æŸ¥è©¢éŒ¯èª¤: {e}")
        else:
            logger.warning("âš ï¸ å‘é‡è³‡æ–™åº«æœªåˆå§‹åŒ–")


    def _search_knowledge(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸é—œçŸ¥è­˜é»

        Args:
            query: æœç´¢æŸ¥è©¢
            top_k: è¿”å›çµæœæ•¸é‡

        Returns:
            List[Dict]: æœç´¢çµæœåˆ—è¡¨
        """
        if not self.collection:
            return []

        try:
            # ä½¿ç”¨ChromaDBæœç´¢
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k
            )

            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {}
                    distance = results['distances'][0][i] if results['distances'] and results['distances'][0] else 0

                    formatted_results.append({
                        'content': doc,
                        'metadata': metadata,
                        'similarity': 1 - distance,  # è½‰æ›ç‚ºç›¸ä¼¼åº¦
                        'title': metadata.get('title', 'ç›¸é—œçŸ¥è­˜'),
                        'source': metadata.get('source_file', 'æ•™å­¸è³‡æ–™'),
                        'chapter': metadata.get('chapter', 'ç›¸é—œç« ç¯€'),
                        'keywords': metadata.get('keywords', [])
                    })
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ æœç´¢çŸ¥è­˜é»æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def _generate_answer_from_search(self, question: str, search_results: List[Dict]) -> Dict[str, Any]:
        """åŸºæ–¼æœç´¢çµæœç”Ÿæˆå›ç­”"""
        # æå–æœ€ç›¸é—œçš„çµæœ
        best_result = search_results[0] if search_results else {}

        # æ§‹å»ºåŸºæ–¼æœç´¢çµæœçš„å›ç­”
        content = best_result.get('content', '')
        title = best_result.get('title', 'ç›¸é—œçŸ¥è­˜')

        detailed_answer = f"""
ğŸ“š **é—œæ–¼ã€Œ{question}ã€çš„å›ç­”**

**åŸºæœ¬æ¦‚å¿µï¼š**
{content}

**ç›¸é—œçŸ¥è­˜é»ï¼š**
{title}

**å­¸ç¿’å»ºè­°ï¼š**
å»ºè­°æ‚¨æ·±å…¥ç†è§£é€™å€‹æ¦‚å¿µçš„æ ¸å¿ƒåŸç†ï¼Œä¸¦å˜—è©¦å°‡å…¶èˆ‡å¯¦éš›æ‡‰ç”¨å ´æ™¯çµåˆã€‚

ğŸ’¡ **æç¤º**ï¼šå¦‚éœ€æ›´è©³ç´°çš„è§£é‡‹ï¼Œè«‹æå‡ºæ›´å…·é«”çš„å•é¡Œã€‚
"""

        return {
            "ç§‘ç›®": best_result.get('subject', 'è³‡è¨Šç®¡ç†'),
            "æ•™æ": best_result.get('source', 'æ•™å­¸è³‡æ–™'),
            "çŸ¥è­˜é»": title,
            "è©³ç´°å›ç­”": detailed_answer.strip(),
            "ç›¸é—œæ¦‚å¿µ": " | ".join(best_result.get('keywords', ['ç›¸é—œæ¦‚å¿µ'])),
            "æ™‚é–“æˆ³": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    def format_response_for_display(self, response: Dict) -> str:
        """æ ¼å¼åŒ–å›æ‡‰ä»¥ä¾›é¡¯ç¤º"""
        if isinstance(response, dict) and 'è©³ç´°å›ç­”' in response:
            return response['è©³ç´°å›ç­”']
        elif isinstance(response, str):
            return response
        else:
            return "æŠ±æ­‰ï¼Œç„¡æ³•æ ¼å¼åŒ–å›æ‡‰ã€‚"

# ==================== RAG Assistant Service é¡åˆ¥ ====================

class RAGAssistantService:
    """RAGæ™ºèƒ½æ•™å­¸åŠ©ç†æœå‹™"""

    def __init__(self):
        """åˆå§‹åŒ–æœå‹™"""
        self.tutors = {}  # å­˜å„²æ¯å€‹ç”¨æˆ¶çš„tutorå¯¦ä¾‹
        self.processors = {}  # å­˜å„²æ¯å€‹ç”¨æˆ¶çš„processorå¯¦ä¾‹
        self.user_sessions = {}  # å­˜å„²ç”¨æˆ¶æœƒè©±æ•¸æ“š
        self.conversation_histories = {}  # å­˜å„²å°è©±æ­·å²

        # åˆå§‹åŒ–RAGè™•ç†å™¨ï¼ˆä½¿ç”¨æ•´åˆçš„é¡åˆ¥ï¼‰
        try:
            # ä½¿ç”¨æ•´åˆå¾Œçš„ RAGBuilder ä½œç‚ºè™•ç†å™¨
            self.shared_processor = RAGBuilder(Config())
            self.shared_ai_responder = AIResponder(
                language='chinese',
                rag_processor=self.shared_processor
            )
        except Exception as e:
            logger.error(f"âŒ RAGç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            self.shared_processor = None
            self.shared_ai_responder = None

