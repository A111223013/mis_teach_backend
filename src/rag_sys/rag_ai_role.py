#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAG AI æ•™å­¸ç³»çµ± - é‡æ§‹ç‰ˆæœ¬
ç°¡åŒ–å‡½æ•¸çµæ§‹ï¼ŒçœŸæ­£å¯¦ç¾ RAG åŠŸèƒ½
"""

from tool.api_keys import get_api_key
import json
import re
from typing import Dict, Any, List, Optional
from datetime import datetime
import logging
import chromadb
from chromadb.config import Settings
from accessories import init_gemini

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==================== å…¨å±€è®Šæ•¸ ====================

# å­¸ç¿’æœƒè©±ç®¡ç†
learning_sessions = {}

# æœƒè©±æŒä¹…åŒ–æ–‡ä»¶è·¯å¾‘
import os
SESSION_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "learning_sessions.json")

def save_sessions_to_file():
    """å°‡æœƒè©±ä¿å­˜åˆ°æ–‡ä»¶ç›®å‰å…ˆè¨»è§£æ‰ä¹‹å¾Œæˆ‘å†çœ‹çœ‹æ˜¯ä¸æ˜¯è¦ç”¨"""
    # å‰µå»ºå¯åºåˆ—åŒ–çš„æœƒè©±å‰¯æœ¬
    serializable_sessions = {}
    for key, session in learning_sessions.items():
        serializable_session = session.copy()
        # ç¢ºä¿ datetime å°è±¡è¢«è½‰æ›ç‚ºå­—ç¬¦ä¸²
        if 'created_at' in serializable_session and isinstance(serializable_session['created_at'], datetime):
            serializable_session['created_at'] = serializable_session['created_at'].isoformat()
        serializable_sessions[key] = serializable_session
    
    with open(SESSION_FILE, 'w', encoding='utf-8') as f:
        json.dump(serializable_sessions, f, ensure_ascii=False, indent=2)

def load_sessions_from_file():
    """å¾æ–‡ä»¶è¼‰å…¥æœƒè©±"""
    if not os.path.exists(SESSION_FILE):
        return
    
    with open(SESSION_FILE, 'r', encoding='utf-8') as f:
        sessions = json.load(f)
        # è½‰æ›å›å­—å…¸
        for key, value in sessions.items():
            # ç¢ºä¿ datetime å­—ç¬¦ä¸²è¢«æ­£ç¢ºè™•ç†
            if 'created_at' in value and isinstance(value['created_at'], str):
                try:
                    value['created_at'] = datetime.fromisoformat(value['created_at'])
                except ValueError:
                    # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“
                    value['created_at'] = datetime.now()
            learning_sessions[key] = value

# åœ¨æ¨¡çµ„è¼‰å…¥æ™‚è¼‰å…¥æœƒè©±
load_sessions_from_file()

def cleanup_old_sessions(max_age_hours: int = 24):
    """æ¸…ç†éæœŸçš„æœƒè©±ï¼Œé¿å…è¨˜æ†¶é«”æ´©æ¼"""
    current_time = datetime.now()
    expired_sessions = []
    
    for session_key, session_data in learning_sessions.items():
        if 'created_at' in session_data:
            try:
                created_time = (datetime.fromisoformat(session_data['created_at']) 
                              if isinstance(session_data['created_at'], str) 
                              else session_data['created_at'])
                
                age_hours = (current_time - created_time).total_seconds() / 3600
                if age_hours > max_age_hours:
                    expired_sessions.append(session_key)
            except:
                # å¦‚æœæ™‚é–“è§£æå¤±æ•—ï¼Œä¿ç•™æœƒè©±
                pass
    
    # åˆªé™¤éæœŸæœƒè©±
    for session_key in expired_sessions:
        del learning_sessions[session_key]
    
    return len(expired_sessions)

# å®šæœŸæ¸…ç†æœƒè©±ï¼ˆæ¯å°æ™‚æ¸…ç†ä¸€æ¬¡ï¼‰
import threading
import time

def auto_cleanup_sessions():
    """è‡ªå‹•æ¸…ç†æœƒè©±çš„å¾Œå°ä»»å‹™"""
    while True:
        try:
            time.sleep(3600)  # æ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡
            cleanup_old_sessions()
        except Exception as e:
            print(f"âš ï¸ è‡ªå‹•æ¸…ç†å¤±æ•—ï¼š{e}")

# å•Ÿå‹•è‡ªå‹•æ¸…ç†ï¼ˆåœ¨å¾Œå°åŸ·è¡Œï¼‰
cleanup_thread = threading.Thread(target=auto_cleanup_sessions, daemon=True)
cleanup_thread.start()

# æ•™å­¸é¢¨æ ¼æç¤ºè©
TEACHER_STYLE = """ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„è³‡ç®¡ç³»æ•™æˆï¼Œæ­£åœ¨ä¸€å°ä¸€è¼”å°å­¸ç”Ÿï¼Œå¹«åŠ©å­¸ç”Ÿé€éé€æ­¥å¼•å°æ–¹å¼ç†è§£è€ƒé¡Œèˆ‡è³‡ç®¡ç³»ç›¸é—œçŸ¥è­˜ï¼Œç¢ºä¿å­¸ç”ŸçœŸæ­£æŒæ¡æ¦‚å¿µï¼Œè€Œä¸åªæ˜¯èƒŒèª¦ç­”æ¡ˆã€‚

**ä½ çš„æ•™å­¸åŸå‰‡**ï¼š
- **å¾æ ¸å¿ƒé–‹å§‹**ï¼šå¾èˆ‡é€™é“é¡Œç›®æœ€ç›´æ¥ç›¸é—œçš„æ ¸å¿ƒæ¦‚å¿µé–‹å§‹ï¼Œè€Œä¸æ˜¯å¾æœ€åŸºç¤çš„æ¦‚å¿µé–‹å§‹
- **æ¦‚å¿µé€£è²«æ€§**ï¼šç¢ºä¿æ¯å€‹å•é¡Œéƒ½èˆ‡é¡Œç›®æ ¸å¿ƒæ¦‚å¿µç›¸é—œï¼Œé¿å…æ¦‚å¿µè·³è„«
- **è˜‡æ ¼æ‹‰åº•å¼æå•**ï¼šé€éå¼•å°æ€§å•é¡Œï¼Œè®“å­¸ç”Ÿè‡ªå·±æ€è€ƒä¸¦å¾—å‡ºç­”æ¡ˆ
- **ç²¾ç¢ºè©•åˆ†**ï¼šæ¯æ¬¡å­¸ç”Ÿå›ç­”å¾Œï¼Œçµ¦å‡º0-100åˆ†çš„å…·é«”è©•åˆ†ï¼Œè©•ä¼°å­¸ç”Ÿå°é¡Œç›®çš„ç†è§£ç¨‹åº¦
- **ç†è§£é©—è­‰**ï¼šç•¶å­¸ç”Ÿç†è§£ç¨‹åº¦é”åˆ°95åˆ†æ™‚ï¼Œè¦æ±‚å­¸ç”Ÿç”¨è‡ªå·±çš„è©±é‡æ–°è§£é‡‹é¡Œç›®å’Œç­”æ¡ˆ

**è©•åˆ†æ¨™æº–**ï¼š
- **0-30åˆ†**ï¼šå®Œå…¨ä¸ç†è§£æˆ–å›ç­”éŒ¯èª¤ï¼Œéœ€è¦å¾åŸºç¤æ¦‚å¿µé–‹å§‹è§£é‡‹
- **31-60åˆ†**ï¼šæœ‰åŸºæœ¬æ¦‚å¿µä½†ç†è§£ä¸æ·±ï¼Œéœ€è¦é€²ä¸€æ­¥å¼•å°å’Œè§£é‡‹
- **61-80åˆ†**ï¼šç†è§£è¼ƒå¥½ï¼Œèƒ½å›ç­”ç›¸é—œå•é¡Œï¼Œå¯ä»¥é€²å…¥æ‡‰ç”¨å±¤é¢
- **81-90åˆ†**ï¼šç†è§£å¾ˆå¥½ï¼Œæ¥è¿‘å®Œå…¨æŒæ¡ï¼Œå¯ä»¥æ·±å…¥æ¢è¨ç´°ç¯€
- **90-99åˆ†**ï¼šé€²å…¥åå‘æ•™å°éšæ®µï¼Œå­¸ç”Ÿç”¨è‡ªå·±çš„è©±å‘AIè§£é‡‹é¡Œç›®å’Œç­”æ¡ˆï¼ŒAIä¸æ–·ä¿®æ­£éŒ¯èª¤ç›´åˆ°99åˆ†
- **99åˆ†**ï¼šå¯ä»¥é€²å…¥ä¸‹ä¸€é¡Œ

**æ•™å­¸æµç¨‹**ï¼š
1. **æ ¸å¿ƒæ¦‚å¿µç¢ºèªéšæ®µ**ï¼šè©•ä¼°å­¸ç”Ÿå°é¡Œç›®æ ¸å¿ƒæ¦‚å¿µçš„æŒæ¡ç¨‹åº¦
2. **ç›¸é—œæ¦‚å¿µå¼•å°éšæ®µ**ï¼šåœç¹æ ¸å¿ƒæ¦‚å¿µï¼Œé€æ­¥å¼•å°å­¸ç”Ÿç†è§£ç›¸é—œçŸ¥è­˜é»
3. **æ‡‰ç”¨ç†è§£éšæ®µ**ï¼šè®“å­¸ç”Ÿå°‡ç†è§£æ‡‰ç”¨åˆ°é¡Œç›®æƒ…å¢ƒä¸­
4. **åå‘æ•™å°éšæ®µ**ï¼šç•¶ç†è§£ç¨‹åº¦é”åˆ°90åˆ†æ™‚ï¼Œå­¸ç”Ÿç”¨è‡ªå·±çš„è©±å‘AIè§£é‡‹é¡Œç›®å’Œç­”æ¡ˆï¼ŒAIä¸æ–·ä¿®æ­£å­¸ç”ŸéŒ¯èª¤ä»¥åŠçŸ¥è­˜ç›²é»
5. **å®Œæˆéšæ®µ**ï¼šé”åˆ°99åˆ†æ™‚ï¼Œå­¸ç”Ÿå®Œå…¨æŒæ¡ï¼Œå¯ä»¥é€²å…¥ä¸‹ä¸€é¡Œ

**å›æ‡‰è¦æ±‚**ï¼š
- èªæ°£è¦ªåˆ‡è‡ªç„¶ï¼Œå¦‚åŒçœŸæ­£çš„è€å¸«
- æ¯æ¬¡å›ç­”å¾Œï¼Œå¿…é ˆçµ¦å‡º0-100åˆ†çš„å…·é«”è©•åˆ†ï¼Œæ ¼å¼ç‚ºã€Œè©•åˆ†ï¼š[åˆ†æ•¸]åˆ†ã€
- æ ¹æ“šè©•åˆ†çµ¦å‡ºç›¸æ‡‰çš„å¼•å°å•é¡Œæˆ–é€²å…¥ä¸‹ä¸€éšæ®µ
- ç•¶è©•åˆ†é”åˆ°90åˆ†æ™‚ï¼Œé€²å…¥åå‘æ•™å°éšæ®µï¼Œè¦æ±‚å­¸ç”Ÿç”¨è‡ªå·±çš„è©±å‘AIè§£é‡‹é¡Œç›®å’Œç­”æ¡ˆ
- åœ¨åå‘æ•™å°éšæ®µï¼ŒAIè¦ä¸æ–·ä¿®æ­£å­¸ç”ŸèªªéŒ¯æˆ–ç†è§£éŒ¯çš„åœ°æ–¹ï¼Œç›´åˆ°é”åˆ°99åˆ†
- åš´ç¦ä½¿ç”¨ä»»ä½•æ ¼å¼åŒ–æ¨™é¡Œï¼Œç›´æ¥ä»¥è‡ªç„¶æ®µè½å‘ˆç¾å…§å®¹

**å­¸ç¿’è©•ä¼°æ¨™æº–**ï¼š
- å­¸ç”Ÿèƒ½ç”¨è‡ªå·±çš„è©±è§£é‡‹é¡Œç›®æ ¸å¿ƒæ¦‚å¿µ
- å­¸ç”Ÿèƒ½ç”¨è‡ªå·±çš„è©±è§£é‡‹ç­”æ¡ˆçš„é‚è¼¯
- å­¸ç”Ÿèƒ½èˆ‰å‡ºç›¸é—œçš„ä¾‹å­æˆ–æ‡‰ç”¨
- å­¸ç”Ÿè¡¨ç¾å‡ºå°é¡Œç›®å’Œç­”æ¡ˆçš„æ·±åº¦ç†è§£

ç¾åœ¨ï¼Œè®“æˆ‘å€‘é–‹å§‹ä¸€å ´æœ‰æ·±åº¦çš„å­¸ç¿’å°è©±ã€‚
"""

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================

def handle_tutoring_conversation(user_email: str, question: str, user_answer: str, correct_answer: str, user_input: str = None, grading_feedback: dict = None) -> dict:
    """
    è™•ç†AIæ•™å­¸å°è©± - é‡æ§‹ç‰ˆæœ¬
    æ•´åˆäº†æœƒè©±ç®¡ç†ã€çŸ¥è­˜æª¢ç´¢ã€AIå›æ‡‰å’Œå­¸ç¿’é€²åº¦æ›´æ–°
    æ–°å¢ï¼šæ”¯æ´AIæ‰¹æ”¹çš„è©•åˆ†åé¥‹
    """
    try:
        # 1. ç²å–æˆ–å‰µå»ºæœƒè©±
        session = get_or_create_session(user_email, question)
        conversation_history = session.get('conversation_history', [])
        
        # 2. åˆ¤æ–·æ˜¯å¦ç‚ºåˆå§‹åŒ–ï¼ˆåŸºæ–¼æ›´æ–°å‰çš„å°è©±æ­·å²ï¼‰
        original_history_length = len(conversation_history)
        is_initial = original_history_length == 0
        
        # 3. æ§‹å»ºAIæç¤ºè©
        if is_initial:
            # åˆå§‹åŒ–ï¼šåˆ†æå­¸ç”Ÿç­”æ¡ˆï¼Œæå‡ºå¼•å°å•é¡Œ
            prompt = build_initial_prompt(question, user_answer, correct_answer, grading_feedback)
        else:
            # å¾ŒçºŒå°è©±ï¼šåŸºæ–¼å­¸ç”Ÿå›ç­”é€²è¡Œæ•™å­¸
            prompt = build_followup_prompt(question, user_answer, correct_answer, user_input, conversation_history, grading_feedback)
        
        # 4. å¢å¼·æç¤ºè©ï¼ˆRAGåŠŸèƒ½ï¼‰
        enhanced_prompt = enhance_prompt_with_knowledge(prompt, question)
        
        # 5. èª¿ç”¨AIç²å–å›æ‡‰
        ai_response = call_gemini_api(enhanced_prompt)
        
        # 6. æ¸…ç†AIå›æ‡‰ï¼ˆç§»é™¤è©•åˆ†ç­‰å…§éƒ¨ä¿¡æ¯ï¼‰
        clean_response = clean_ai_response(ai_response)
        
        # 7. è¨˜éŒ„å°è©±æ­·å²ï¼ˆå…ˆè¨˜éŒ„ï¼Œå†æ›´æ–°å­¸ç¿’é€²åº¦ï¼‰
        if user_input:
            conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": clean_response})
        session['conversation_history'] = conversation_history
        
        # 8. æ›´æ–°å­¸ç¿’é€²åº¦ï¼ˆåªåœ¨éåˆå§‹åŒ–éšæ®µï¼‰
        if not is_initial:
            update_learning_progress(session, question, ai_response, conversation_history)
        else:
            print(f"ğŸ¯ åˆå§‹åŒ–éšæ®µï¼Œè·³éè©•åˆ†æ›´æ–°")
        
        # 9. ä¿å­˜æœƒè©±åˆ°å…¨å±€å­—å…¸ï¼ˆä½¿ç”¨èˆ‡ get_or_create_session ç›¸åŒçš„é‚è¼¯ï¼‰
        clean_question = question.strip().replace('\n', ' ').replace('\r', ' ')
        # çµ„åˆç”¨æˆ¶emailå’Œé¡Œç›®hashï¼Œç¢ºä¿å”¯ä¸€æ€§
        session_key = f"{user_email}_question_{hash(clean_question)}"
        
        # ç¢ºä¿æœƒè©±è¢«æ­£ç¢ºä¿å­˜
        learning_sessions[session_key] = session
        
        # ä¿å­˜åˆ°æ–‡ä»¶ä»¥ç¢ºä¿æŒä¹…åŒ–
        #save_sessions_to_file()
        
        # 9. è¿”å›çµæœ
        return {
            'response': clean_response,
            'learning_stage': session.get('learning_stage', 'core_concept_confirmation'),
            'understanding_level': session.get('understanding_level', 0),
            'concept_progress': session.get('concept_progress', [])
        }
        
    except Exception as e:
        logger.error(f"âŒ æ•™å­¸å°è©±è™•ç†å¤±æ•—: {e}")
        return {
            'response': 'æŠ±æ­‰ï¼Œç³»çµ±å‡ºç¾å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚',
            'learning_stage': 'core_concept_confirmation',
            'understanding_level': 0,
            'concept_progress': []
        }

def update_learning_progress(session: dict, question: str, ai_response: str, conversation_history: list):
    """
    æ›´æ–°å­¸ç¿’é€²åº¦ - æ•´åˆç‰ˆæœ¬
    åŒ…å«è©•åˆ†æå–ã€æ™ºèƒ½è©•åˆ†è¨ˆç®—å’Œå­¸ç¿’éšæ®µæ›´æ–°
    """
    try:
        # 1. æå–AIè©•åˆ†
        score = extract_score_from_response(ai_response)
        if score is None:
            print(f"âš ï¸ æœªæå–åˆ°è©•åˆ†ï¼Œè·³éå­¸ç¿’é€²åº¦æ›´æ–°")
            return
        
        # 2. è¨ˆç®—å°è©±æ¬¡æ•¸
        # å°è©±æ­·å²æ ¼å¼ï¼šuser, assistant, user, assistant, ...
        # æ‰€ä»¥å°è©±æ¬¡æ•¸ = (ç¸½é•·åº¦ - 1) // 2ï¼ˆæ¸›1æ˜¯å› ç‚ºæœ€å¾Œä¸€æ¢æ˜¯AIå›æ‡‰ï¼‰
        conversation_count = (len(conversation_history) - 1) // 2

        
        # 3. æ™ºèƒ½è©•åˆ†è¨ˆç®—
        old_level = session.get('understanding_level', 0)
        smart_score = calculate_smart_score(old_level, score, conversation_count)
        session['understanding_level'] = smart_score

        
        # 4. æ›´æ–°å­¸ç¿’éšæ®µ
        old_stage = session.get('learning_stage', 'core_concept_confirmation')
        new_stage = determine_learning_stage(smart_score)
        session['learning_stage'] = new_stage
        
        if old_stage != new_stage:
            print(f"ğŸ”„ å­¸ç¿’éšæ®µæ›´æ–°ï¼š{old_stage} â†’ {new_stage}")
        
        # 5. è¨˜éŒ„é€²åº¦
        record_progress(session, score, smart_score, new_stage)
        
        # 6. ä¿å­˜æ›´æ–°å¾Œçš„æœƒè©±
        #save_sessions_to_file()

        
    except Exception as e:
        logger.error(f"âŒ å­¸ç¿’é€²åº¦æ›´æ–°å¤±æ•—: {e}")

def calculate_smart_score(current_score: int, ai_score: int, conversation_count: int = 0) -> int:
    """
    æ™ºèƒ½è©•åˆ†è¨ˆç®— - å¯¦ç¾æ–°çš„è©•åˆ†é‚è¼¯
    """
    try:

        # åˆå§‹åŒ–éšæ®µï¼šä¸çµ¦åˆ†æ•¸
        if conversation_count == 0:
            return 0
        
        # ç¬¬ä¸€å€‹å•é¡Œï¼šçµ¦äºˆåŸºç¤è©•åˆ† 0-95
        elif conversation_count == 1:
            base_score = min(95, max(0, ai_score))
            return base_score
        
        # å¾ŒçºŒå•é¡Œï¼šåŸºæ–¼ç•¶å‰åˆ†æ•¸çµ¦äºˆåŠ åˆ†
        else:
            if ai_score > current_score:
                bonus = min(10, ai_score - current_score)
                new_score = min(95, current_score + bonus)
                return new_score
            else:
                penalty = min(2, current_score - ai_score)
                new_score = max(0, current_score - penalty)
                return new_score
            
    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½è©•åˆ†è¨ˆç®—å¤±æ•—: {e}")
        return current_score

# ==================== RAG åŠŸèƒ½ ====================

def should_search_database(question: str) -> bool:
    """
    æ™ºèƒ½åˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢å‘é‡è³‡æ–™åº«
    éæ¿¾æ‰éå­¸è¡“å•é¡Œï¼Œåªå°MISç›¸é—œçš„æŠ€è¡“æ¦‚å¿µé€²è¡ŒçŸ¥è­˜æª¢ç´¢
    """
    try:
        # ä½¿ç”¨ç°¡å–®çš„é—œéµå­—åˆ¤æ–·ï¼Œé¿å…èª¿ç”¨AIé€²è¡Œåˆ¤æ–·
        mis_keywords = [
            'ç¶²è·¯', 'æ‹“æ¨¸', 'è³‡æ–™åº«', 'æ¼”ç®—æ³•', 'ç¨‹å¼è¨­è¨ˆ', 'ä½œæ¥­ç³»çµ±',
            'è¨˜æ†¶é«”', 'CPU', 'ç¡¬ç¢Ÿ', 'è»Ÿé«”', 'ç¡¬é«”', 'ç³»çµ±åˆ†æ',
            'è³‡è¨Šç®¡ç†', 'é›»è…¦ç§‘å­¸', 'è³‡æ–™çµæ§‹', 'ç¶²è·¯å®‰å…¨', 'é›²ç«¯è¨ˆç®—',
            'å¤§æ•¸æ“š', 'äººå·¥æ™ºæ…§', 'æ©Ÿå™¨å­¸ç¿’', 'è³‡æ–™åº«ç®¡ç†', 'ç¶²è·¯ç®¡ç†',
            'ç³»çµ±è¨­è¨ˆ', 'è»Ÿé«”å·¥ç¨‹', 'å°ˆæ¡ˆç®¡ç†', 'ä¼æ¥­è³‡æºè¦åŠƒ', 'å®¢æˆ¶é—œä¿‚ç®¡ç†'
        ]
        
        # æª¢æŸ¥å•é¡Œæ˜¯å¦åŒ…å«MISç›¸é—œé—œéµå­—
        question_lower = question.lower()
        has_mis_content = any(keyword in question_lower for keyword in mis_keywords)
        
        # éæ¿¾æ‰æ˜é¡¯çš„éå­¸è¡“å•é¡Œ
        non_academic_patterns = [
            'ä½ å¥½', 'æ—©å®‰', 'æ™šå®‰', 'è¬è¬', 'ä¸å®¢æ°£', 'ä½ æ˜¯èª°', 'è‡ªæˆ‘ä»‹ç´¹',
            'å¤©æ°£', 'å¿ƒæƒ…', 'é–’èŠ', '1+1', 'ç°¡å–®è¨ˆç®—'
        ]
        
        is_non_academic = any(pattern in question_lower for pattern in non_academic_patterns)
        
        should_search = has_mis_content and not is_non_academic
        
        return should_search
        
    except Exception as e:
        logger.error(f"âŒ RAGåˆ¤æ–·å¤±æ•—: {e}")
        return False  # é è¨­ä¸æª¢ç´¢

def enhance_prompt_with_knowledge(prompt: str, question: str) -> str:
    """
    ä½¿ç”¨RAGå¢å¼·æç¤ºè© - çœŸæ­£çš„RAGåŠŸèƒ½
    """
    try:
        # 1. åˆ¤æ–·æ˜¯å¦éœ€è¦æª¢ç´¢çŸ¥è­˜
        if not should_search_database(question):
            return prompt
        
        # 2. åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
        client, collection = init_vector_database()
        if not collection:
            print(f"âš ï¸ å‘é‡è³‡æ–™åº«ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æç¤ºè©")
            return prompt
        
        # 3. æª¢ç´¢ç›¸é—œçŸ¥è­˜
        knowledge_results = search_knowledge(question, top_k=2)  # æ¸›å°‘æª¢ç´¢æ•¸é‡
        
        if knowledge_results:
            # 4. æ§‹å»ºçŸ¥è­˜å¢å¼·éƒ¨åˆ†
            knowledge_context = "\n\n**ç›¸é—œçŸ¥è­˜åƒè€ƒï¼š**\n"
            for i, result in enumerate(knowledge_results, 1):
                knowledge_context += f"{i}. {result['content'][:200]}...\n"
            
            # 5. å¢å¼·æç¤ºè©
            enhanced_prompt = prompt + knowledge_context
            return enhanced_prompt
        else:
            return prompt
            
    except Exception as e:
        logger.error(f"âŒ RAGå¢å¼·å¤±æ•—: {e}")
        return prompt

def search_knowledge(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    å¾å‘é‡è³‡æ–™åº«æª¢ç´¢çŸ¥è­˜ - çœŸæ­£çš„RAGæª¢ç´¢
    è‡ªå‹•å°‡ä¸­æ–‡å•é¡Œç¿»è­¯æˆè‹±æ–‡é€²è¡Œæª¢ç´¢
    """
    try:
        client, collection = init_vector_database()
        if not collection:
            return []
        
        # 1. å…ˆå°‡ä¸­æ–‡å•é¡Œç¿»è­¯æˆè‹±æ–‡ï¼ˆå› ç‚ºå‘é‡è³‡æ–™åº«æ˜¯è‹±æ–‡æ•™æï¼‰
        english_query = translate_to_english(query)
        
        # 2. åŸ·è¡Œç›¸ä¼¼æ€§æœç´¢
        results = collection.query(
            query_texts=[english_query],
            n_results=top_k
        )
        
        # 3. æ ¼å¼åŒ–çµæœ
        knowledge_items = []
        if results['documents'] and results['documents'][0]:
            for i, doc in enumerate(results['documents'][0]):
                knowledge_items.append({
                    'content': doc,
                    'metadata': results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {},
                    'distance': results['distances'][0][i] if results['distances'] and results['distances'][0] else 0
                })
        
        return knowledge_items
        
    except Exception as e:
        logger.error(f"âŒ çŸ¥è­˜æª¢ç´¢å¤±æ•—: {e}")
        return []

def translate_to_english(text: str) -> str:
    # ä½¿ç”¨Geminié€²è¡Œç¿»è­¯
    model = init_gemini(model_name = 'gemini-1.5-flash')
    prompt = f"""è«‹å°‡ä»¥ä¸‹ä¸­æ–‡å•é¡Œç¿»è­¯æˆè‹±æ–‡ï¼Œä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§ï¼š

ä¸­æ–‡å•é¡Œï¼š{text}

è«‹åªè¿”å›è‹±æ–‡ç¿»è­¯ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹æˆ–é¡å¤–æ–‡å­—ã€‚"""
    
    response = model.generate_content(prompt)
    
    # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰æ•ˆ
    if not response or not hasattr(response, 'text'):
        return "Translation failed: Invalid response format"
    
    # æª¢æŸ¥å®‰å…¨è©•ç´š
    if hasattr(response, 'candidates') and response.candidates:
        candidate = response.candidates[0]
        if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
            # æª¢æŸ¥æ˜¯å¦æœ‰å®‰å…¨å•é¡Œ
            for rating in candidate.safety_ratings:
                if rating.category in ['HARM_CATEGORY_HARASSMENT', 'HARM_CATEGORY_HATE_SPEECH', 
                                     'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'HARM_CATEGORY_DANGEROUS_CONTENT']:
                    if rating.probability in ['HIGH', 'MEDIUM']:
                        return "Translation failed: Response blocked by safety filter"
    
    # å®‰å…¨åœ°å­˜å–å›æ‡‰æ–‡å­—
    try:
        if response.text:
            english_text = response.text.strip()
            return english_text
        else:
            return "Translation failed: Empty response"
    except Exception as text_error:
        logger.error(f"ç„¡æ³•å­˜å–å›æ‡‰æ–‡å­—: {text_error}")
        return "Translation failed: Cannot access response text"


# ==================== è¼”åŠ©åŠŸèƒ½ ====================

def get_or_create_session(user_email: str, question: str) -> dict:
    """ç²å–æˆ–å‰µå»ºå­¸ç¿’æœƒè©±"""
    # ä½¿ç”¨ç”¨æˆ¶email + é¡Œç›®å…§å®¹çš„çµ„åˆï¼Œç¢ºä¿æ¯å€‹ç”¨æˆ¶çš„æ¯é“é¡Œç›®éƒ½æœ‰ç¨ç«‹æœƒè©±
    clean_question = question.strip().replace('\n', ' ').replace('\r', ' ')
    # çµ„åˆç”¨æˆ¶emailå’Œé¡Œç›®hashï¼Œç¢ºä¿å”¯ä¸€æ€§
    session_key = f"{user_email}_question_{hash(clean_question)}"
    
    # é¡¯ç¤ºç•¶å‰ç”¨æˆ¶çš„æ‰€æœ‰æœƒè©±
    user_sessions = [key for key in learning_sessions.keys() if key.startswith(f"{user_email}_")]
    
    # é¡¯ç¤ºæœƒè©±çµ±è¨ˆä¿¡æ¯
    if learning_sessions:
        # çµ±è¨ˆä¸åŒç”¨æˆ¶çš„æœƒè©±æ•¸é‡
        user_counts = {}
        for key in learning_sessions.keys():
            if '_question_' in key:
                user_part = key.split('_question_')[0]
                user_counts[user_part] = user_counts.get(user_part, 0) + 1
        

    
    # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨æœƒè©±
    if session_key in learning_sessions:
        existing_session = learning_sessions[session_key]
        return existing_session
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°æœƒè©±ï¼Œå‰µå»ºæ–°æœƒè©±
    learning_sessions[session_key] = {
        'user_email': user_email,
        'question': question,
        'conversation_history': [],
        'understanding_level': 0,
        'learning_stage': 'core_concept_confirmation',
        'concept_progress': [],
        'created_at': datetime.now().isoformat()
    }
    
    # ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶
    #save_sessions_to_file()

    
    return learning_sessions[session_key]

def build_initial_prompt(question: str, user_answer: str, correct_answer: str, grading_feedback: dict = None) -> str:
    """æ§‹å»ºåˆå§‹åŒ–æç¤ºè©"""
    
    # å¦‚æœæœ‰AIæ‰¹æ”¹çš„è©•åˆ†åé¥‹ï¼ŒåŠ å…¥æç¤ºè©ä¸­
    feedback_section = ""
    if grading_feedback:
        feedback_section = f"""

**AIæ‰¹æ”¹è©•åˆ†åé¥‹ï¼ˆè«‹åƒè€ƒä½¿ç”¨ï¼‰ï¼š**
- å„ªé»ï¼š{grading_feedback.get('strengths', 'ç„¡')}
- éœ€è¦æ”¹é€²ï¼š{grading_feedback.get('weaknesses', 'ç„¡')}
- å­¸ç¿’å»ºè­°ï¼š{grading_feedback.get('suggestions', 'ç„¡')}
- è©•åˆ†èªªæ˜ï¼š{grading_feedback.get('explanation', 'ç„¡')}
"""
    
    return f"""{TEACHER_STYLE}

**é¡Œç›®ï¼š** {question}
**å­¸ç”Ÿç­”æ¡ˆï¼š** {user_answer}
**æ­£ç¢ºç­”æ¡ˆï¼š** {correct_answer}{feedback_section}

è«‹åˆ†æå­¸ç”Ÿçš„ç­”æ¡ˆï¼Œæ‰¾å‡ºéœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼Œä¸¦æå‡ºä¸€å€‹å…·é«”çš„å¼•å°å•é¡Œä¾†é–‹å§‹æ•™å­¸ã€‚

**é‡è¦ï¼š** åˆå§‹åŒ–éšæ®µä¸çµ¦åˆ†æ•¸ï¼Œåªæå‡ºå¼•å°å•é¡Œã€‚

**å›æ‡‰è¦æ±‚ï¼š**
- èªæ°£è¦ªåˆ‡è‡ªç„¶ï¼Œå¦‚åŒçœŸæ­£çš„è€å¸«
- åˆ†æå­¸ç”Ÿç­”æ¡ˆçš„å„ªç¼ºé»ï¼ˆå¯åƒè€ƒAIæ‰¹æ”¹åé¥‹ï¼‰
- æå‡ºå…·é«”çš„å¼•å°å•é¡Œ
- ä¸è¦çµ¦å‡ºè©•åˆ†ï¼ˆåˆå§‹åŒ–éšæ®µï¼‰
- çµ•å°ä¸è¦åŒ…å«ã€Œè©•åˆ†ï¼šã€å­—æ¨£

è«‹ç¾åœ¨ç”Ÿæˆé–‹å ´ç™½ï¼š"""

def build_followup_prompt(question: str, user_answer: str, correct_answer: str, user_input: str, conversation_history: list, grading_feedback: dict = None) -> str:
    """æ§‹å»ºå¾ŒçºŒå°è©±æç¤ºè©"""
    # ç²å–ç•¶å‰å­¸ç¿’éšæ®µæŒ‡å°
    current_stage = 'core_concept_confirmation'  # é è¨­å€¼
    
    # å¾å°è©±æ­·å²ä¸­æ¨æ–·ç•¶å‰éšæ®µï¼Œè€Œä¸æ˜¯é‡æ–°æŸ¥æ‰¾æœƒè©±
    if conversation_history:
        # æ ¹æ“šå°è©±é•·åº¦åˆ¤æ–·éšæ®µ
        if len(conversation_history) >= 6:  # 3è¼ªå°è©±
            current_stage = 'related_concept_guidance'
        elif len(conversation_history) >= 4:  # 2è¼ªå°è©±
            current_stage = 'core_concept_confirmation'
        else:
            current_stage = 'core_concept_confirmation'
    
    stage_guidance = get_stage_guidance(current_stage)
    
    # å¦‚æœæœ‰AIæ‰¹æ”¹çš„è©•åˆ†åé¥‹ï¼ŒåŠ å…¥æç¤ºè©ä¸­
    feedback_section = ""
    if grading_feedback:
        feedback_section = f"""

**AIæ‰¹æ”¹è©•åˆ†åé¥‹ï¼ˆè«‹åƒè€ƒä½¿ç”¨ï¼‰ï¼š**
- å„ªé»ï¼š{grading_feedback.get('strengths', 'ç„¡')}
- éœ€è¦æ”¹é€²ï¼š{grading_feedback.get('weaknesses', 'ç„¡')}
- å­¸ç¿’å»ºè­°ï¼š{grading_feedback.get('suggestions', 'ç„¡')}
- è©•åˆ†èªªæ˜ï¼š{grading_feedback.get('explanation', 'ç„¡')}
"""
    
    return f"""{TEACHER_STYLE}

**é¡Œç›®ï¼š** {question}
**æ­£ç¢ºç­”æ¡ˆï¼š** {correct_answer}
**å­¸ç”Ÿæœ€æ–°å›ç­”ï¼š** {user_input}{feedback_section}

**å°è©±æ­·å²ï¼š**
{format_conversation_history(conversation_history)}

**ç•¶å‰å­¸ç¿’éšæ®µæŒ‡å°ï¼š**
{stage_guidance}

è«‹åŸºæ–¼å­¸ç”Ÿçš„å›ç­”é€²è¡Œæ•™å­¸æŒ‡å°ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œï¼š

**æ•™å­¸æ­¥é©Ÿï¼š**
1. **è©•ä¼°å­¸ç”Ÿå›ç­”**ï¼šåˆ†æå­¸ç”Ÿå›ç­”çš„è³ªé‡
2. **çµ¦å‡ºæ­£ç¢ºç­”æ¡ˆ**ï¼šå¦‚æœå­¸ç”Ÿå›ç­”éŒ¯èª¤ï¼Œç›´æ¥çµ¦å‡ºæ­£ç¢ºç­”æ¡ˆ
3. **æå‡ºä¸‹ä¸€å€‹å•é¡Œ**ï¼šåŸºæ–¼ç•¶å‰é€²åº¦ï¼Œæå‡ºç›¸é—œçš„å»¶ä¼¸å•é¡Œ
4. **çµ¦å‡ºè©•åˆ†**ï¼šæ ¹æ“šå­¸ç”Ÿå›ç­”è³ªé‡çµ¦äºˆé©ç•¶åˆ†æ•¸

**é‡è¦è¦æ±‚ï¼š**
- ä¸è¦é‡è¤‡å•å­¸ç”Ÿã€Œä½ çŸ¥é“å—ï¼Ÿã€æˆ–ã€Œä½ è¦ºå¾—å‘¢ï¼Ÿã€
- å¦‚æœå­¸ç”Ÿå›ç­”éŒ¯èª¤ï¼Œç›´æ¥çµ¦å‡ºæ­£ç¢ºç­”æ¡ˆ
- é¿å…é™·å…¥å¾ªç’°æå•
- æ¯æ¬¡éƒ½è¦çµ¦å‡ºè©•åˆ†

**è©•åˆ†é‚è¼¯ï¼š**
1. ç¬¬ä¸€å€‹å•é¡Œï¼šæ ¹æ“šå­¸ç”Ÿå›ç­”è³ªé‡ï¼Œçµ¦äºˆ0-95åˆ†çš„åŸºç¤è©•åˆ†
2. å¾ŒçºŒå•é¡Œï¼šåŸºæ–¼ç•¶å‰åˆ†æ•¸ï¼Œçµ¦äºˆé©ç•¶åŠ åˆ†ï¼ˆ1-10åˆ†ï¼‰
3. é”åˆ°95åˆ†æ™‚ï¼šé€²å…¥åå‘æ•™å°éšæ®µ
4. åå‘æ•™å°å®Œæˆï¼šç›´æ¥çµ¦å‡º100åˆ†

**é‡è¦æé†’ï¼š**
- ä½ å¿…é ˆåœ¨å›æ‡‰çš„æœ€å¾Œçµ¦å‡ºè©•åˆ†ï¼Œæ ¼å¼ç‚ºã€Œè©•åˆ†ï¼š[åˆ†æ•¸]åˆ†ã€
- è©•åˆ†ç¯„åœï¼š0-100åˆ†
- æ ¹æ“šå­¸ç”Ÿå›ç­”çš„è³ªé‡çµ¦äºˆé©ç•¶åˆ†æ•¸
- é€™æ˜¯å¼·åˆ¶è¦æ±‚ï¼Œå¿…é ˆéµå®ˆï¼
- å¦‚æœæ²’æœ‰è©•åˆ†ï¼Œç³»çµ±å°‡ç„¡æ³•æ­£å¸¸å·¥ä½œï¼

**è©•åˆ†æ ¼å¼ç¤ºä¾‹ï¼š**
åŒå­¸ï¼Œä½ çš„å›ç­”å¾ˆå¥½ï¼è®“æˆ‘å€‘ç¹¼çºŒæ·±å…¥æ¢è¨...

è©•åˆ†ï¼š85åˆ†

**å†æ¬¡å¼·èª¿ï¼š**
- å›æ‡‰çš„æœ€å¾Œå¿…é ˆåŒ…å«ã€Œè©•åˆ†ï¼š[åˆ†æ•¸]åˆ†ã€
- é€™æ˜¯ç³»çµ±é‹ä½œçš„å¿…è¦æ¢ä»¶
- è«‹åš´æ ¼éµå®ˆè©•åˆ†æ ¼å¼è¦æ±‚ï¼

è«‹ç¾åœ¨åˆ†æå­¸ç”Ÿçš„å›ç­”ä¸¦æä¾›æ•™å­¸æŒ‡å°ï¼š"""

def format_conversation_history(conversation_history: list) -> str:
    """æ ¼å¼åŒ–å°è©±æ­·å²"""
    if not conversation_history:
        return "ç„¡"
    
    formatted = ""
    for i, msg in enumerate(conversation_history[-4:], 1):  # åªé¡¯ç¤ºæœ€è¿‘4æ¢
        role = "å­¸ç”Ÿ" if msg['role'] == 'user' else "AIå°å¸«"
        formatted += f"{i}. {role}: {msg['content'][:100]}...\n"
    
    return formatted

def determine_learning_stage(understanding_level: int) -> str:
    """æ ¹æ“šç†è§£ç¨‹åº¦ç¢ºå®šå­¸ç¿’éšæ®µ"""
    if understanding_level >= 95:
        return 'understanding_verification'      # åå‘æ•™å°
    elif understanding_level >= 80:
        return 'application_understanding'       # æ‡‰ç”¨ç†è§£
    elif understanding_level >= 60:
        return 'application_understanding'       # æ‡‰ç”¨ç†è§£
    elif understanding_level >= 30:
        return 'related_concept_guidance'        # ç›¸é—œæ¦‚å¿µå¼•å°
    else:
        return 'core_concept_confirmation'       # æ ¸å¿ƒæ¦‚å¿µç¢ºèª

def get_stage_guidance(stage: str) -> str:
    """æ ¹æ“šå­¸ç¿’éšæ®µæä¾›æŒ‡å°"""
    stage_guidance = {
        'core_concept_confirmation': f"""
æ‚¨ç›®å‰è™•æ–¼æ ¸å¿ƒæ¦‚å¿µç¢ºèªéšæ®µã€‚è«‹ï¼š
- å¾é€™é“é¡Œç›®æœ€æ ¸å¿ƒçš„æ¦‚å¿µé–‹å§‹æå•
- è©•ä¼°å­¸ç”Ÿå°é¡Œç›®æ ¸å¿ƒæ¦‚å¿µçš„æŒæ¡ç¨‹åº¦
- å¦‚æœå­¸ç”Ÿå°æ ¸å¿ƒæ¦‚å¿µä¸æ¸…æ¥šï¼Œè«‹å…ˆè§£é‡‹æ ¸å¿ƒæ¦‚å¿µ
- é¿å…è·³è„«åˆ°ä¸ç›¸é—œçš„åŸºç¤æ¦‚å¿µï¼Œçµ•å°å¿…é ˆä¿æŒèˆ‡é¡Œç›®çš„ç›¸é—œæ€§
""",
        'related_concept_guidance': f"""
æ‚¨ç›®å‰è™•æ–¼ç›¸é—œæ¦‚å¿µå¼•å°éšæ®µã€‚è«‹ï¼š
- åœç¹é¡Œç›®æ ¸å¿ƒæ¦‚å¿µï¼Œé€æ­¥å¼•å°å­¸ç”Ÿç†è§£ç›¸é—œçŸ¥è­˜é»
- ç¢ºä¿æ¯å€‹å•é¡Œéƒ½èˆ‡é¡Œç›®æ ¸å¿ƒæ¦‚å¿µç›¸é—œ
- ä½ å¯ä»¥ä½¿ç”¨å…·é«”ä¾‹å­å¹«åŠ©å­¸ç”Ÿç†è§£æŠ½è±¡æ¦‚å¿µ
- è§€å¯Ÿå­¸ç”Ÿçš„å›ç­”èˆ‡åé¥‹ï¼Œé©æ™‚èª¿æ•´å•é¡Œé›£åº¦
""",
        'application_understanding': f"""
æ‚¨ç›®å‰è™•æ–¼æ‡‰ç”¨ç†è§£éšæ®µã€‚è«‹ï¼š
- è®“å­¸ç”Ÿå°‡ç†è§£æ‡‰ç”¨åˆ°é¡Œç›®æƒ…å¢ƒä¸­
- æä¾›èˆ‡é¡Œç›®ç›¸é—œçš„ç·´ç¿’å•é¡Œæˆ–æ¡ˆä¾‹
- è§€å¯Ÿå­¸ç”Ÿæ˜¯å¦èƒ½æ­£ç¢ºæ‡‰ç”¨æ¦‚å¿µåˆ°é¡Œç›®
- å¦‚æœå­¸ç”Ÿæ‡‰ç”¨æ­£ç¢ºï¼Œå¯ä»¥é€²å…¥ç†è§£é©—è­‰éšæ®µ
""",
        'understanding_verification': f"""
æ‚¨ç›®å‰è™•æ–¼ç†è§£é©—è­‰éšæ®µã€‚è«‹ï¼š
- è¦æ±‚å­¸ç”Ÿç”¨è‡ªå·±çš„è©±é‡æ–°è§£é‡‹é¡Œç›®å’Œç­”æ¡ˆ
- è©•ä¼°å­¸ç”Ÿæ˜¯å¦çœŸæ­£ç†è§£äº†é¡Œç›®å’Œç­”æ¡ˆçš„é‚è¼¯
- å¦‚æœå­¸ç”Ÿè§£é‡‹æ¸…æ¥šï¼Œå¯ä»¥é€²å…¥ä¸‹ä¸€é¡Œæˆ–ä¸‹ä¸€éšæ®µ
- å¦‚æœå­¸ç”Ÿè§£é‡‹ä¸æ¸…æ¥šï¼Œä½ ç›´æ¥çµ¦å‡ºæ­£ç¢ºç­”æ¡ˆï¼Œå¹«åŠ©å­¸ç”Ÿæ›´åŠ ç†è§£é¡Œç›®è·Ÿç­”æ¡ˆ
"""
    }
    
    return stage_guidance.get(stage, stage_guidance['core_concept_confirmation'])

def get_stage_display_name(stage: str) -> str:
    """ç²å–å­¸ç¿’éšæ®µçš„ä¸­æ–‡é¡¯ç¤ºåç¨±"""
    stage_names = {
        'core_concept_confirmation': 'æ ¸å¿ƒæ¦‚å¿µç¢ºèª',
        'related_concept_guidance': 'ç›¸é—œæ¦‚å¿µå¼•å°',
        'application_understanding': 'æ‡‰ç”¨ç†è§£',
        'understanding_verification': 'ç†è§£é©—è­‰',
        'unknown': 'æœªçŸ¥éšæ®µ'
    }
    return stage_names.get(stage, stage)

def record_progress(session: dict, score: int, smart_score: int, stage: str):
    """è¨˜éŒ„å­¸ç¿’é€²åº¦"""
    if 'concept_progress' not in session:
        session['concept_progress'] = []
    
    session['concept_progress'].append({
        'stage': stage,
        'understanding_level': smart_score,
        'score': score,
        'timestamp': datetime.now().isoformat()
    })

def extract_score_from_response(ai_response: str) -> int:
    """å¾AIå›æ‡‰ä¸­æå–è©•åˆ†"""
    try:
        # å°‹æ‰¾è©•åˆ†æ ¼å¼ï¼šè©•åˆ†ï¼š[åˆ†æ•¸]åˆ†
        score_patterns = [
            r'è©•åˆ†[ï¼š:]\s*(\d+)åˆ†',
            r'è©•åˆ†[ï¼š:]\s*(\d+)',
            r'åˆ†æ•¸[ï¼š:]\s*(\d+)åˆ†',
            r'åˆ†æ•¸[ï¼š:]\s*(\d+)',
            r'(\d+)åˆ†',
            r'è©•åˆ†[ï¼š:]\s*(\d+)',
            r'ç†è§£ç¨‹åº¦[ï¼š:]\s*(\d+)',
            r'è©•åˆ†[ï¼š:]\s*(\d+)\s*åˆ†',
            r'è©•åˆ†[ï¼š:]\s*(\d+)\s*',
            r'(\d+)\s*åˆ†',
            r'è©•åˆ†[ï¼š:]\s*(\d+)',
            r'åˆ†æ•¸[ï¼š:]\s*(\d+)'
        ]
        
        for i, pattern in enumerate(score_patterns):
            match = re.search(pattern, ai_response)
            if match:
                score = int(match.group(1))
                if 0 <= score <= 100:
                    return score
                else:
                    print(f"âš ï¸ è©•åˆ†è¶…å‡ºç¯„åœï¼š{score}")
        
        print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•è©•åˆ†æ ¼å¼")
        numbers = re.findall(r'\d+', ai_response)
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°è©•åˆ†ï¼Œå˜—è©¦å¾æœ€å¾Œå¹¾è¡Œä¸­å°‹æ‰¾
        lines = ai_response.strip().split('\n')
        last_lines = lines[-3:] if len(lines) >= 3 else lines
        
        for line in reversed(last_lines):
            if 'è©•åˆ†' in line or 'åˆ†æ•¸' in line:
                # å˜—è©¦æå–æ•¸å­—
                numbers_in_line = re.findall(r'\d+', line)
                if numbers_in_line:
                    score = int(numbers_in_line[0])
                    if 0 <= score <= 100:
                        return score
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ è©•åˆ†æå–å¤±æ•—: {e}")
        return None

def clean_ai_response(ai_response: str) -> str:
    """æ¸…ç†AIå›æ‡‰ï¼Œç§»é™¤è©•åˆ†ç­‰å…§éƒ¨ä¿¡æ¯"""
    try:
        # ç§»é™¤è©•åˆ†æ ¼å¼
        cleaned = re.sub(r'è©•åˆ†[ï¼š:]\s*\d+åˆ†', '', ai_response)
        # æ¸…ç†å¤šé¤˜ç©ºè¡Œ
        cleaned = re.sub(r'\n\s*\n', '\n\n', cleaned)
        cleaned = cleaned.strip()
        
        if not cleaned:
            return "åŒå­¸ï¼Œæˆ‘å·²ç¶“åˆ†æäº†æ‚¨çš„å›ç­”ã€‚è®“æˆ‘å€‘ç¹¼çºŒå­¸ç¿’å§ï¼"
        
        return cleaned
        
    except Exception as e:
        logger.error(f"âŒ å›æ‡‰æ¸…ç†å¤±æ•—: {e}")
        return ai_response

# ==================== åˆå§‹åŒ–å‡½æ•¸ ====================

def init_vector_database():
    """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
    try:
        import os
        
        # ç²å–ç•¶å‰æ–‡ä»¶çš„çµ•å°è·¯å¾‘
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # æ§‹å»ºå‘é‡è³‡æ–™åº«çš„çµ•å°è·¯å¾‘
        db_path = os.path.join(current_dir, "data", "knowledge_db", "chroma_db")
        
        
        chroma_client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # ç²å–æˆ–å‰µå»ºé›†åˆ
        collection = chroma_client.get_or_create_collection(
            name="textbook_knowledge",  # ä½¿ç”¨æœ‰æ•¸æ“šçš„é›†åˆ
            metadata={"hnsw:space": "cosine"}
        )
        
        return chroma_client, collection
        
    except Exception as e:
        logger.warning(f"âš ï¸ å‘é‡è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        return None, None


def call_gemini_api(prompt: str) -> str:
    """èª¿ç”¨Gemini API"""
    try:
        model = init_gemini(model_name = 'gemini-1.5-flash')
        if not model:
            return "æŠ±æ­‰ï¼ŒAIæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
        # è¨­ç½®ç”Ÿæˆåƒæ•¸ï¼Œç¢ºä¿å›æ‡‰å®Œæ•´
        generation_config = {
            'max_output_tokens': 4000,  # å¢åŠ æœ€å¤§è¼¸å‡ºé•·åº¦
            'temperature': 0.7,
            'top_p': 0.8,
            'top_k': 40
        }
        
        response = model.generate_content(prompt, generation_config=generation_config)
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰æ•ˆ
        if not response or not hasattr(response, 'text'):
            return "æŠ±æ­‰ï¼ŒAIå›æ‡‰æ ¼å¼ä¸æ­£ç¢ºï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
        # æª¢æŸ¥å®‰å…¨è©•ç´š
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
                # æª¢æŸ¥æ˜¯å¦æœ‰å®‰å…¨å•é¡Œ
                for rating in candidate.safety_ratings:
                    if rating.category in ['HARM_CATEGORY_HARASSMENT', 'HARM_CATEGORY_HATE_SPEECH', 
                                         'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'HARM_CATEGORY_DANGEROUS_CONTENT']:
                        if rating.probability in ['HIGH', 'MEDIUM']:
                            return "æŠ±æ­‰ï¼ŒAIå›æ‡‰è¢«å®‰å…¨éæ¿¾å™¨é˜»æ“‹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
        # å®‰å…¨åœ°å­˜å–å›æ‡‰æ–‡å­—
        try:
            return response.text
        except Exception as text_error:
            logger.error(f"ç„¡æ³•å­˜å–å›æ‡‰æ–‡å­—: {text_error}")
            return "æŠ±æ­‰ï¼Œç„¡æ³•å­˜å–AIå›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
    except Exception as e:
        logger.error(f"âŒ Gemini APIèª¿ç”¨å¤±æ•—: {e}")
        return "æŠ±æ­‰ï¼ŒAIå›æ‡‰ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
