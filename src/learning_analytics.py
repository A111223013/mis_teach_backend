import logging
import math
import json
import time
import os
import threading
import concurrent.futures
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from collections import defaultdict
from flask import Blueprint, request, jsonify
from sqlalchemy import text
from accessories import sqldb, mongo, init_gemini, redis_client
from bson import ObjectId
from src.api import get_user_info
from src.quiz_generator import generate_quiz_by_ai

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

# å‰µå»ºè—åœ–
analytics_bp = Blueprint('learning_analytics', __name__)

def get_student_quiz_records(user_email: str) -> List[Dict]:
    """ç²å–å­¸ç”Ÿçš„ç­”é¡Œè¨˜éŒ„"""
    try:
        # æŸ¥è©¢ç­”é¡Œè¨˜éŒ„ï¼Œç›´æ¥å¾ quiz_answers è¡¨ç²å–
        query = text("""
            SELECT 
                qa.answer_id as answer_id,
                qa.mongodb_question_id as question_id,
                qa.created_at as attempt_time,
                qa.answer_time_seconds as time_spent,
                qa.is_correct
            FROM quiz_answers qa
            WHERE qa.user_email = :user_email
            ORDER BY qa.created_at DESC
        """)
        
        result = sqldb.session.execute(query, {"user_email": user_email})
        records = result.fetchall()
        
        quiz_records = []
        for row in records:
            # å¾ MongoDB ç²å–é¡Œç›®è©³ç´°ä¿¡æ¯
            question_doc = mongo.db.exam.find_one({"_id": ObjectId(row.question_id)})
            if question_doc:
                # è™•ç†å¾®æ¦‚å¿µæ•¸çµ„
                micro_concepts = question_doc.get('micro_concepts', [])
                micro_concept_id = str(micro_concepts[0]) if micro_concepts else ''
                
                # å¾key-pointsç²å–é ˜åŸŸä¿¡æ¯
                key_points = question_doc.get('key-points', '')
                
                # ç²å–é›£åº¦ä¿¡æ¯ï¼Œè™•ç†ä¸åŒçš„å­—æ®µå
                difficulty = (question_doc.get('difficulty level') or 
                            question_doc.get('difficulty') or 
                            question_doc.get('level') or 
                            'ä¸­ç­‰')
                
                # ç²å–é ˜åŸŸä¿¡æ¯ - å˜—è©¦å¤šå€‹å­—æ®µ
                domain_name = (question_doc.get('domain') or 
                             question_doc.get('subject') or 
                             question_doc.get('field') or 
                             key_points or 
                             'æœªçŸ¥é ˜åŸŸ')
                
                quiz_records.append({
                    'id': row.answer_id,
                    'question_id': row.question_id,
                    'attempt_time': row.attempt_time.isoformat() + 'Z',
                    'time_spent': row.time_spent or 0,
                    'is_correct': bool(row.is_correct),
                    'micro_concept_id': micro_concept_id,
                    'domain_name': domain_name,  # ä½¿ç”¨æ›´æº–ç¢ºçš„é ˜åŸŸåç¨±
                    'difficulty': difficulty,
                    'key_points': key_points  # ä¿ç•™åŸå§‹key-pointsç”¨æ–¼èª¿è©¦
                })
        
        logger.info(f"ç²å–åˆ° {len(quiz_records)} æ¢ç­”é¡Œç´€éŒ„")
        
        # èª¿è©¦ä¿¡æ¯ï¼šé¡¯ç¤ºé ˜åŸŸåˆ†ä½ˆ
        domain_counts = {}
        for record in quiz_records:
            domain = record['domain_name']
            domain_counts[domain] = domain_counts.get(domain, 0) + 1
        
        return quiz_records
            
    except Exception as e:
        logger.error(f"ç²å–å­¸ç”Ÿç­”é¡Œç´€éŒ„å¤±æ•—: {str(e)}")
        return []

def calculate_difficulty_statistics(quiz_records: List[Dict]) -> Dict[str, Any]:
    """è¨ˆç®—å„é›£åº¦çš„çµ±è¨ˆæ•¸æ“š"""
    if not quiz_records:
        return {
            'easy': {'total': 0, 'correct': 0, 'accuracy': 0.0, 'mastery': 0.0},
            'medium': {'total': 0, 'correct': 0, 'accuracy': 0.0, 'mastery': 0.0},
            'hard': {'total': 0, 'correct': 0, 'accuracy': 0.0, 'mastery': 0.0}
        }
    
    difficulty_stats = {
        'easy': {'total': 0, 'correct': 0, 'records': []},
        'medium': {'total': 0, 'correct': 0, 'records': []},
        'hard': {'total': 0, 'correct': 0, 'records': []}
    }
    
    # çµ±è¨ˆå„é›£åº¦çš„ç­”é¡Œæƒ…æ³
    for record in quiz_records:
        difficulty = record.get('difficulty', 'ä¸­ç­‰')
        if difficulty == 'ç°¡å–®':
            key = 'easy'
        elif difficulty == 'å›°é›£':
            key = 'hard'
        else:
            key = 'medium'
        
        difficulty_stats[key]['total'] += 1
        difficulty_stats[key]['records'].append(record)
        if record.get('is_correct', False):
            difficulty_stats[key]['correct'] += 1
    
    # è¨ˆç®—æº–ç¢ºç‡å’ŒæŒæ¡åº¦
    result = {}
    for key, stats in difficulty_stats.items():
        total = stats['total']
        correct = stats['correct']
        accuracy = correct / total if total > 0 else 0.0
        
        # è¨ˆç®—è©²é›£åº¦çš„æŒæ¡åº¦
        mastery = calculate_mixed_mastery(stats['records']) if stats['records'] else 0.0
        
        result[key] = {
            'total': total,
            'correct': correct,
            'accuracy': round(accuracy, 3),
            'mastery': round(mastery, 3)
        }
    
    return result

def calculate_historical_metrics(quiz_records: List[Dict], trend_days: int) -> Dict[str, Any]:
    """è¨ˆç®—æ­·å²æ•¸æ“šç”¨æ–¼è¶¨å‹¢åˆ†æ"""
    if not quiz_records:
        return {
            'learning_velocity': 0,
            'retention_rate': 0,
            'avg_time_per_concept': 0,
            'focus_score': 0
        }
    
    # è¨ˆç®—æ­·å²æœŸé–“ï¼ˆå‰ä¸€å€‹é€±æœŸï¼‰
    from datetime import datetime, timedelta
    current_time = datetime.now()
    historical_start = current_time - timedelta(days=trend_days*2)
    historical_end = current_time - timedelta(days=trend_days)
    
    # ç¯©é¸æ­·å²æœŸé–“çš„è¨˜éŒ„
    historical_records = []
    for record in quiz_records:
        try:
            record_time = datetime.fromisoformat(record['attempt_time'].replace('Z', '+00:00'))
            if historical_start <= record_time < historical_end:
                historical_records.append(record)
        except:
            continue
    
    # å¦‚æœæ²’æœ‰æ­·å²æ•¸æ“šï¼Œè¿”å›ç•¶å‰æ•¸æ“šçš„80%ä½œç‚ºåŸºæº–
    if not historical_records:
        current_metrics = calculate_learning_metrics(quiz_records)
        return {
            'learning_velocity': current_metrics['learning_velocity'] * 0.8,
            'retention_rate': current_metrics['retention_rate'] * 0.8,
            'avg_time_per_concept': current_metrics['avg_time_per_concept'] * 1.2,  # æ™‚é–“è¶Šå°‘è¶Šå¥½
            'focus_score': current_metrics['focus_score'] * 0.8
        }
    
    # è¨ˆç®—æ­·å²æŒ‡æ¨™
    return calculate_learning_metrics(historical_records)

def calculate_learning_metrics(quiz_records: List[Dict]) -> Dict[str, Any]:
    """è¨ˆç®—å­¸ç¿’æ•ˆç‡æŒ‡æ¨™"""
    if not quiz_records:
        return {
            'learning_velocity': 0,
            'retention_rate': 0,
            'avg_time_per_concept': 0,
            'focus_score': 0,
            'overall_mastery': 0
        }
    
    # å­¸ç¿’é€Ÿåº¦ï¼šä½¿ç”¨å¢å¼·ç‰ˆæ¼”ç®—æ³•
    learning_velocity = calculate_enhanced_learning_velocity(quiz_records)
    
    # ä¿æŒç‡ï¼šä½¿ç”¨å¢å¼·ç‰ˆéºå¿˜æ„ŸçŸ¥æ¼”ç®—æ³•
    retention_rate = calculate_enhanced_retention_rate(quiz_records)
    
    # å¹³å‡æ¯æ¦‚å¿µæ™‚é–“ï¼šä½¿ç”¨å¢å¼·ç‰ˆæ™‚é–“åˆ†ææ¼”ç®—æ³•
    avg_time_per_concept = calculate_enhanced_avg_time_per_concept(quiz_records)
    
    # å°ˆæ³¨åº¦ï¼šä½¿ç”¨å¢å¼·ç‰ˆå°ˆæ³¨åº¦åˆ†ææ¼”ç®—æ³•
    focus_score = calculate_enhanced_focus_score(quiz_records) * 10  # è½‰æ›ç‚º10åˆ†åˆ¶
        
    # ä½¿ç”¨æ··åˆæ¼”ç®—æ³•è¨ˆç®—æ•´é«”æŒæ¡åº¦
    overall_mastery = calculate_mixed_mastery(quiz_records)
    difficulty_aware_mastery = overall_mastery
    forgetting_aware_mastery = overall_mastery
    
    # è¨ˆç®—é¡å¤–çš„çµ±è¨ˆæ•¸æ“š
    total_questions = len(quiz_records)
    correct_questions = sum(1 for r in quiz_records if r.get('is_correct', False))
    wrong_questions = total_questions - correct_questions
    accuracy_rate = correct_questions / total_questions if total_questions > 0 else 0
    error_rate = wrong_questions / total_questions if total_questions > 0 else 0
    
    # è¨ˆç®—å„é›£åº¦çš„çµ±è¨ˆ
    difficulty_stats = calculate_difficulty_statistics(quiz_records)
    
    return {
        'learning_velocity': round(learning_velocity, 1),
        'retention_rate': round(retention_rate, 3),  # ä¿æŒ0-1ç¯„åœï¼Œå‰ç«¯æœƒè½‰æ›ç‚ºç™¾åˆ†æ¯”
        'avg_time_per_concept': round(avg_time_per_concept, 1),
        'focus_score': round(focus_score, 1),
        'overall_mastery': round(overall_mastery, 3),
        'difficulty_aware_mastery': round(difficulty_aware_mastery, 3),
        'forgetting_aware_mastery': round(forgetting_aware_mastery, 3),
        # æ–°å¢çµ±è¨ˆæ•¸æ“š
        'total_questions': total_questions,
        'correct_questions': correct_questions,
        'wrong_questions': wrong_questions,
        'accuracy_rate': round(accuracy_rate, 3),
        'error_rate': round(error_rate, 3),
        'difficulty_stats': difficulty_stats
    }

def calculate_concept_mastery(quiz_records: List[Dict], concept_id: str) -> Dict[str, Any]:
    """è¨ˆç®—ç‰¹å®šæ¦‚å¿µçš„æŒæ¡åº¦ - ä½¿ç”¨æ–°çš„Knowledge Tracingæ¼”ç®—æ³•"""
    concept_records = [r for r in quiz_records if r['micro_concept_id'] == concept_id]
    
    if not concept_records:
        return {
            'mastery': 0,
            'attempts': 0,
            'correct': 0,
            'wrong_count': 0,
            'recent_accuracy': 0,
            'trend': 'stable',
            'difficulty_breakdown': {'ç°¡å–®': 0, 'ä¸­ç­‰': 0, 'å›°é›£': 0},
            'forgetting_analysis': {
                'base_mastery': 0,
                'current_mastery': 0,
                'days_since_practice': 0,
                'review_urgency': 'low'
            }
        }
    
    # ä½¿ç”¨æ–°çš„æ¼”ç®—æ³•è¨ˆç®—æŒæ¡åº¦
    difficulty_data = calculate_difficulty_aware_mastery(quiz_records, concept_id)
    forgetting_data = calculate_forgetting_aware_mastery(concept_records, concept_id)
    
    # ä½¿ç”¨é›£åº¦æ„ŸçŸ¥çš„æŒæ¡åº¦ä½œç‚ºä¸»è¦æŒæ¡åº¦
    enhanced_mastery = difficulty_data['overall_mastery']
    
    # è¨ˆç®—åŸºæœ¬çµ±è¨ˆæ•¸æ“š
    total_attempts = len(concept_records)
    correct_attempts = sum(1 for r in concept_records if r['is_correct'])
    wrong_count = total_attempts - correct_attempts
    
    # æœ€è¿‘5æ¬¡ç­”é¡Œçš„æ­£ç¢ºç‡
    recent_records = concept_records[:5]
    recent_correct = sum(1 for r in recent_records if r['is_correct'])
    recent_accuracy = recent_correct / len(recent_records) if recent_records else 0
    
    # è¶¨å‹¢åˆ†æï¼ˆåŸºæ–¼éºå¿˜æ„ŸçŸ¥çš„æŒæ¡åº¦è®ŠåŒ–ï¼‰
    base_mastery = forgetting_data['base_mastery']
    current_mastery = forgetting_data['current_mastery']
    
    if current_mastery > base_mastery + 0.1:
            trend = 'improving'
    elif current_mastery < base_mastery - 0.1:
            trend = 'declining'
    else:
        trend = 'stable'
    
    return {
        'mastery': round(enhanced_mastery, 2),  # ä½¿ç”¨æ–°æ¼”ç®—æ³•çš„æŒæ¡åº¦
        'attempts': total_attempts,
        'correct': correct_attempts,
        'wrong_count': wrong_count,
        'recent_accuracy': round(recent_accuracy, 2),
        'trend': trend,
        # æ–°æ¼”ç®—æ³•çš„è©³ç´°çµæœ
        'difficulty_breakdown': difficulty_data['difficulty_breakdown'],
        'forgetting_analysis': {
            'base_mastery': forgetting_data['base_mastery'],
            'current_mastery': forgetting_data['current_mastery'],
            'days_since_practice': forgetting_data['days_since_practice'],
            'review_urgency': forgetting_data['review_urgency']
        },
        'difficulty_analysis': difficulty_data['difficulty_analysis']
    }

def calculate_difficulty_aware_mastery(quiz_records: List[Dict], concept_id: str) -> Dict[str, Any]:
    """è¨ˆç®—é›£åº¦æ„ŸçŸ¥çš„æŒæ¡åº¦ - Difficulty-aware KT"""
    # å¦‚æœæ˜¯é ˜åŸŸIDï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰è¨˜éŒ„ï¼›å¦‚æœæ˜¯å¾®æ¦‚å¿µIDï¼Œå‰‡ç¯©é¸
    if len(concept_id) == 24:  # MongoDB ObjectIdé•·åº¦
        # å¯èƒ½æ˜¯é ˜åŸŸIDï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰è¨˜éŒ„
        concept_records = quiz_records
    else:
        # å¾®æ¦‚å¿µIDï¼ŒæŒ‰micro_concept_idç¯©é¸
        concept_records = [r for r in quiz_records if r['micro_concept_id'] == concept_id]
    
    if not concept_records:
        return {
            'overall_mastery': 0,
            'difficulty_breakdown': {'ç°¡å–®': 0, 'ä¸­ç­‰': 0, 'å›°é›£': 0},
            'difficulty_analysis': {
                'easy_mastery': 0,
                'medium_mastery': 0,
                'hard_mastery': 0,
                'bottleneck_level': 'none',
                'recommended_difficulty': 'ç°¡å–®'
            }
        }
    
    # æŒ‰é›£åº¦åˆ†çµ„çµ±è¨ˆ
    difficulty_stats = {}
    for record in concept_records:
        difficulty = record.get('difficulty', 'ä¸­ç­‰')
        if difficulty not in difficulty_stats:
            difficulty_stats[difficulty] = {'total': 0, 'correct': 0}
        difficulty_stats[difficulty]['total'] += 1
        if record['is_correct']:
            difficulty_stats[difficulty]['correct'] += 1
    # è¨ˆç®—å„é›£åº¦æŒæ¡åº¦
    difficulty_breakdown = {}
    for difficulty in ['ç°¡å–®', 'ä¸­ç­‰', 'å›°é›£']:
        if difficulty in difficulty_stats:
            stats = difficulty_stats[difficulty]
            mastery = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
            difficulty_breakdown[difficulty] = round(mastery, 2)
        else:
            difficulty_breakdown[difficulty] = 0
    
    # è¨ˆç®—åŠ æ¬ŠæŒæ¡åº¦ï¼ˆå›°é›£é¡Œæ¬Šé‡æ›´é«˜ï¼‰
    difficulty_weights = {'ç°¡å–®': 1, 'ä¸­ç­‰': 2, 'å›°é›£': 3}
    weighted_mastery = 0
    total_weight = 0
    
    for difficulty, stats in difficulty_stats.items():
        weight = difficulty_weights.get(difficulty, 2)
        mastery = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        weighted_mastery += mastery * weight
        total_weight += weight
    
    overall_mastery = weighted_mastery / total_weight if total_weight > 0 else 0
    
    # åˆ†æå­¸ç¿’ç“¶é ¸
    easy_mastery = difficulty_breakdown.get('ç°¡å–®', 0)
    medium_mastery = difficulty_breakdown.get('ä¸­ç­‰', 0)
    hard_mastery = difficulty_breakdown.get('å›°é›£', 0)
    
    if easy_mastery < 0.6:
        bottleneck_level = 'easy'
        recommended_difficulty = 'ç°¡å–®'
    elif medium_mastery < 0.6:
        bottleneck_level = 'medium'
        recommended_difficulty = 'ä¸­ç­‰'
    elif hard_mastery < 0.6:
        bottleneck_level = 'hard'
        recommended_difficulty = 'å›°é›£'
    else:
        bottleneck_level = 'none'
        recommended_difficulty = 'å›°é›£'  # å¯ä»¥æŒ‘æˆ°æ›´é›£çš„é¡Œç›®
    
    return {
        'overall_mastery': round(overall_mastery, 2),
        'difficulty_breakdown': difficulty_breakdown,
        'difficulty_analysis': {
            'easy_mastery': easy_mastery,
            'medium_mastery': medium_mastery,
            'hard_mastery': hard_mastery,
            'bottleneck_level': bottleneck_level,
            'recommended_difficulty': recommended_difficulty
        }
    }

def calculate_forgetting_aware_mastery(concept_records: List[Dict], concept_id: str) -> Dict[str, Any]:
    """è¨ˆç®—éºå¿˜æ„ŸçŸ¥çš„æŒæ¡åº¦ - Forgetting-aware KT"""
    if not concept_records:
        return {
            'base_mastery': 0,
            'current_mastery': 0,
            'forgetting_factor': 1.0,
            'days_since_practice': 0,
            'review_urgency': 'low',
            'forgetting_curve_data': []
        }
    
    # è¨ˆç®—åŸºç¤æŒæ¡åº¦
    total_attempts = len(concept_records)
    correct_attempts = sum(1 for r in concept_records if r['is_correct'])
    base_mastery = correct_attempts / total_attempts if total_attempts > 0 else 0
    
    # ç²å–æœ€å¾Œç·´ç¿’æ™‚é–“
    last_practice = max(record['attempt_time'] for record in concept_records)
    last_practice_time = datetime.fromisoformat(last_practice.replace('Z', '+00:00'))
    
    # è¨ˆç®—æ™‚é–“å·®ï¼ˆå¤©ï¼‰
    from datetime import timezone
    time_diff = (datetime.now(timezone.utc) - last_practice_time).days
    
    # è¨ˆç®—éºå¿˜è¡°æ¸›å› å­ï¼ˆåŸºæ–¼è‰¾è³“æµ©æ–¯éºå¿˜æ›²ç·šï¼‰
    forgetting_rate = 0.1  # å¯èª¿æ•´åƒæ•¸ï¼Œæ§åˆ¶éºå¿˜é€Ÿåº¦
    forgetting_factor = math.exp(-forgetting_rate * time_diff)
    
    # è¨ˆç®—ç•¶å‰æœ‰æ•ˆæŒæ¡åº¦
    current_mastery = base_mastery * forgetting_factor
    
    # åˆ¤æ–·è¤‡ç¿’ç·Šæ€¥ç¨‹åº¦
    if time_diff > 7:
        review_urgency = 'high'
    elif time_diff > 3:
        review_urgency = 'medium'
    else:
        review_urgency = 'low'
    
    # ç”Ÿæˆéºå¿˜æ›²ç·šæ•¸æ“šï¼ˆç”¨æ–¼å‰ç«¯å±•ç¤ºï¼‰
    forgetting_curve_data = []
    for days in range(0, 15):  # ç”Ÿæˆ15å¤©çš„éºå¿˜æ›²ç·š
        decay_factor = math.exp(-forgetting_rate * days)
        predicted_mastery = base_mastery * decay_factor
        forgetting_curve_data.append({
            'days': days,
            'mastery': round(predicted_mastery, 2)
        })
    
    return {
        'base_mastery': round(base_mastery, 2),
        'current_mastery': round(current_mastery, 2),
        'forgetting_factor': round(forgetting_factor, 2),
        'days_since_practice': time_diff,
        'review_urgency': review_urgency,
        'forgetting_curve_data': forgetting_curve_data
    }

def get_knowledge_structure():
    """ç²å–çŸ¥è­˜çµæ§‹"""
    try:
        domains = list(mongo.db.domain.find({}))
        blocks = list(mongo.db.block.find({}))
        concepts = list(mongo.db.micro_concept.find({}))
        
        return {
            'domains': domains,
            'blocks': blocks,
            'concepts': concepts
        }
    except Exception as e:
        logger.error(f"ç²å–çŸ¥è­˜çµæ§‹å¤±æ•—: {str(e)}")
        return {'domains': [], 'blocks': [], 'concepts': []}

# å·²ç§»é™¤ /overview API - åŠŸèƒ½å·²æ•´åˆåˆ° /init-data
@analytics_bp.route('/ai-diagnosis', methods=['POST', 'OPTIONS'])
def ai_diagnosis():
    """AIè¨ºæ–·ç‰¹å®šçŸ¥è­˜é»"""
    if request.method == 'OPTIONS':
        return jsonify({'success': True})
    
    try:
        data = request.get_json()
        concept_id = data.get('concept_id')
        concept_name = data.get('concept_name', 'æœªçŸ¥æ¦‚å¿µ')
        domain_name = data.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
        if not concept_id:
            logger.error("éŒ¯èª¤: ç¼ºå°‘æ¦‚å¿µID")
            return jsonify({'error': 'ç¼ºå°‘æ¦‚å¿µID'}), 400
        
        # ç²å–ç”¨æˆ¶ä¿¡æ¯
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'ç¼ºå°‘èªè­‰ä¿¡æ¯'}), 401
        
        token = auth_header.split(' ')[1]
        user_email = get_user_info(token, 'email')
        
        if not user_email:
            return jsonify({'error': 'ç„¡æ³•ç²å–ç”¨æˆ¶ä¿¡æ¯'}), 401
        
        # æª¢æŸ¥Rediså¿«å–
        # ä½¿ç”¨æ¨™æº–åŒ–çš„å¿«å–éµæ ¼å¼ï¼šlearning_analytics:ai_diagnosis:{user_email}:{concept_id}:{concept_name}
        # ç¢ºä¿æ¯å€‹çŸ¥è­˜é»éƒ½æœ‰ç¨ç«‹çš„å¿«å–ï¼Œèˆ‡å‰ç«¯å­˜å„²å‘½åä¿æŒä¸€è‡´
        cache_key = f"learning_analytics:ai_diagnosis:{user_email}:{concept_id}:{concept_name}"
        cached_data = redis_client.get(cache_key)
        if cached_data:
            # æª¢æŸ¥éµæ˜¯å¦é‚„æœ‰éæœŸæ™‚é–“ï¼ˆé¿å…ä½¿ç”¨å·²éæœŸçš„å¿«å–ï¼‰
            ttl = redis_client.ttl(cache_key)
            if ttl > 0:
                logger.info(f"âœ… ä½¿ç”¨AIè¨ºæ–·å¿«å–: {cache_key} (å‰©é¤˜ {ttl} ç§’) - è·³éæ‰€æœ‰æŸ¥è©¢")
                return json.loads(cached_data)
            else:
                # å¦‚æœéµå­˜åœ¨ä½†å·²éæœŸï¼Œåˆªé™¤å®ƒï¼ˆRedis æœƒè‡ªå‹•åˆªé™¤ï¼Œä½†æˆ‘å€‘æ˜ç¢ºåˆªé™¤ä»¥ç¢ºä¿ï¼‰
                redis_client.delete(cache_key)
                logger.info(f"â° AIè¨ºæ–·å¿«å–å·²éæœŸï¼Œåˆªé™¤: {cache_key}")
        else:
            logger.info(f"âŒ AIè¨ºæ–·å¿«å–ä¸å­˜åœ¨: {cache_key} - å°‡åŸ·è¡ŒæŸ¥è©¢")
        
        # åªæœ‰åœ¨å¿«å–ä¸å­˜åœ¨æ™‚æ‰åŸ·è¡Œä»¥ä¸‹æŸ¥è©¢
        logger.info(f"ğŸ”„ é–‹å§‹åŸ·è¡ŒAIè¨ºæ–·æŸ¥è©¢æµç¨‹...")
        
        # ç²å–è©²æ¦‚å¿µçš„ç­”é¡Œè¨˜éŒ„
        quiz_records = get_student_quiz_records(user_email)
        
        # å˜—è©¦ç”¨IDå’Œåç¨±åŒ¹é…
        # æ³¨æ„ï¼šmicro_concept_idå­—æ®µå¯¦éš›åŒ…å«çš„æ˜¯æ¦‚å¿µåç¨±ï¼Œä¸æ˜¯ObjectId
        concept_records = [r for r in quiz_records if 
                          r.get('micro_concept_id') == concept_name or  # ç”¨concept_nameåŒ¹é…micro_concept_id
                          r.get('micro_concept_name') == concept_name or
                          str(r.get('micro_concept_id', '')) == str(concept_id)]  # ä¹Ÿå˜—è©¦ObjectIdåŒ¹é…
        
        # ç²å–Neo4jçŸ¥è­˜é»é—œè¯æ•¸æ“š
        knowledge_relations = get_knowledge_relations_from_neo4j(concept_name)
        
        if not concept_records:
            return jsonify({
                'concept_name': concept_name,
                'domain_name': domain_name,
                'diagnosis': 'æš«ç„¡ç­”é¡Œè¨˜éŒ„ï¼Œç„¡æ³•é€²è¡ŒAIè¨ºæ–·ã€‚å»ºè­°å…ˆå®Œæˆç›¸é—œç·´ç¿’é¡Œã€‚',
                'suggestions': [
                    'å®Œæˆè©²çŸ¥è­˜é»çš„åŸºç¤ç·´ç¿’é¡Œ',
                    'é–±è®€ç›¸é—œæ•™æå…§å®¹',
                    'è§€çœ‹æ•™å­¸å½±ç‰‡'
                ],
                'difficulty_level': 'æœªçŸ¥',
                'mastery_level': 0
            })
        
        # è¨ˆç®—æŒæ¡åº¦çµ±è¨ˆ
        total_attempts = len(concept_records)
        correct_attempts = sum(1 for r in concept_records if r['is_correct'])
        mastery = correct_attempts / total_attempts if total_attempts > 0 else 0
        
        # åˆ†æé¡Œç›®é›£æ˜“åº¦åˆ†å¸ƒ
        difficulty_stats = {}
        for record in concept_records:
            # å˜—è©¦å¾ä¸åŒå­—æ®µç²å–é›£æ˜“åº¦
            difficulty = (record.get('difficulty_level') or 
                        record.get('difficulty') or 
                        record.get('level') or 
                        'ä¸­ç­‰')  # é»˜èªè¨­ç‚ºä¸­ç­‰
            if difficulty not in difficulty_stats:
                difficulty_stats[difficulty] = {'total': 0, 'correct': 0}
            difficulty_stats[difficulty]['total'] += 1
            if record['is_correct']:
                difficulty_stats[difficulty]['correct'] += 1
        
        # åˆ†æéŒ¯èª¤æ¨¡å¼
        wrong_records = [r for r in concept_records if not r['is_correct']]
        recent_records = concept_records[:5]  # æœ€è¿‘5æ¬¡ç­”é¡Œ
        recent_accuracy = sum(1 for r in recent_records if r['is_correct']) / len(recent_records) if recent_records else 0
        
        # ç²å–å­¸ç¿’è·¯å¾‘æ¨è–¦
        learning_path_data = calculate_graph_based_mastery(user_email, concept_id)
        
        # ç²å–é›£åº¦åˆ†ææ•¸æ“š
        difficulty_aware_data = calculate_difficulty_aware_mastery(concept_records, concept_id)
        
        # ç²å–éºå¿˜åˆ†ææ•¸æ“š
        forgetting_aware_data = calculate_forgetting_aware_mastery(concept_records, concept_id)
        
        # ç”ŸæˆAIè¨ºæ–·
        diagnosis_result = generate_ai_diagnosis(
            concept_name=concept_name,
            domain_name=domain_name,
            mastery=mastery,
            total_attempts=total_attempts,
            correct_attempts=correct_attempts,
            recent_accuracy=recent_accuracy,
            wrong_records=wrong_records,
            knowledge_relations=knowledge_relations,
            difficulty_stats=difficulty_stats,
            learning_path=learning_path_data['learning_path']
        )
        
        # æ·»åŠ æ–°æ¼”ç®—æ³•çš„æ•¸æ“šåˆ°è¨ºæ–·çµæœ
        diagnosis_result['difficulty_breakdown'] = difficulty_aware_data['difficulty_breakdown']
        diagnosis_result['forgetting_analysis'] = {
            'base_mastery': forgetting_aware_data['base_mastery'],
            'current_mastery': forgetting_aware_data['current_mastery'],
            'days_since_practice': forgetting_aware_data['days_since_practice'],
            'review_urgency': forgetting_aware_data['review_urgency'],
            'forgetting_curve_data': forgetting_aware_data.get('forgetting_curve_data', [])
        }
        
        # å¿«å–è¨ºæ–·çµæœåˆ°Redisï¼ˆ30åˆ†é˜ï¼‰
        # ä½¿ç”¨ SET ... NX EX åŸå­æ“ä½œï¼šåªåœ¨éµä¸å­˜åœ¨æ™‚è¨­ç½®ï¼Œä¸¦è¨­ç½®éæœŸæ™‚é–“
        # é¿å…é‡è¤‡å‰µå»ºç›¸åŒéµåï¼Œç¢ºä¿æ‰€æœ‰å¿«å–éƒ½æœ‰éæœŸæ™‚é–“
        cache_ttl = 30 * 60  # 30åˆ†é˜
        cache_value = json.dumps(diagnosis_result, ensure_ascii=False)
        
        # ä½¿ç”¨åŸå­æ“ä½œ SET ... NX EXï¼šåªåœ¨éµä¸å­˜åœ¨æ™‚å‰µå»ºï¼Œä¸¦è‡ªå‹•è¨­ç½®éæœŸæ™‚é–“
        set_result = redis_client.set(cache_key, cache_value, ex=cache_ttl, nx=True)
        if set_result:
            logger.info(f"AIè¨ºæ–·å·²å¿«å–: {cache_key} (éæœŸæ™‚é–“: {cache_ttl} ç§’)")
        else:
            # éµå·²å­˜åœ¨ï¼Œå¯èƒ½æ˜¯ä¸¦ç™¼è«‹æ±‚å‰µå»ºçš„ï¼Œè¨˜éŒ„ä½†ä¸å ±éŒ¯ï¼ˆé€™æ˜¯æ­£å¸¸æƒ…æ³ï¼‰
            logger.debug(f"AIè¨ºæ–·å¿«å–éµå·²å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯ä¸¦ç™¼è«‹æ±‚ï¼‰ï¼Œè·³éå‰µå»º: {cache_key}")
        
        return jsonify(diagnosis_result)
        
    except Exception as e:
        logger.error(f"AIè¨ºæ–·å¤±æ•—: {e}")
        return jsonify({'error': 'AIè¨ºæ–·å¤±æ•—'}), 500

@analytics_bp.route('/init-data', methods=['POST', 'OPTIONS'])
def init_data():
    if request.method == 'OPTIONS':
        return jsonify({'success': True})
    """åˆå§‹åŒ–å­¸ç¿’åˆ†ææ•¸æ“š - ç²å–æ‰€æœ‰æ•¸æ“š"""
    try:
        # ç²å–è«‹æ±‚åƒæ•¸
        data = request.get_json() or {}
        trend_days = data.get('trendDays', 7)
        
        # å¾è«‹æ±‚ä¸­ç²å–JWT token
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'success': False, 'error': 'ç¼ºå°‘èªè­‰ä»¤ç‰Œ'}), 401
        
        token = auth_header.split(' ')[1]
        user_email = get_user_info(token, 'email')
        
        # ç²å–å­¸ç”Ÿç­”é¡Œç´€éŒ„
        quiz_records = get_student_quiz_records(user_email)
        
        # è¨ˆç®—å­¸ç¿’æŒ‡æ¨™
        learning_metrics = calculate_learning_metrics(quiz_records)
        # ç²å–çŸ¥è­˜çµæ§‹
        knowledge_structure = get_knowledge_structure()
        
        # å¾MongoDBç²å–æ‰€æœ‰é ˜åŸŸ
        all_domains = list(mongo.db.domain.find({}, {'name': 1, '_id': 1}))
        
        # åŸºæ–¼ç­”é¡Œè¨˜éŒ„è¨ˆç®—å„é ˜åŸŸæŒæ¡åº¦
        domain_stats = {}
        
        # çµ±è¨ˆå„é ˜åŸŸçš„ç­”é¡Œæƒ…æ³
        for record in quiz_records:
            domain_name = record.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
            if domain_name not in domain_stats:
                domain_stats[domain_name] = {
                    'total': 0,
                    'correct': 0,
                    'wrong': 0
                }
            
            domain_stats[domain_name]['total'] += 1
            if record['is_correct']:
                domain_stats[domain_name]['correct'] += 1
            else:
                domain_stats[domain_name]['wrong'] += 1
        
        
        # æ§‹å»ºé ˜åŸŸæ•¸æ“š - åŒ…å«æ‰€æœ‰é ˜åŸŸï¼Œå³ä½¿æ²’æœ‰ç­”é¡Œè¨˜éŒ„
        # éæ¿¾æ‰ã€ŒæœªçŸ¥é ˜åŸŸã€
        domains = []
        for domain_doc in all_domains:
            domain_name = domain_doc.get('name', '')
            # è·³éã€ŒæœªçŸ¥é ˜åŸŸã€
            if domain_name == 'æœªçŸ¥é ˜åŸŸ' or domain_name == 'æœªçŸ¥' or not domain_name or domain_name.strip() == '':
                continue
            domain_id = str(domain_doc.get('_id', ''))
            
            # å˜—è©¦åŒ¹é…é ˜åŸŸåç¨±ï¼ˆè™•ç†æ‹¬è™Ÿå’Œè‹±æ–‡éƒ¨åˆ†ï¼‰
            matched_stats = None
            for stats_domain_name, stats in domain_stats.items():
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„æ ¸å¿ƒåç¨±
                if (stats_domain_name in domain_name or 
                    domain_name.split('ï¼ˆ')[0] in stats_domain_name or
                    stats_domain_name in domain_name.split('ï¼ˆ')[0]):
                    matched_stats = stats
                    break
            
            # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ï¼Œä½¿ç”¨é»˜èªå€¼
            if matched_stats is None:
                matched_stats = {'total': 0, 'correct': 0, 'wrong': 0}
            
            stats = matched_stats.copy()  # å‰µå»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
            # ç¢ºä¿statsåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
            if 'wrong' not in stats:
                stats['wrong'] = stats['total'] - stats['correct']
            
            if stats['total'] > 0:
                domain_mastery = stats['correct'] / stats['total']
            else:
                domain_mastery = 0.0  # æ²’æœ‰ç­”é¡Œè¨˜éŒ„æ™‚è¨­ç‚º0
            
            # è¨ˆç®—è©²é ˜åŸŸçš„é›£åº¦æ„ŸçŸ¥æŒæ¡åº¦
            domain_records = [r for r in quiz_records if r.get('domain_name') == domain_name.split('ï¼ˆ')[0]]
            difficulty_aware_data = calculate_difficulty_aware_mastery(domain_records, domain_id)
            
            
            # å¾MongoDBç²å–è©²é ˜åŸŸä¸‹çš„å°çŸ¥è­˜é»ï¼ˆå¾®æ¦‚å¿µï¼‰
            # éœ€è¦å…ˆé€šéblockæ‰¾åˆ°è©²é ˜åŸŸä¸‹çš„å¾®æ¦‚å¿µ
            domain_id_obj = domain_doc.get('_id')
            
            # å…ˆæ‰¾åˆ°è©²é ˜åŸŸä¸‹çš„æ‰€æœ‰block
            blocks = list(mongo.db.block.find({'domain_id': domain_id_obj}, {'_id': 1}))
            block_ids = [block['_id'] for block in blocks]
            
            # å†æ‰¾åˆ°é€™äº›blockä¸‹çš„å¾®æ¦‚å¿µ
            micro_concepts_query = {'block_id': {'$in': block_ids}} if block_ids else {}
            micro_concept_docs = list(mongo.db.micro_concept.find(micro_concepts_query, {'name': 1, '_id': 1, 'block_id': 1}))
            
            
            # çµ±è¨ˆæ¯å€‹å¾®æ¦‚å¿µçš„ç­”é¡Œæƒ…æ³
            # éœ€è¦åŒ¹é…ç°¡åŒ–çš„é ˜åŸŸåç¨±
            simplified_domain_name = domain_name.split('ï¼ˆ')[0]  # å–æ‹¬è™Ÿå‰çš„éƒ¨åˆ†
            domain_records = [r for r in quiz_records if r.get('domain_name') == simplified_domain_name]
            micro_concept_stats = {}
            for record in domain_records:
                concept_id = record.get('micro_concept_id', '')
                concept_name = record.get('micro_concept_name', '')
                # ä½¿ç”¨æ¦‚å¿µIDä½œç‚ºä¸»è¦åŒ¹é…æ–¹å¼
                if concept_id and concept_id != 'None' and concept_id != '':
                    if concept_id not in micro_concept_stats:
                        micro_concept_stats[concept_id] = {'total': 0, 'correct': 0, 'wrong': 0}
                    micro_concept_stats[concept_id]['total'] += 1
                    if record['is_correct']:
                        micro_concept_stats[concept_id]['correct'] += 1
                    else:
                        micro_concept_stats[concept_id]['wrong'] += 1
                
                # ä¹Ÿå˜—è©¦ç”¨æ¦‚å¿µåç¨±åŒ¹é…ï¼ˆä½œç‚ºå‚™é¸ï¼‰
                elif concept_name and concept_name != 'None' and concept_name != '':
                    if concept_name not in micro_concept_stats:
                        micro_concept_stats[concept_name] = {'total': 0, 'correct': 0, 'wrong': 0}
                    micro_concept_stats[concept_name]['total'] += 1
                    if record['is_correct']:
                        micro_concept_stats[concept_name]['correct'] += 1
                    else:
                        micro_concept_stats[concept_name]['wrong'] += 1
            
            # æ§‹å»ºå°çŸ¥è­˜é»æ•¸æ“š
            concepts = []
            for concept_doc in micro_concept_docs:
                concept_id = str(concept_doc.get('_id', ''))
                concept_name = concept_doc.get('name', f'æ¦‚å¿µ {concept_id[:8]}')
                
                # è·³éæ²’æœ‰IDçš„æ¦‚å¿µ
                if not concept_id or concept_id == 'None' or concept_id == '':
                    continue
                
                # ç²å–è©²å¾®æ¦‚å¿µçš„ç­”é¡Œçµ±è¨ˆ
                # å„ªå…ˆä½¿ç”¨æ¦‚å¿µåç¨±åŒ¹é…ï¼ˆå› ç‚ºç­”é¡Œè¨˜éŒ„ä¸­çš„concept_idå¯¦éš›ä¸Šæ˜¯æ¦‚å¿µåç¨±ï¼‰
                concept_stats = micro_concept_stats.get(concept_name, micro_concept_stats.get(concept_id, {'total': 0, 'correct': 0, 'wrong': 0}))
                
                
                if concept_stats['total'] > 0:
                    concept_mastery = concept_stats['correct'] / concept_stats['total']
                else:
                    concept_mastery = 0.0  # æ²’æœ‰ç­”é¡Œè¨˜éŒ„æ™‚è¨­ç‚º0
                
                concepts.append({
                    'id': concept_id,
                    'name': concept_name,
                    'mastery': round(concept_mastery, 2),
                    'questionCount': concept_stats['total'],
                    'wrongCount': concept_stats['total'] - concept_stats['correct']
                })
            
            domains.append({
                'id': domain_id,
                'name': domain_name,
                'mastery': round(domain_mastery, 2),  # ä½¿ç”¨domain_masteryè®Šé‡
                'questionCount': stats['total'],
                'wrongCount': stats['wrong'],
                'concepts': concepts,  # åŒ…å«å°çŸ¥è­˜é»
                'expanded': False,  # ç”¨æ–¼å‰ç«¯å±•é–‹ç‹€æ…‹
                # æ–°å¢é›£åº¦æ„ŸçŸ¥æ•¸æ“š
                'difficulty_aware_mastery': difficulty_aware_data['overall_mastery'],
                'difficulty_breakdown': difficulty_aware_data['difficulty_breakdown'],
                'difficulty_analysis': difficulty_aware_data['difficulty_analysis'],
            })
        
        # æŒ‰æŒæ¡åº¦æ’åº
        domains.sort(key=lambda x: x['mastery'], reverse=True)
        
        # é¡¯ç¤ºæ‰€æœ‰çŸ¥è­˜é»ï¼ˆåŒ…å«å°çŸ¥è­˜é»ï¼‰
        all_knowledge_points = []
        for domain in domains:
            # åˆ¤æ–·ç‹€æ…‹ï¼šæ•¸æ“šä¸è¶³ã€éœ€è¦åŠ å¼·ã€æŒæ¡è‰¯å¥½
            
            if domain['questionCount'] == 0:
                status = 'no_data'
                status_text = 'æ•¸æ“šä¸è¶³'
            elif domain['mastery'] < 0.6:
                status = 'weak'
                status_text = 'éœ€è¦åŠ å¼·'
            else:
                status = 'good'
                status_text = 'æŒæ¡è‰¯å¥½'
            
            all_knowledge_points.append({
                    'id': domain['id'],
                    'name': domain['name'],
                    'mastery': domain['mastery'],
                'questionCount': domain['questionCount'],
                'wrongCount': domain['wrongCount'],
                'status': status,
                'status_text': status_text,
                'concepts': domain['concepts'],  # åŒ…å«å°çŸ¥è­˜é»
                'expanded': False  # ç”¨æ–¼å‰ç«¯å±•é–‹ç‹€æ…‹
            })
        
        # æŒ‰æŒæ¡åº¦æ’åºï¼Œé¡¯ç¤ºæ‰€æœ‰çŸ¥è­˜é»
        all_knowledge_points.sort(key=lambda x: x['mastery'])
        top_weak_points = all_knowledge_points  # é¡¯ç¤ºæ‰€æœ‰çŸ¥è­˜é»
        
        # æ§‹å»ºç¸½è¦½æ•¸æ“š
        # è¨ˆç®—é¡å¤–çš„çµ±è¨ˆæ•¸æ“š
        total_attempts = len(quiz_records)
        correct_attempts = sum(1 for r in quiz_records if r['is_correct'])
        accuracy = correct_attempts / total_attempts if total_attempts > 0 else 0
        
        # è¨ˆç®—é€£çºŒå­¸ç¿’å¤©æ•¸
        consecutive_days = calculate_consecutive_days(quiz_records)
        
        # è¨ˆç®—æœ¬é€±å·²ä½œç­”é¡Œæ•¸
        from datetime import timezone
        week_ago = datetime.now(timezone.utc) - timedelta(days=7)
        recent_activity = len([r for r in quiz_records if datetime.fromisoformat(r['attempt_time'].replace('Z', '+00:00')) >= week_ago])
        
        # è¨ˆç®—å·²æŒæ¡å’Œå­¸ç¿’ä¸­çš„æ¦‚å¿µ
        mastered_concepts = len([d for d in domains if d['mastery'] >= 0.8])
        learning_concepts = len([d for d in domains if 0.3 <= d['mastery'] < 0.8])
        
        # è¨ˆç®—å­¸ç¿’æ™‚é–“çµ±è¨ˆ
        total_study_time = calculate_total_study_time(quiz_records)
        avg_daily_time = calculate_avg_daily_time(quiz_records)
        longest_session = calculate_longest_session(quiz_records)
        study_intensity = calculate_study_intensity(quiz_records)
        
        # è¨ˆç®—æ­·å²æ•¸æ“šç”¨æ–¼è¶¨å‹¢åˆ†æ
        historical_metrics = calculate_historical_metrics(quiz_records, trend_days)
        
        overview_data = {
            'total_mastery': learning_metrics['overall_mastery'],
            'learning_velocity': learning_metrics['learning_velocity'],
            'retention_rate': learning_metrics['retention_rate'],
            'avg_time_per_concept': learning_metrics['avg_time_per_concept'],
            'focus_score': learning_metrics['focus_score'],
            'domains': domains,
            'top_weak_points': top_weak_points,
            'recent_activity': recent_activity,
            # æ–°å¢çš„çµ±è¨ˆæ•¸æ“š
            'total_attempts': total_attempts,
            'accuracy': accuracy,
            'consecutive_days': consecutive_days,
            'mastered_concepts': mastered_concepts,
            'learning_concepts': learning_concepts,
            'total_study_time': total_study_time,
            'avg_daily_time': avg_daily_time,
            'longest_session': longest_session,
            'study_intensity': study_intensity,
            # æ­·å²æ•¸æ“šç”¨æ–¼è¶¨å‹¢è¨ˆç®—
            'previous_learning_velocity': historical_metrics['learning_velocity'],
            'previous_retention_rate': historical_metrics['retention_rate'],
            'previous_avg_time_per_concept': historical_metrics['avg_time_per_concept'],
            'previous_focus_score': historical_metrics['focus_score']
        }
        
        # ç”Ÿæˆè¶¨å‹¢æ•¸æ“šï¼ˆä½¿ç”¨å‚³å…¥çš„å¤©æ•¸ï¼‰
        trends = generate_trend_data(quiz_records, trend_days)
        
        # ç”ŸæˆæŒ‰é ˜åŸŸç¯©é¸çš„è¶¨å‹¢æ•¸æ“š
        domain_trends = {}
        
        for domain in domains:
            domain_name = domain['name']
            simplified_name = domain_name.split('ï¼ˆ')[0]  # å–æ‹¬è™Ÿå‰çš„éƒ¨åˆ†
            # ç¯©é¸è©²é ˜åŸŸçš„ç­”é¡Œè¨˜éŒ„
            domain_records = [r for r in quiz_records if r.get('domain_name') == simplified_name]
            
            if domain_records:
                domain_trends[domain_name] = generate_trend_data(domain_records, trend_days)
            else:
                pass
        
        for name, trends in domain_trends.items():
            total_questions = sum(day['questions'] for day in trends)
            pass
        
        # ç”Ÿæˆé€²æ­¥çŸ¥è­˜é»æ•¸æ“š
        improvement_items = generate_improvement_items(domains, quiz_records)
        # ç”Ÿæˆéœ€è¦é—œæ³¨çš„çŸ¥è­˜é»æ•¸æ“š
        attention_items = generate_attention_items(domains, quiz_records)
        
        
        # ç”Ÿæˆé€²åº¦è¿½è¹¤æ•¸æ“š
        progress_tracking = generate_progress_tracking(quiz_records)
        
        # ç”Ÿæˆé›·é”åœ–æ•¸æ“š
        radar_data = generate_radar_data(domains, quiz_records)
        
        # ç”ŸæˆAIæ•™ç·´åˆ†æ
        ai_coach_analysis = generate_ai_coach_analysis(overview_data, domains, quiz_records, user_email)
        
        # ç”Ÿæˆå­¸ç¿’è¶¨å‹¢æ•¸æ“šï¼ˆçµåˆéºå¿˜æ›²ç·šï¼‰
        learning_trends = generate_learning_trends_with_forgetting(domains, quiz_records, trend_days)
        
        # æ§‹å»ºå®Œæ•´æ•¸æ“š
        complete_data = {
            'overview': overview_data,
            'trends': learning_trends,  # ä½¿ç”¨æ–°çš„å­¸ç¿’è¶¨å‹¢
            'domain_trends': domain_trends,  # æ–°å¢ï¼šæŒ‰é ˜åŸŸç¯©é¸çš„è¶¨å‹¢æ•¸æ“š
            'improvement_items': improvement_items,
            'attention_items': attention_items,
            'progress_tracking': progress_tracking,
            'radar_data': radar_data,
            'ai_coach_analysis': ai_coach_analysis  # æ–°å¢AIæ•™ç·´åˆ†æ
        }

        return jsonify({
            'success': True,
            'data': complete_data
        })
        
    except Exception as e:
        logger.error(f'åˆå§‹åŒ–å­¸ç¿’åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}')
        return jsonify({
            'success': False,
            'error': 'åˆå§‹åŒ–å­¸ç¿’åˆ†ææ•¸æ“šå¤±æ•—'
        }), 500


@analytics_bp.route('/ai-practice-parallel', methods=['POST', 'OPTIONS'])
def ai_practice_parallel():
    """AIä¸¦è¡Œå‡ºé¡Œç·´ç¿’ - ä½¿ç”¨å¤šå€‹API keyä¸¦è¡Œç”Ÿæˆé¡Œç›®"""
    if request.method == 'OPTIONS':
        return jsonify({'success': True})
    
    try:
        data = request.get_json()
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘èªè­‰ä¿¡æ¯'
            }), 401
        token = auth_header.split(' ')[1]
        user_email = get_user_info(token, 'email')
        if not user_email:
            return jsonify({
                'success': False,
                'error': 'ç„¡æ³•ç²å–ç”¨æˆ¶ä¿¡æ¯ï¼Œè«‹é‡æ–°ç™»å…¥'
            }), 401
        
        concept_name = data.get('concept_name', 'æœªçŸ¥æ¦‚å¿µ')
        domain_name = data.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
        difficulty = data.get('difficulty', 'medium')
        question_count = data.get('question_count', 20)
        
        
        # ä½¿ç”¨ä¸¦è¡Œç”Ÿæˆ
        quiz_result = generate_quiz_parallel(concept_name, domain_name, difficulty, question_count, user_email)
        
        if quiz_result.get('success'):
            return jsonify({
                'success': True,
                'quiz_id': quiz_result.get('quiz_id'),
                'template_id': quiz_result.get('template_id', quiz_result.get('quiz_id')),  # æ·»åŠ template_id
                'quiz_info': quiz_result.get('quiz_info', {}),
                'questions': quiz_result.get('questions', []),
                'concept_name': concept_name,
                'domain_name': domain_name,
                'difficulty': difficulty,
                'question_count': len(quiz_result.get('questions', [])),
                'generation_time': quiz_result.get('generation_time', 0),
                'api_keys_used': quiz_result.get('api_keys_used', 0)
            })
        else:
            return jsonify({
                'success': False,
                'error': quiz_result.get('error', 'ç”Ÿæˆé¡Œç›®å¤±æ•—')
            }), 500
        
    except Exception as e:
        logger.error(f"AIä¸¦è¡Œå‡ºé¡Œç·´ç¿’å¤±æ•—: {e}")
        return jsonify({
            'success': False,
            'error': f'AIä¸¦è¡Œå‡ºé¡Œç·´ç¿’å¤±æ•—: {str(e)}'
        }), 500

def generate_quiz_parallel(concept_name: str, domain_name: str, difficulty: str, question_count: int, user_email: str = 'ai_system@mis_teach.com') -> Dict[str, Any]:
    """ä½¿ç”¨å¤šå€‹API keyä¸¦è¡Œç”Ÿæˆé¡Œç›®"""
    start_time = time.time()
    
    try:
        # è®€å–API keys - éœ€è¦å…ˆè¼‰å…¥ç’°å¢ƒè®Šæ•¸
        from dotenv import load_dotenv
        load_dotenv('api.env')
        
        wu_keys = os.getenv('WU_API_KEYS', '').split(',')
        pan_keys = os.getenv('PAN_API_KEYS', '').split(',')
        
        # éæ¿¾ç©ºå­—ç¬¦ä¸²
        wu_keys = [key.strip() for key in wu_keys if key.strip()]
        pan_keys = [key.strip() for key in pan_keys if key.strip()]
        
        all_keys = wu_keys + pan_keys
        # å»é‡è¤‡ï¼Œç¢ºä¿æ¯å€‹API keyåªä½¿ç”¨ä¸€æ¬¡
        available_keys = list(dict.fromkeys([key for key in all_keys if key]))
        
        if not available_keys:
            return {
                'success': False,
                'error': 'æ²’æœ‰å¯ç”¨çš„APIå¯†é‘°'
            }
        
        
        # æ ¹æ“šå‚³å…¥çš„question_countåƒæ•¸åˆ†é…ä»»å‹™
        # å„ªå…ˆä½¿ç”¨1é¡Œ1keyæ¨¡å¼ï¼Œå¦‚æœAPI keyä¸è¶³å‰‡å¹³å‡åˆ†é…
        if len(available_keys) >= question_count:
            # API keyè¶³å¤ ï¼šæ¯å€‹keyç”Ÿæˆ1é¡Œï¼Œåªä½¿ç”¨éœ€è¦çš„API keyæ•¸é‡
            questions_per_key = 1
            remaining_questions = 0
            used_keys = available_keys[:question_count]
        else:
            # API keyä¸è¶³ï¼šå¹³å‡åˆ†é…é¡Œç›®
            questions_per_key = question_count // len(available_keys)
            remaining_questions = question_count % len(available_keys)
            used_keys = available_keys
        
        # æº–å‚™ä¸¦è¡Œä»»å‹™
        tasks = []
        for i, api_key in enumerate(used_keys):
            # åˆ†é…é¡Œç›®æ•¸é‡
            if len(available_keys) >= question_count:
                # API keyè¶³å¤ ï¼šæ¯å€‹keyç”Ÿæˆ1é¡Œ
                key_question_count = 1
            else:
                # API keyä¸è¶³ï¼šå¹³å‡åˆ†é…
                key_question_count = questions_per_key
                if i < remaining_questions:
                    key_question_count += 1
            
            if key_question_count <= 0:
                continue
                
            # æ±ºå®šä½¿ç”¨å“ªå€‹APIçµ„
            api_group = 'wu_api' if api_key in wu_keys else 'pan_api'
            
            task = {
                'api_key': api_key,
                'api_group': api_group,
                'question_count': key_question_count,
                'concept_name': concept_name,
                'domain_name': domain_name,
                'difficulty': difficulty
            }
            tasks.append(task)
        
        # æœ€å¤§åŒ–ä¸¦è¡Œåº¦ï¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„API key
        max_workers = min(len(tasks), 20)  # æœ€å¤š20å€‹ä¸¦è¡Œä»»å‹™
        
        
        # ä¸¦è¡ŒåŸ·è¡Œä»»å‹™
        all_questions = []
        successful_keys = 0
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_task = {
                executor.submit(generate_questions_with_key, task): task 
                for task in tasks
            }
            
            # æ”¶é›†çµæœ
            for future in concurrent.futures.as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    result = future.result()
                    if result.get('success'):
                        questions = result.get('questions', [])
                        all_questions.extend(questions)
                        successful_keys += 1
                    else:
                        logger.error(f"{task['api_group']} ç”Ÿæˆå¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                except Exception as e:
                    logger.error(f"{task['api_group']} åŸ·è¡Œç•°å¸¸: {str(e)}")
        
        if not all_questions:
            return {
                'success': False,
                'error': 'æ‰€æœ‰APIå¯†é‘°éƒ½ç”Ÿæˆå¤±æ•—'
            }
        
        # å¦‚æœé¡Œç›®æ•¸é‡ä¸è¶³ï¼Œå˜—è©¦ç”¨å‰©é¤˜çš„API keyè£œå……
        if len(all_questions) < question_count:
            logger.warning(f"é¡Œç›®æ•¸é‡ä¸è¶³ï¼Œç•¶å‰: {len(all_questions)}, éœ€è¦: {question_count}")
            # é€™è£¡å¯ä»¥æ·»åŠ è£œå……é‚è¼¯
        
        # é™åˆ¶é¡Œç›®æ•¸é‡
        all_questions = all_questions[:question_count]
        
        generation_time = time.time() - start_time
        
        # ç”Ÿæˆæ¸¬é©—ä¿¡æ¯
        quiz_info = {
            'title': f'{concept_name} - {difficulty}é›£åº¦ç·´ç¿’',
            'description': f'AIç”Ÿæˆçš„{concept_name}ç·´ç¿’é¡Œï¼Œå…±{len(all_questions)}é¡Œ',
            'total_questions': len(all_questions),
            'difficulty': difficulty,
            'concept': concept_name,
            'domain': domain_name,
            'generation_time': round(generation_time, 2),
            'api_keys_used': successful_keys
        }
        
        # ä¿å­˜åˆ°MongoDBä¸¦å‰µå»ºSQL template
        quiz_id, template_id = save_quiz_to_database(quiz_info, all_questions, concept_name, domain_name, user_email)
        
        return {
            'success': True,
            'quiz_id': quiz_id,
            'template_id': template_id,
            'quiz_info': quiz_info,
            'questions': all_questions,
            'generation_time': round(generation_time, 2),
            'api_keys_used': successful_keys
        }
        
    except Exception as e:
        logger.error(f"ä¸¦è¡Œç”Ÿæˆé¡Œç›®å¤±æ•—: {e}")
        return {
            'success': False,
            'error': f'ä¸¦è¡Œç”Ÿæˆå¤±æ•—: {str(e)}'
        }

def generate_questions_with_key(task: Dict[str, Any]) -> Dict[str, Any]:
    """ä½¿ç”¨å–®å€‹API keyç”Ÿæˆé¡Œç›®"""
    try:
        api_key = task['api_key']
        api_group = task['api_group']
        question_count = task['question_count']
        concept_name = task['concept_name']
        domain_name = task['domain_name']
        difficulty = task['difficulty']
        
        # æ§‹å»ºéœ€æ±‚åƒæ•¸ï¼Œçµåˆæ¦‚å¿µåç¨±å’Œé ˜åŸŸ
        full_topic = f"{domain_name} - {concept_name}" if domain_name and domain_name != concept_name else concept_name
        requirements = {
            'topic': full_topic,
            'concept_name': concept_name,
            'domain_name': domain_name,
            'question_types': ['single-choice', 'multiple-choice', 'fill-in-the-blank', 'true-false'],
            'difficulty': difficulty,
            'question_count': question_count,
            'exam_type': 'knowledge'
        }
        
        # èª¿ç”¨quiz_generator
        result = generate_quiz_by_ai(requirements)
        
        if result.get('success'):
            return {
                'success': True,
                'questions': result.get('questions', []),
                'api_group': api_group
            }
        else:
            return {
                'success': False,
                'error': result.get('error', 'ç”Ÿæˆå¤±æ•—'),
                'api_group': api_group
            }
            
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'api_group': task.get('api_group', 'unknown')
        }

def save_quiz_to_database(quiz_info: Dict[str, Any], questions: List[Dict], concept_name: str, domain_name: str, user_email: str = 'ai_system@mis_teach.com') -> tuple[str, str]:
    """ä¿å­˜æ¸¬é©—åˆ°MongoDBè³‡æ–™åº«çš„examé›†åˆ"""
    try:
        # ç”Ÿæˆå”¯ä¸€çš„exam_idï¼Œä½¿ç”¨ObjectIdæ ¼å¼
        from bson import ObjectId
        exam_id = str(ObjectId())
        
        # è½‰æ›é¡Œç›®æ ¼å¼ä»¥ç¬¦åˆexamé›†åˆçš„çµæ§‹
        exam_questions = []
        for i, question in enumerate(questions):
            # æ ¹æ“šé¡Œå‹ç¢ºå®šanswer_typeï¼ŒAIç”Ÿæˆçš„é¡Œç›®éƒ½è¨­ç‚ºsingleé¡å‹
            question_type = question.get('question_type', 'single-choice')
            if question_type == 'single-choice':
                answer_type = 'single-choice'
            elif question_type == 'multiple-choice':
                answer_type = 'multiple-choice'  # æ”¹ç‚ºsingleé¡å‹
            elif question_type == 'fill-in-the-blank':
                answer_type = 'fill-in-the-blank'
            elif question_type == 'true-false':
                answer_type = 'true-false'
            else:
                answer_type = 'single-choice'
            
            # è™•ç†é¸é …æ ¼å¼
            options = question.get('options', [])
            if options and isinstance(options, list):
                # å¦‚æœé¸é …åŒ…å«æ¨™ç±¤ï¼ˆå¦‚"é¸é …A: å…§å®¹"ï¼‰ï¼Œæå–å…§å®¹
                processed_options = []
                for option in options:
                    if ': ' in option:
                        processed_options.append(option.split(': ', 1)[1])
                    else:
                        processed_options.append(option)
            else:
                processed_options = []
            
            exam_question = {
                # è®“MongoDBè‡ªå‹•ç”Ÿæˆ_idï¼Œé¿å…é‡è¤‡IDå•é¡Œ
                '_id': ObjectId(),
                'type': answer_type,
                'school': '',
                'department': '',
                'year': '',
                'question_number': str(i + 1),
                'question_text': question.get('question_text', ''),
                'options': processed_options,
                'answer': question.get('correct_answer', ''),
                'answer_type': answer_type,
                'image_file': [],
                'detail-answer': question.get('explanation', ''),
                'key-points': concept_name,  # ä½¿ç”¨å–®ä¸€å­—ç¬¦ä¸²è€Œä¸æ˜¯æ•¸çµ„
                'micro_concepts': [concept_name, f"{concept_name}åŸºç¤", f"{concept_name}æ‡‰ç”¨"],
                'difficulty_level': 'ä¸­ç­‰' if quiz_info['difficulty'] == 'medium' else ('ç°¡å–®' if quiz_info['difficulty'] == 'easy' else 'å›°é›£'),
                'error_reason': '',
                'created_at': datetime.now()
            }
            exam_questions.append(exam_question)
        
        # ç›´æ¥ä¿å­˜é¡Œç›®ä½œç‚ºç¨ç«‹æ–‡æª”ï¼Œä¸éœ€è¦æ¸¬é©—æ–‡æª”
        if exam_questions:
            try:
                question_results = mongo.db.exam.insert_many(exam_questions)
                
                # å‰µå»ºSQL templateï¼ˆä½¿ç”¨æ‰€æœ‰é¡Œç›®çš„IDï¼‰
                question_ids = [str(q_id) for q_id in question_results.inserted_ids]
                
                template_id = create_sql_template(question_ids, {
                    'title': quiz_info['title'],
                    'total_questions': len(exam_questions),
                    'difficulty': quiz_info['difficulty'],
                    'concept': concept_name,
                    'domain': domain_name
                }, user_email)
                
                return str(question_results.inserted_ids[0]), template_id  # è¿”å›ç¬¬ä¸€å€‹é¡Œç›®çš„IDå’Œtemplate_id
                
            except Exception as e:
                successful_ids = []
                for i, question in enumerate(exam_questions):
                    try:
                        result = mongo.db.exam.insert_one(question)
                        successful_ids.append(str(result.inserted_id))
                    except Exception as single_error:
                        continue
                
                if successful_ids:
                    template_id = create_sql_template(successful_ids, {
                        'title': quiz_info['title'],
                        'total_questions': len(successful_ids),
                        'difficulty': quiz_info['difficulty'],
                        'concept': concept_name,
                        'domain': domain_name
                    }, user_email)
                    return exam_id, template_id
                else:
                    raise e
        else:
            return f"temp_{int(time.time())}", f"temp_template_{int(time.time())}"
            
    except Exception as e:
        return f"temp_{int(time.time())}", f"temp_template_{int(time.time())}"

def create_sql_template(question_ids: List[str], quiz_info: Dict[str, Any], user_email: str = '') -> str:
    """ç‚ºAIç”Ÿæˆçš„æ¸¬é©—å‰µå»ºSQL templateï¼Œåƒè€ƒå­¸æ ¡è€ƒå¤é¡Œçš„å‰µå»ºæ–¹å¼"""
    try:
        from accessories import sqldb
        from sqlalchemy import text
        import json
        
        # å‰µå»ºSQL templateè¨˜éŒ„
        template_query = text("""
            INSERT INTO quiz_templates (
                user_email,
                template_type,
                question_ids,
                school,
                department,
                year
            ) VALUES (
                :user_email,
                :template_type,
                :question_ids,
                :school,
                :department,
                :year
            )
        """)
        
        # æº–å‚™æ•¸æ“š
        template_data = {
            'user_email': user_email,
            'template_type': 'knowledge',
            'question_ids': json.dumps(question_ids),  # ä½¿ç”¨æ‰€æœ‰é¡Œç›®çš„ID
            'school': '',
            'department': '',
            'year': ''
        }
        
        # åŸ·è¡ŒSQLä¸¦ç²å–lastrowidä½œç‚ºtemplate_id
        with sqldb.engine.connect() as conn:
            result = conn.execute(template_query, template_data)
            conn.commit()
            template_id = result.lastrowid
            
        logger.info(f"SQL templateå·²å‰µå»º: {template_id}")
        return str(template_id)
        
    except Exception as e:
        logger.error(f"å‰µå»ºSQL templateå¤±æ•—: {e}")
        return f"ai_template_{int(time.time())}"

def generate_trend_data(quiz_records: List[Dict], days: int = 7) -> List[Dict]:
    """ç”Ÿæˆè¶¨å‹¢æ•¸æ“šï¼ŒåŒ…å«éºå¿˜æ›²ç·šåˆ†æ"""
    trends = []
    for i in range(days):
        from datetime import timezone
        date = (datetime.now(timezone.utc) - timedelta(days=days-1-i)).strftime('%Y-%m-%d')
        # è¨ˆç®—è©²å¤©çš„æŒæ¡åº¦
        day_records = [r for r in quiz_records if r['attempt_time'].startswith(date)]
        if day_records:
            correct_count = sum(1 for r in day_records if r['is_correct'])
            total_count = len(day_records)
            mastery = correct_count / total_count
        else:
            mastery = 0
        
        # è¨ˆç®—è©²å¤©çš„éºå¿˜æ›²ç·šæ•¸æ“š
        forgetting_data = []
        if day_records:
            # æŒ‰æ¦‚å¿µåˆ†çµ„è¨ˆç®—éºå¿˜ç‡
            concept_groups = {}
            for record in day_records:
                concept_id = record.get('micro_concept_id')
                if concept_id:
                    if concept_id not in concept_groups:
                        concept_groups[concept_id] = []
                    concept_groups[concept_id].append(record)
            
            # è¨ˆç®—æ¯å€‹æ¦‚å¿µçš„éºå¿˜ç‡
            for concept_id, concept_records in concept_groups.items():
                forgetting_info = calculate_forgetting_aware_mastery(concept_records, concept_id)
                # ç¢ºä¿éºå¿˜ç‡æ˜¯åˆç†çš„æ•¸å€¼
                forgetting_rate = max(0, 1 - forgetting_info['current_mastery'])
                forgetting_data.append({
                    'concept_id': concept_id,
                    'base_mastery': forgetting_info['base_mastery'],
                    'current_mastery': forgetting_info['current_mastery'],
                    'forgetting_rate': forgetting_rate,
                    'days_since_practice': forgetting_info['days_since_practice']
                })
            if forgetting_data:
                avg_forgetting = sum(item['forgetting_rate'] for item in forgetting_data) / len(forgetting_data)
        
        trends.append({
            'date': date,
            'mastery': mastery,
            'questions': len(day_records),
            'accuracy': mastery,
            'forgetting_data': forgetting_data
        })
    
    return trends

# å·²ç§»é™¤ /trends API - åŠŸèƒ½å·²æ•´åˆåˆ° /init-data

# å·²ç§»é™¤ /peer-comparison API - å‰ç«¯æœªä½¿ç”¨

@analytics_bp.route('/difficulty-analysis', methods=['POST', 'OPTIONS'])
def get_difficulty_analysis():
    if request.method == 'OPTIONS':
        return jsonify({'success': True})
    """ç²å–é›£åº¦åˆ†ææ•¸æ“š - Difficulty-aware KT"""
    try:
        # ç²å–JWT token
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'success': False, 'error': 'ç¼ºå°‘èªè­‰ä¿¡æ¯'}), 401
        
        token = auth_header.split(' ')[1]
        user_email = get_user_info(token, 'email')
        
        if not user_email:
            return jsonify({'success': False, 'error': 'ç„¡æ³•ç²å–ç”¨æˆ¶ä¿¡æ¯'}), 401
        
        # ç²å–å­¸ç”Ÿç­”é¡Œè¨˜éŒ„
        quiz_records = get_student_quiz_records(user_email)
        
        # è¨ˆç®—æ•´é«”é›£åº¦åˆ†æ
        overall_difficulty_stats = {}
        for record in quiz_records:
            difficulty = record.get('difficulty', 'ä¸­ç­‰')
            if difficulty not in overall_difficulty_stats:
                overall_difficulty_stats[difficulty] = {'total': 0, 'correct': 0}
            overall_difficulty_stats[difficulty]['total'] += 1
            if record['is_correct']:
                overall_difficulty_stats[difficulty]['correct'] += 1
        
        # è¨ˆç®—æ•´é«”é›£åº¦åˆ†ä½ˆ
        overall_difficulty_breakdown = {}
        for difficulty in ['ç°¡å–®', 'ä¸­ç­‰', 'å›°é›£']:
            if difficulty in overall_difficulty_stats:
                stats = overall_difficulty_stats[difficulty]
                mastery = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
                overall_difficulty_breakdown[difficulty] = {
                    'mastery': round(mastery, 2),
                    'total_questions': stats['total'],
                    'correct_questions': stats['correct']
                }
            else:
                overall_difficulty_breakdown[difficulty] = {
                    'mastery': 0,
                    'total_questions': 0,
                    'correct_questions': 0
                }
        
        # è¨ˆç®—å„é ˜åŸŸçš„é›£åº¦åˆ†æ
        domain_difficulty_analysis = []
        domains = list(mongo.db.domain.find({}, {'name': 1, '_id': 1}))
        
        for domain_doc in domains:
            domain_name = domain_doc.get('name', 'æœªçŸ¥é ˜åŸŸ')
            domain_id = str(domain_doc.get('_id', ''))
            
            # ç²å–è©²é ˜åŸŸçš„ç­”é¡Œè¨˜éŒ„
            domain_records = [r for r in quiz_records if r.get('domain_name') == domain_name.split('ï¼ˆ')[0]]
            
            if domain_records:
                difficulty_data = calculate_difficulty_aware_mastery(domain_records, domain_id)
            else:
                # æ²’æœ‰ç­”é¡Œè¨˜éŒ„æ™‚ï¼Œè¿”å›é»˜èªæ•¸æ“š
                difficulty_data = {
                    'overall_mastery': 0,
                    'difficulty_breakdown': {'ç°¡å–®': 0, 'ä¸­ç­‰': 0, 'å›°é›£': 0},
                    'difficulty_analysis': {
                        'easy_mastery': 0,
                        'medium_mastery': 0,
                        'hard_mastery': 0,
                        'bottleneck_level': 'none',
                        'recommended_difficulty': 'ç°¡å–®'
                    }
                }
            
            domain_difficulty_analysis.append({
                'domain_id': domain_id,
                'domain_name': domain_name,
                'overall_mastery': difficulty_data['overall_mastery'],
                'difficulty_breakdown': difficulty_data['difficulty_breakdown'],
                'difficulty_analysis': difficulty_data['difficulty_analysis']
            })
        
        # ç”Ÿæˆå€‹äººåŒ–é›£åº¦æ¨è–¦
        personalized_recommendations = []
        for domain_data in domain_difficulty_analysis:
            analysis = domain_data['difficulty_analysis']
            if analysis['bottleneck_level'] != 'none':
                personalized_recommendations.append({
                    'domain': domain_data['domain_name'],
                    'bottleneck_level': analysis['bottleneck_level'],
                    'recommended_difficulty': analysis['recommended_difficulty'],
                    'reason': f"åœ¨{analysis['bottleneck_level']}é›£åº¦é¡Œç›®ä¸Šè¡¨ç¾ä¸ä½³ï¼Œå»ºè­°å…ˆç·´ç¿’{analysis['recommended_difficulty']}é›£åº¦"
                })
        
        return jsonify({
            'success': True,
            'data': {
                'overall_difficulty_breakdown': overall_difficulty_breakdown,
                'domain_difficulty_analysis': domain_difficulty_analysis,
                'personalized_recommendations': personalized_recommendations
            }
        })
        
    except Exception as e:
        logger.error(f'ç²å–é›£åº¦åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}')
        return jsonify({
            'success': False,
            'error': f'ç²å–é›£åº¦åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}'
        }), 500

@analytics_bp.route('/forgetting-analysis', methods=['POST', 'OPTIONS'])
def get_forgetting_analysis():
    if request.method == 'OPTIONS':
        return jsonify({'success': True})
    """ç²å–éºå¿˜åˆ†ææ•¸æ“š - Forgetting-aware KT"""
    try:
        # ç²å–JWT token
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'success': False, 'error': 'ç¼ºå°‘èªè­‰ä¿¡æ¯'}), 401
        
        token = auth_header.split(' ')[1]
        user_email = get_user_info(token, 'email')
        
        if not user_email:
            return jsonify({'success': False, 'error': 'ç„¡æ³•ç²å–ç”¨æˆ¶ä¿¡æ¯'}), 401
        
        # ç²å–å­¸ç”Ÿç­”é¡Œè¨˜éŒ„
        quiz_records = get_student_quiz_records(user_email)
        
        # æŒ‰æ¦‚å¿µåˆ†çµ„è¨ˆç®—éºå¿˜åˆ†æ
        concept_forgetting_analysis = {}
        for record in quiz_records:
            concept_id = record['micro_concept_id']
            if concept_id not in concept_forgetting_analysis:
                concept_forgetting_analysis[concept_id] = []
            concept_forgetting_analysis[concept_id].append(record)
        
        # è¨ˆç®—æ¯å€‹æ¦‚å¿µçš„éºå¿˜åˆ†æ
        forgetting_results = []
        review_recommendations = []
        
        for concept_id, concept_records in concept_forgetting_analysis.items():
            forgetting_data = calculate_forgetting_aware_mastery(concept_records, concept_id)
            
            # ç²å–æ¦‚å¿µåç¨±
            concept_name = "æœªçŸ¥æ¦‚å¿µ"
            for concept_doc in mongo.db.micro_concept.find({'_id': ObjectId(concept_id) if concept_id else None}):
                concept_name = concept_doc.get('name', 'æœªçŸ¥æ¦‚å¿µ')
                break
            
            forgetting_results.append({
                'concept_id': concept_id,
                'concept_name': concept_name,
                'base_mastery': forgetting_data['base_mastery'],
                'current_mastery': forgetting_data['current_mastery'],
                'forgetting_factor': forgetting_data['forgetting_factor'],
                'days_since_practice': forgetting_data['days_since_practice'],
                'review_urgency': forgetting_data['review_urgency'],
                'forgetting_curve_data': forgetting_data['forgetting_curve_data']
            })
            
            # ç”Ÿæˆè¤‡ç¿’å»ºè­°
            if forgetting_data['review_urgency'] != 'low':
                review_recommendations.append({
                    'concept_id': concept_id,
                    'concept_name': concept_name,
                    'urgency': forgetting_data['review_urgency'],
                    'days_since_practice': forgetting_data['days_since_practice'],
                    'current_mastery': forgetting_data['current_mastery'],
                    'suggested_review_time': _get_suggested_review_time(forgetting_data['review_urgency']),
                    'review_method': _get_review_method(forgetting_data['current_mastery'])
                })
        
        # æŒ‰ç·Šæ€¥ç¨‹åº¦æ’åºè¤‡ç¿’å»ºè­°
        review_recommendations.sort(key=lambda x: {'high': 3, 'medium': 2, 'low': 1}[x['urgency']], reverse=True)
        
        return jsonify({
            'success': True,
            'data': {
                'concept_forgetting_analysis': forgetting_results,
                'review_recommendations': review_recommendations,
                'summary': {
                    'total_concepts': len(forgetting_results),
                    'high_urgency_count': len([r for r in review_recommendations if r['urgency'] == 'high']),
                    'medium_urgency_count': len([r for r in review_recommendations if r['urgency'] == 'medium']),
                    'low_urgency_count': len([r for r in review_recommendations if r['urgency'] == 'low'])
                }
            }
        })
        
    except Exception as e:
        logger.error(f'ç²å–éºå¿˜åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}')
        return jsonify({
            'success': False,
            'error': f'ç²å–éºå¿˜åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}'
        }), 500

# ==================== LINE Bot å°ˆç”¨å‡½æ•¸ ====================

def get_learning_analysis_for_linebot(line_id: str) -> str:
    """LINE Bot å°ˆç”¨çš„å­¸ç¿’åˆ†æå‡½æ•¸"""
    try:
        # é€šé line_id æ‰¾åˆ°ç”¨æˆ¶
        user = mongo.db.user.find_one({"lineId": line_id})
        if not user:
            return "âŒ è«‹å…ˆç¶å®šæ‚¨çš„å¸³è™Ÿæ‰èƒ½ä½¿ç”¨å­¸ç¿’åˆ†æåŠŸèƒ½ï¼"
        
        user_email = user.get('email')
        user_name = user.get('name', 'åŒå­¸')
        
        # ç²å–å­¸ç¿’åˆ†ææ•¸æ“š
        quiz_records = get_student_quiz_records(user_email)
        learning_metrics = calculate_learning_metrics(quiz_records)
        
        # è¨ˆç®—æ•´é«”æŒæ¡åº¦
        total_questions = learning_metrics.get('total_questions', 0)
        correct_answers = learning_metrics.get('correct_questions', 0)
        overall_accuracy = (correct_answers / total_questions * 100) if total_questions > 0 else 0
        # ç²å–é ˜åŸŸæ•¸æ“š
        all_domains = list(mongo.db.domain.find({}, {'name': 1, '_id': 1}))
        domain_stats = {}
        
        for record in quiz_records:
            domain_name = record.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
            if domain_name not in domain_stats:
                domain_stats[domain_name] = {'total': 0, 'correct': 0, 'wrong': 0}
            
            domain_stats[domain_name]['total'] += 1
            if record['is_correct']:
                domain_stats[domain_name]['correct'] += 1
            else:
                domain_stats[domain_name]['wrong'] += 1
        
        # æ§‹å»ºé ˜åŸŸæŒæ¡åº¦
        domains = []
        for domain_doc in all_domains:
            domain_name = domain_doc.get('name', 'æœªçŸ¥é ˜åŸŸ')
            stats = domain_stats.get(domain_name, {'total': 0, 'correct': 0, 'wrong': 0})
            mastery = (stats['correct'] / stats['total'] * 100) if stats['total'] > 0 else 0
            
            domains.append({
                'name': domain_name,
                'mastery': mastery,
                'total': stats['total'],
                'correct': stats['correct']
            })
        
        # æ‰¾å‡ºå¼·é …å’Œå¼±é …
        strong_domains = [d for d in domains if d['mastery'] >= 70]
        weak_domains = [d for d in domains if d['mastery'] < 50 and d['total'] > 0]
        
        # æ ¼å¼åŒ–å ±å‘Š
        report = f"""ğŸ“Š å­¸ç¿’åˆ†æå ±å‘Š - {user_name}

ğŸ¯ æ•´é«”è¡¨ç¾ï¼š
â€¢ ç¸½ç­”é¡Œæ•¸ï¼š{total_questions} é¡Œ
â€¢ æ­£ç¢ºç‡ï¼š{overall_accuracy:.1f}%

ğŸ’ª å¼·é …é ˜åŸŸï¼š"""
        
        if strong_domains:
            for domain in strong_domains:
                report += f"\nâ€¢ {domain['name']} ({domain['mastery']:.1f}%)"
        else:
            report += "\nâ€¢ æš«ç„¡å¼·é …é ˜åŸŸ"
        
        report += "\n\nâš ï¸ éœ€è¦åŠ å¼·ï¼š"
        if weak_domains:
            for domain in weak_domains:
                report += f"\nâ€¢ {domain['name']} ({domain['mastery']:.1f}%)"
        else:
            report += "\nâ€¢ æš«ç„¡å¼±é …é ˜åŸŸ"
        
        report += f"""

ğŸ’¡ å­¸ç¿’å»ºè­°ï¼š
1. å°ˆæ³¨æ–¼å¼±é …é ˜åŸŸçš„ç·´ç¿’
2. ä¿æŒæ¯æ—¥å­¸ç¿’ç¿’æ…£
3. å®šæœŸè¤‡ç¿’å·²æŒæ¡çš„çŸ¥è­˜é»

ğŸ“± æ›´å¤šè©³ç´°åˆ†æè«‹è‡³ç¶²ç«™æŸ¥çœ‹ï¼"""
        
        return report
        
    except Exception as e:
        print(f"âŒ LINE Bot å­¸ç¿’åˆ†æå¤±æ•—: {e}")
        return "âŒ å­¸ç¿’åˆ†æåŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

def generate_ai_coach_analysis(overview_data: Dict, domains: List[Dict], quiz_records: List[Dict], user_email: str = None) -> Dict[str, Any]:
    """ç”ŸæˆAIæ•™ç·´åˆ†æï¼ˆä½¿ç”¨Rediså¿«å–ï¼‰"""
    try:
        # ç”Ÿæˆå¿«å–éµ
        # ä½¿ç”¨æ¨™æº–åŒ–çš„å¿«å–éµæ ¼å¼ï¼šlearning_analytics:ai_coach_analysis:{user_email}:{total_attempts}:{total_mastery}
        # èˆ‡å‰ç«¯å­˜å„²å‘½åä¿æŒä¸€è‡´
        total_attempts = overview_data.get('total_attempts', 0)
        total_mastery = overview_data.get('total_mastery', 0)
        cache_key = f"learning_analytics:ai_coach_analysis:{user_email or 'anonymous'}:{total_attempts}:{total_mastery:.2f}"
        
        # æª¢æŸ¥Rediså¿«å–
        cached_data = redis_client.get(cache_key)
        if cached_data:
            # æª¢æŸ¥éµæ˜¯å¦é‚„æœ‰éæœŸæ™‚é–“ï¼ˆé¿å…ä½¿ç”¨å·²éæœŸçš„å¿«å–ï¼‰
            ttl = redis_client.ttl(cache_key)
            if ttl > 0:
                logger.info(f"âœ… ä½¿ç”¨AIæ•™ç·´åˆ†æå¿«å–: {cache_key} (å‰©é¤˜ {ttl} ç§’) - è·³éæ‰€æœ‰æŸ¥è©¢")
                return json.loads(cached_data)
            else:
                # å¦‚æœéµå­˜åœ¨ä½†å·²éæœŸï¼Œåˆªé™¤å®ƒ
                redis_client.delete(cache_key)
                logger.info(f"â° AIæ•™ç·´åˆ†æå¿«å–å·²éæœŸï¼Œåˆªé™¤: {cache_key}")
        else:
            logger.info(f"âŒ AIæ•™ç·´åˆ†æå¿«å–ä¸å­˜åœ¨: {cache_key} - å°‡åŸ·è¡ŒæŸ¥è©¢")
        
        # åªæœ‰åœ¨å¿«å–ä¸å­˜åœ¨æ™‚æ‰åŸ·è¡Œä»¥ä¸‹æŸ¥è©¢
        logger.info(f"ğŸ”„ é–‹å§‹åŸ·è¡ŒAIæ•™ç·´åˆ†ææŸ¥è©¢æµç¨‹...")
        
        # åˆå§‹åŒ–Geminiæ¨¡å‹
        model = init_gemini('gemini-2.5-flash')
        
        # æº–å‚™åˆ†ææ•¸æ“š
        total_attempts = overview_data.get('total_attempts', 0)
        total_mastery = overview_data.get('total_mastery', 0)
        learning_velocity = overview_data.get('learning_velocity', 0)
        retention_rate = overview_data.get('retention_rate', 0)
        
        # æ‰¾å‡ºéœ€è¦é—œæ³¨çš„é ˜åŸŸ
        weak_domains = [d for d in domains if d.get('mastery', 0) < 0.3 and d.get('questionCount', 0) > 0]
        strong_domains = [d for d in domains if d.get('mastery', 0) > 0.7 and d.get('questionCount', 0) > 0]
        
        # åˆ†æéºå¿˜æƒ…æ³
        forgetting_analysis = []
        for domain in domains:
            if domain.get('forgetting_analysis'):
                fa = domain['forgetting_analysis']
                if fa.get('days_since_practice', 0) > 3:
                    forgetting_analysis.append({
                        'name': domain['name'],
                        'days': fa['days_since_practice'],
                        'mastery': fa['current_mastery']
                    })
        
        # æ§‹å»ºGeminiæç¤ºè©
        prompt = f"""
ä½ æ˜¯å­¸ç¿’åˆ†æAIæ•™ç·´ã€‚è«‹åŸºæ–¼ä»¥ä¸‹å­¸ç¿’æ•¸æ“šç”Ÿæˆç°¡æ½”çš„å­¸ç¿’å»ºè­°ï¼ˆä¸è¶…é50å­—ï¼‰ï¼š

å­¸ç¿’æ•¸æ“šï¼š
- ç¸½ç­”é¡Œæ•¸ï¼š{total_attempts}
- æ•´é«”æŒæ¡åº¦ï¼š{total_mastery:.1%}
- å­¸ç¿’é€Ÿåº¦ï¼š{learning_velocity:.1f} æ¦‚å¿µ/å°æ™‚
- è¨˜æ†¶ä¿æŒç‡ï¼š{retention_rate:.1%}

éœ€è¦é—œæ³¨çš„é ˜åŸŸï¼š
{', '.join([d['name'] for d in weak_domains[:3]]) if weak_domains else 'ç„¡'}

è¡¨ç¾è‰¯å¥½çš„é ˜åŸŸï¼š
{', '.join([d['name'] for d in strong_domains[:3]]) if strong_domains else 'ç„¡'}

éºå¿˜æé†’ï¼š
{', '.join([f"{fa['name']}å·²{fa['days']}å¤©æœªè¤‡ç¿’" for fa in forgetting_analysis[:3]]) if forgetting_analysis else 'ç„¡'}

è«‹ç”Ÿæˆï¼š
1. ç°¡æ½”çš„å­¸ç¿’ç‹€æ³ç¸½çµ
2. å…·é«”çš„å­¸ç¿’å»ºè­°
3. éœ€è¦é‡é»é—œæ³¨çš„é ˜åŸŸ
4. è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”

æ ¼å¼ï¼šç›´æ¥è¼¸å‡ºæ–‡å­—ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼ã€‚
"""

        # èª¿ç”¨Gemini API
        response = model.generate_content(prompt)
        ai_analysis = response.text.strip()
        
        result = {
            'analysis': ai_analysis,
            'last_updated': datetime.now().strftime('%m/%d %H:%M'),
            'weak_domains': [d['name'] for d in weak_domains[:3]],
            'strong_domains': [d['name'] for d in strong_domains[:3]],
            'forgetting_reminders': forgetting_analysis[:3]
        }
        
        # å¿«å–çµæœåˆ°Redisï¼ˆ2å°æ™‚ï¼‰
        # ä½¿ç”¨ SET ... NX EX åŸå­æ“ä½œï¼šåªåœ¨éµä¸å­˜åœ¨æ™‚è¨­ç½®ï¼Œä¸¦è¨­ç½®éæœŸæ™‚é–“
        # é¿å…é‡è¤‡å‰µå»ºç›¸åŒéµåï¼Œç¢ºä¿æ‰€æœ‰å¿«å–éƒ½æœ‰éæœŸæ™‚é–“
        cache_ttl = 2 * 60 * 60  # 2å°æ™‚
        cache_value = json.dumps(result, ensure_ascii=False)
        
        # ä½¿ç”¨åŸå­æ“ä½œ SET ... NX EXï¼šåªåœ¨éµä¸å­˜åœ¨æ™‚å‰µå»ºï¼Œä¸¦è‡ªå‹•è¨­ç½®éæœŸæ™‚é–“
        set_result = redis_client.set(cache_key, cache_value, ex=cache_ttl, nx=True)
        if set_result:
            logger.info(f"AIæ•™ç·´åˆ†æå·²å¿«å–: {cache_key} (éæœŸæ™‚é–“: {cache_ttl} ç§’)")
        else:
            # éµå·²å­˜åœ¨ï¼Œå¯èƒ½æ˜¯ä¸¦ç™¼è«‹æ±‚å‰µå»ºçš„ï¼Œè¨˜éŒ„ä½†ä¸å ±éŒ¯ï¼ˆé€™æ˜¯æ­£å¸¸æƒ…æ³ï¼‰
            logger.debug(f"AIæ•™ç·´åˆ†æå¿«å–éµå·²å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯ä¸¦ç™¼è«‹æ±‚ï¼‰ï¼Œè·³éå‰µå»º: {cache_key}")
        
        return result
        
    except Exception as e:
        logger.error(f"ç”ŸæˆAIæ•™ç·´åˆ†æå¤±æ•—: {e}")
        return {
            'analysis': 'æ­£åœ¨åˆ†ææ‚¨çš„å­¸ç¿’æ•¸æ“š...',
            'last_updated': datetime.now().strftime('%m/%d %H:%M'),
            'weak_domains': [],
            'strong_domains': [],
            'forgetting_reminders': []
        }

def generate_learning_trends_with_forgetting(domains: List[Dict], quiz_records: List[Dict], trend_days: int) -> List[Dict]:
    """ç”Ÿæˆçµåˆéºå¿˜æ›²ç·šçš„å­¸ç¿’è¶¨å‹¢æ•¸æ“š"""
    trends = []
    
    # æŒ‰æ—¥æœŸåˆ†çµ„ç­”é¡Œè¨˜éŒ„
    from collections import defaultdict
    daily_records = defaultdict(list)
    
    for record in quiz_records:
        try:
            date_str = record['attempt_time'][:10]  # æå–æ—¥æœŸéƒ¨åˆ†
            daily_records[date_str].append(record)
        except:
            continue
    
    # ç”Ÿæˆè¶¨å‹¢æ•¸æ“š
    for i in range(trend_days):
        date = (datetime.now() - timedelta(days=trend_days-1-i)).strftime('%Y-%m-%d')
        day_records = daily_records.get(date, [])
        
        if day_records:
            # è¨ˆç®—ç•¶å¤©çš„å­¸ç¿’æŒ‡æ¨™
            total_questions = len(day_records)
            correct_questions = sum(1 for r in day_records if r['is_correct'])
            accuracy = correct_questions / total_questions if total_questions > 0 else 0
            
            # è¨ˆç®—éºå¿˜æ›²ç·šæ•¸æ“š
            forgetting_data = []
            for domain in domains:
                if domain.get('forgetting_analysis'):
                    fa = domain['forgetting_analysis']
                    forgetting_data.append({
                        'domain': domain['name'],
                        'current_mastery': fa.get('current_mastery', 0),
                        'days_since_practice': fa.get('days_since_practice', 0)
                    })
            
            trends.append({
                'date': date,
                'questions': total_questions,
                'accuracy': accuracy,
                'mastery': accuracy,  # ä½¿ç”¨æº–ç¢ºç‡ä½œç‚ºæŒæ¡åº¦
                'forgetting_data': forgetting_data
            })
        else:
            trends.append({
                'date': date,
                'questions': 0,
                'accuracy': 0,
                'mastery': 0,
                'forgetting_data': []
            })
    
    return trends

def _get_suggested_review_time(urgency: str) -> str:
    """æ ¹æ“šç·Šæ€¥ç¨‹åº¦ç²å–å»ºè­°è¤‡ç¿’æ™‚é–“"""
    if urgency == 'high':
        return 'ç«‹å³è¤‡ç¿’'
    elif urgency == 'medium':
        return '3å¤©å…§è¤‡ç¿’'
    else:
        return '1é€±å…§è¤‡ç¿’'

def calculate_enhanced_learning_velocity(quiz_records: List[Dict]) -> float:
    """è¨ˆç®—å­¸ç¿’é€Ÿåº¦ - åŸºæ–¼Piech et al., 2015 Deep Knowledge Tracingæ–‡ç»"""
    if not quiz_records:
        return 0.0
    
    # åªè¨ˆç®—ç­”å°çš„é¡Œç›®ï¼Œå› ç‚ºç­”éŒ¯ä¸ç®—å­¸ç¿’
    correct_records = [r for r in quiz_records if r.get('is_correct', False)]
    if not correct_records:
        return 0.0
    
    # æŒ‰ç…§æ–‡ç»æ¼”ç®—æ³•ï¼šè¨ˆç®—å­¸ç¿’çš„æ¦‚å¿µæ•¸é‡ï¼ˆå»é‡ï¼‰
    concept_hours = set()
    for record in correct_records:
        concept_id = record.get('micro_concept_id')
        if concept_id:
            # ç²¾ç¢ºåˆ°å°æ™‚ï¼Œé¿å…åŒä¸€å¤©å¤šæ¬¡ç­”å°åŒä¸€æ¦‚å¿µé‡è¤‡è¨ˆç®—
            hour_key = record['attempt_time'][:13]  # YYYY-MM-DDTHH
            concept_hours.add((hour_key, concept_id))
    
    # è¨ˆç®—ç¸½å­¸ç¿’å°æ™‚æ•¸ï¼ˆæ‰€æœ‰ç­”é¡Œè¨˜éŒ„çš„ä¸åŒå°æ™‚æ•¸ï¼‰
    total_hours = len(set(r['attempt_time'][:13] for r in quiz_records))
    
    if total_hours == 0:
        return 0.0
    
    # å­¸ç¿’é€Ÿåº¦ = æŒæ¡çš„æ¦‚å¿µæ•¸é‡ / ç¸½å­¸ç¿’å°æ™‚æ•¸
    velocity = len(concept_hours) / max(total_hours, 1)
    

    
    return round(velocity, 1)

def calculate_enhanced_retention_rate(quiz_records: List[Dict]) -> float:
    """è¨ˆç®—è¨˜æ†¶ä¿æŒç‡ - åŸºæ–¼æ··åˆæ¼”ç®—æ³•çš„æ™‚é–“è¡°æ¸›"""
    if not quiz_records:
        return 0.0
    
    # ä½¿ç”¨æ··åˆæ¼”ç®—æ³•è¨ˆç®—æ•´é«”æŒæ¡åº¦
    overall_mastery = calculate_mixed_mastery(quiz_records)
    
    # è¨˜æ†¶ä¿æŒç‡ = æ··åˆæŒæ¡åº¦ï¼ˆå·²åŒ…å«æ™‚é–“è¡°æ¸›ï¼‰
    return overall_mastery

def calculate_mixed_mastery(quiz_records: List[Dict], concept_id: str = None) -> float:
    """è¨ˆç®—æ··åˆæŒæ¡åº¦ - åŸºæ–¼PFA + Forgetting-aware BKT + Difficulty-aware KTï¼Œæ·»åŠ é›£åº¦ä¸Šé™é™åˆ¶"""
    if not quiz_records:
        return 0.0
    
    import math
    from datetime import datetime
    
    # å¦‚æœæŒ‡å®šæ¦‚å¿µIDï¼Œåªè¨ˆç®—è©²æ¦‚å¿µçš„è¨˜éŒ„
    if concept_id:
        concept_records = [r for r in quiz_records if r.get('micro_concept_id') == concept_id]
    else:
        concept_records = quiz_records
    
    if not concept_records:
        return 0.0
    
    # æŒ‰æ™‚é–“æ’åº
    concept_records.sort(key=lambda x: x['attempt_time'])
    
    # åƒæ•¸è¨­å®šï¼ˆèª¿æ•´ç‚ºæ›´åˆç†çš„å€¼ï¼‰
    theta = 0.0   # åŸºç¤èƒ½åŠ›åƒæ•¸ï¼ˆèª¿æ•´ç‚º0ï¼‰
    w_s = 0.4    # æˆåŠŸæ¬Šé‡ï¼ˆå¢åŠ ï¼‰
    w_f = 0.2    # å¤±æ•—æ¬Šé‡ï¼ˆæ¸›å°‘ï¼‰
    w_d = 0.2    # é›£åº¦æ¬Šé‡ï¼ˆæ¸›å°‘ï¼‰
    w_t = 0.2    # æ™‚é–“è¡°æ¸›æ¬Šé‡ï¼ˆæ¸›å°‘ï¼‰
    lambda_decay = 0.05  # éºå¿˜ç‡ï¼ˆæ¸›å°‘ï¼‰
    
    # è¨ˆç®—æœ€è¿‘çš„æˆåŠŸå’Œå¤±æ•—æ¬¡æ•¸ï¼ˆåŠ æ¬Šï¼‰
    successes_recent = 0
    failures_recent = 0
    difficulty_sum = 0
    time_decay_sum = 0
    
    current_time = datetime.now()
    
    for i, record in enumerate(concept_records):
        # æ™‚é–“æ¬Šé‡ï¼šæœ€è¿‘çš„ç­”é¡Œæ¬Šé‡æ›´é«˜
        attempt_time = datetime.fromisoformat(record['attempt_time'].replace('Z', '+00:00'))
        # è½‰æ›ç‚ºnaive datetime
        attempt_time = attempt_time.replace(tzinfo=None)
        time_diff_hours = (current_time - attempt_time).total_seconds() / 3600
        time_weight = math.exp(-lambda_decay * time_diff_hours / 24)  # æŒ‰å¤©è¨ˆç®—
        
        # é›£åº¦æ¬Šé‡
        difficulty = record.get('difficulty', 'ä¸­ç­‰')
        difficulty_weight = {'ç°¡å–®': 1.0, 'ä¸­ç­‰': 2.0, 'å›°é›£': 3.0}.get(difficulty, 2.0)
        
        # æ™‚é–“è¡°æ¸›
        time_decay = math.exp(-lambda_decay * time_diff_hours / 24)
        
        if record.get('is_correct', False):
            successes_recent += time_weight
        else:
            failures_recent += time_weight
        
        difficulty_sum += difficulty_weight * time_weight
        time_decay_sum += time_decay * time_weight
    
    # è¨ˆç®—å¹³å‡é›£åº¦å’Œæ™‚é–“è¡°æ¸›
    total_attempts = len(concept_records)
    avg_difficulty = difficulty_sum / total_attempts if total_attempts > 0 else 2.0
    avg_time_decay = time_decay_sum / total_attempts if total_attempts > 0 else 1.0
    
    # æ··åˆæŒæ¡åº¦å…¬å¼ï¼ˆä¿æŒåŸæœ¬çš„è¨ˆç®—æ–¹å¼ï¼‰
    mastery_raw = theta + w_s * successes_recent - w_f * failures_recent - w_d * avg_difficulty + w_t * avg_time_decay
    
    # Sigmoidå‡½æ•¸å£“ç¸®åˆ°0-1
    mastery = 1 / (1 + math.exp(-mastery_raw))
    
    # æ·»åŠ é›£åº¦ä¸Šé™é™åˆ¶
    difficulty_limits = {
        'ç°¡å–®': 0.6,  # ç°¡å–®é¡Œæœ€å¤š60%
        'ä¸­ç­‰': 0.8,  # ä¸­ç­‰é¡Œæœ€å¤š80%
        'å›°é›£': 1.0   # å›°é›£é¡Œæœ€å¤š100%
    }
    
    # æ ¹æ“šç­”é¡Œè¨˜éŒ„ä¸­ä¸»è¦é›£åº¦è¨­å®šä¸Šé™
    difficulty_counts = {'ç°¡å–®': 0, 'ä¸­ç­‰': 0, 'å›°é›£': 0}
    for record in concept_records:
        difficulty = record.get('difficulty', 'ä¸­ç­‰')
        if difficulty in difficulty_counts:
            difficulty_counts[difficulty] += 1
    
    # æ‰¾å‡ºä¸»è¦é›£åº¦ï¼ˆç­”é¡Œæ¬¡æ•¸æœ€å¤šçš„ï¼‰
    main_difficulty = max(difficulty_counts, key=difficulty_counts.get)
    max_mastery = difficulty_limits.get(main_difficulty, 1.0)
    
    # æ‡‰ç”¨ä¸Šé™é™åˆ¶
    mastery = min(mastery, max_mastery)
    
    return round(mastery, 3)

def calculate_enhanced_avg_time_per_concept(quiz_records: List[Dict]) -> float:
    """è¨ˆç®—å¹³å‡æŒæ¡æ™‚é–“ - åŸºæ–¼æ··åˆæ¼”ç®—æ³•"""
    if not quiz_records:
        return 0.0
    
    # åªè¨ˆç®—ç­”å°çš„é¡Œç›®
    correct_records = [r for r in quiz_records if r.get('is_correct', False)]
    if not correct_records:
        return 0.0
    
    # è¨ˆç®—æ‰€æœ‰ç­”å°é¡Œç›®çš„å¹³å‡æ™‚é–“
    total_time = 0
    count = 0
    
    for record in correct_records:
        time_spent = record.get('time_spent', 0)
        if time_spent > 0:
            total_time += time_spent
            count += 1
    
    if count == 0:
        return 0.0
    
    # è¿”å›å¹³å‡æ™‚é–“ï¼ˆåˆ†é˜ï¼‰
    return (total_time / count) / 60

def calculate_enhanced_focus_score(quiz_records: List[Dict]) -> float:
    """è¨ˆç®—å¢å¼·ç‰ˆå°ˆæ³¨ç¨‹åº¦ - åŸºæ–¼å°ˆæ³¨åº¦åˆ†ææ¼”ç®—æ³•"""
    if not quiz_records:
        return 0.0
    
    from collections import defaultdict
    from datetime import datetime, timezone, timedelta
    
    # æŒ‰æœƒè©±åˆ†çµ„ï¼ˆ30åˆ†é˜å…§çš„ç­”é¡Œè¦–ç‚ºåŒä¸€æœƒè©±ï¼‰
    session_groups = defaultdict(list)
    current_session = []
    last_time = None
    
    for record in sorted(quiz_records, key=lambda x: x['attempt_time']):
        attempt_time = datetime.fromisoformat(record['attempt_time'].replace('Z', '+00:00'))
        
        if last_time is None or (attempt_time - last_time).total_seconds() > 1800:  # 30åˆ†é˜
            if current_session:
                session_groups[len(session_groups)] = current_session
            current_session = [record]
        else:
            current_session.append(record)
        
        last_time = attempt_time
    
    if current_session:
        session_groups[len(session_groups)] = current_session
    
    if not session_groups:
        return 0.0
    
    session_scores = []
    
    for session_id, session_records in session_groups.items():
        if len(session_records) < 2:
            continue
            
        # è¨ˆç®—æœƒè©±å°ˆæ³¨åº¦æŒ‡æ¨™
        total_questions = len(session_records)
        correct_questions = sum(1 for r in session_records if r.get('is_correct', False))
        accuracy = correct_questions / total_questions
        
        # æ™‚é–“ä¸€è‡´æ€§ï¼ˆç­”é¡Œé–“éš”æ˜¯å¦ç©©å®šï¼‰
        time_intervals = []
        for i in range(1, len(session_records)):
            prev_time = datetime.fromisoformat(session_records[i-1]['attempt_time'].replace('Z', '+00:00'))
            curr_time = datetime.fromisoformat(session_records[i]['attempt_time'].replace('Z', '+00:00'))
            interval = (curr_time - prev_time).total_seconds()
            time_intervals.append(interval)
        
        # è¨ˆç®—æ™‚é–“é–“éš”çš„è®Šç•°ä¿‚æ•¸ï¼ˆè¶Šå°è¶Šå°ˆæ³¨ï¼‰
        if time_intervals:
            avg_interval = sum(time_intervals) / len(time_intervals)
            variance = sum((x - avg_interval) ** 2 for x in time_intervals) / len(time_intervals)
            cv = (variance ** 0.5) / avg_interval if avg_interval > 0 else 1
            time_consistency = max(0, 1 - cv)  # è®Šç•°ä¿‚æ•¸è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜
        else:
            time_consistency = 0
        
        # é›£åº¦é©æ‡‰æ€§ï¼ˆèƒ½å¦è™•ç†ä¸åŒé›£åº¦çš„é¡Œç›®ï¼‰
        difficulties = [r.get('difficulty', 'ä¸­ç­‰') for r in session_records]
        difficulty_diversity = len(set(difficulties)) / 3  # æœ€å¤š3ç¨®é›£åº¦
        
        # é€£çºŒç­”å°ç‡ï¼ˆå°ˆæ³¨æ™‚æ›´å®¹æ˜“é€£çºŒç­”å°ï¼‰
        consecutive_correct = 0
        max_consecutive = 0
        for r in session_records:
            if r.get('is_correct', False):
                consecutive_correct += 1
                max_consecutive = max(max_consecutive, consecutive_correct)
            else:
                consecutive_correct = 0
        
        consecutive_rate = max_consecutive / total_questions if total_questions > 0 else 0
        
        # ç¶œåˆå°ˆæ³¨åº¦åˆ†æ•¸
        focus_score = (
            accuracy * 0.4 +           # æº–ç¢ºç‡æ¬Šé‡40%
            time_consistency * 0.3 +   # æ™‚é–“ä¸€è‡´æ€§æ¬Šé‡30%
            difficulty_diversity * 0.2 + # é›£åº¦é©æ‡‰æ€§æ¬Šé‡20%
            consecutive_rate * 0.1     # é€£çºŒç­”å°ç‡æ¬Šé‡10%
        )
        
        session_scores.append(focus_score)
    
    return sum(session_scores) / len(session_scores) if session_scores else 0.0

def _get_review_method(current_mastery: float) -> str:
    """æ ¹æ“šç•¶å‰æŒæ¡åº¦ç²å–è¤‡ç¿’æ–¹æ³•"""
    if current_mastery < 0.3:
        return 'é‡æ–°å­¸ç¿’åŸºç¤æ¦‚å¿µ'
    elif current_mastery < 0.6:
        return 'é‡é»ç·´ç¿’ç›¸é—œé¡Œç›®'
    else:
        return 'å¿«é€Ÿè¤‡ç¿’éå›ºè¨˜æ†¶'

def calculate_graph_based_mastery(student_id: str, concept_id: str, knowledge_graph: Dict = None) -> Dict[str, Any]:
    """è¨ˆç®—åœ–åŸºæ–¼çš„æŒæ¡åº¦é æ¸¬ - Graph-based KT"""
    try:
        # ç²å–å­¸ç”Ÿç­”é¡Œè¨˜éŒ„
        quiz_records = get_student_quiz_records(student_id)
        
        # ç²å–çŸ¥è­˜é»é—œè¯é—œä¿‚ - éœ€è¦å…ˆç²å–æ¦‚å¿µåç¨±
        # å¾æ¦‚å¿µIDç²å–æ¦‚å¿µåç¨±ï¼ˆå¾MongoDBæŸ¥è©¢ï¼‰
        concept_name = get_concept_name_by_id(concept_id)
        logger.info(f"ğŸ” [DEBUG] ç²å–æ¦‚å¿µåç¨±: {concept_id} -> {concept_name}")
        
        concept_relations = get_knowledge_relations_from_neo4j(concept_name)
        logger.info(f"ğŸ” [DEBUG] Neo4jé—œè¯é—œä¿‚: å‰ç½®={len(concept_relations.get('prerequisites', []))}, ç›¸é—œ={len(concept_relations.get('related_concepts', []))}")
        
        # ç°¡åŒ–çš„åœ–ç¥ç¶“ç¶²çµ¡é æ¸¬ï¼ˆåŸºæ–¼é—œè¯çŸ¥è­˜é»çš„æŒæ¡åº¦ï¼‰
        related_concepts = concept_relations.get('prerequisites', []) + concept_relations.get('related_concepts', [])
        
        # è¨ˆç®—é—œè¯çŸ¥è­˜é»çš„å¹³å‡æŒæ¡åº¦
        related_mastery_scores = []
        for related_concept in related_concepts:
            related_concept_id = related_concept.get('id', '')
            related_records = [r for r in quiz_records if r['micro_concept_id'] == related_concept_id]
            if related_records:
                mastery = sum(1 for r in related_records if r['is_correct']) / len(related_records)
                related_mastery_scores.append(mastery)
        
        # é æ¸¬ç•¶å‰çŸ¥è­˜é»çš„æŒæ¡åº¦
        if related_mastery_scores:
            predicted_mastery = sum(related_mastery_scores) / len(related_mastery_scores)
            # æ ¹æ“šé—œè¯å¼·åº¦èª¿æ•´é æ¸¬
            avg_relation_strength = sum(r.get('strength', 0.5) for r in related_concepts) / len(related_concepts) if related_concepts else 0.5
            predicted_mastery *= avg_relation_strength
        else:
            predicted_mastery = 0.5  # é»˜èªä¸­ç­‰æŒæ¡åº¦
        
        # ç”Ÿæˆå­¸ç¿’è·¯å¾‘æ¨è–¦ï¼ˆåŸºæ–¼Neo4jé—œè¯é—œä¿‚ï¼‰
        learning_path = generate_learning_path_recommendations(concept_id, concept_relations, quiz_records)
        
        return {
            'predicted_mastery': round(predicted_mastery, 2),
            'confidence': min(0.9, len(related_mastery_scores) * 0.2),  # åŸºæ–¼é—œè¯çŸ¥è­˜é»æ•¸é‡
            'related_concepts': related_concepts,
            'learning_path': learning_path,
            'prerequisites_analysis': analyze_prerequisites(concept_relations.get('prerequisites', []), quiz_records)
        }
        
    except Exception as e:
        logger.error(f"åœ–åŸºæ–¼æŒæ¡åº¦é æ¸¬å¤±æ•—: {e}")
        return {
            'predicted_mastery': 0.5,
            'confidence': 0.1,
            'related_concepts': [],
            'learning_path': [],
            'prerequisites_analysis': []
        }

def generate_learning_path_recommendations(concept_id: str, concept_relations: Dict, quiz_records: List[Dict]) -> List[Dict]:
    """ä½¿ç”¨AIç”Ÿæˆå€‹æ€§åŒ–å­¸ç¿’è·¯å¾‘æ¨è–¦"""
    try:
        # ç²å–ç•¶å‰æ¦‚å¿µçš„æŒæ¡åº¦
        current_records = [r for r in quiz_records if r['micro_concept_id'] == concept_id]
        current_mastery = sum(1 for r in current_records if r['is_correct']) / len(current_records) if current_records else 0
        current_concept_name = get_concept_name_by_id(concept_id)
        
        # åˆ†æå­¸ç¿’æ­·å²
        total_attempts = len(current_records)
        recent_attempts = len([r for r in current_records if r['attempt_time'] >= (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')])
        avg_time_per_question = sum(r.get('time_spent', 0) for r in current_records) / len(current_records) if current_records else 0
        
        # åˆ†æéŒ¯èª¤æ¨¡å¼
        wrong_records = [r for r in current_records if not r['is_correct']]
        common_errors = []
        if wrong_records:
            # ç°¡å–®çš„éŒ¯èª¤åˆ†æï¼ˆå¯¦éš›å¯ä»¥æ›´è¤‡é›œï¼‰
            common_errors = ['æ¦‚å¿µç†è§£ä¸è¶³', 'è¨ˆç®—éŒ¯èª¤', 'æ‡‰ç”¨èƒ½åŠ›æ¬ ç¼º']
        
        # åˆ†æå‰ç½®çŸ¥è­˜é»
        prerequisites = concept_relations.get('prerequisites', [])
        related_concepts = concept_relations.get('related_concepts', [])
        
        # æº–å‚™AIæç¤ºè© - å¼·åŒ–Neo4jé—œè¯è¦æ±‚
        # æ§‹å»ºè©³ç´°çš„é—œè¯è³‡è¨Š
        relations_context = ""
        if concept_relations and concept_relations.get('has_relations', False):
            prereqs = concept_relations.get('prerequisites', [])
            related = concept_relations.get('related_concepts', [])
            leads_to = concept_relations.get('leads_to', [])
            
            if prereqs:
                prereq_list = [f"{p['name']}(å¼·åº¦:{p.get('strength', 0.5):.2f})" for p in prereqs[:5]]
                relations_context += f"\n- **å‰ç½®çŸ¥è­˜é»**ï¼ˆå¿…é ˆå…ˆæŒæ¡ï¼ŒæŒ‰å¼·åº¦æ’åºï¼‰ï¼š{', '.join(prereq_list)}"
            
            if related:
                related_list = [f"{r['name']}(å¼·åº¦:{r.get('strength', 0.5):.2f})" for r in related[:5]]
                relations_context += f"\n- **ç›¸é—œçŸ¥è­˜é»**ï¼ˆå¯åŒæ™‚å­¸ç¿’ï¼‰ï¼š{', '.join(related_list)}"
            
            if leads_to:
                leads_list = [f"{l['name']}(å¼·åº¦:{l.get('strength', 0.5):.2f})" for l in leads_to[:5]]
                relations_context += f"\n- **å¾ŒçºŒçŸ¥è­˜é»**ï¼ˆæŒæ¡å¾Œå¯å­¸ç¿’ï¼‰ï¼š{', '.join(leads_list)}"
        else:
            relations_context = "\n- âš ï¸ **ç„¡Neo4jé—œè¯æ•¸æ“š**ï¼šæ­¤çŸ¥è­˜é»åœ¨çŸ¥è­˜åœ–è­œä¸­æ²’æœ‰é—œè¯é—œä¿‚ã€‚"
        
        prompt = f"""
ä½ æ˜¯å€‹æ€§åŒ–å­¸ç¿’è·¯å¾‘è¨­è¨ˆAIã€‚è«‹ç‚ºå­¸ç”Ÿè¨­è¨ˆ3-5å€‹å…·é«”çš„å­¸ç¿’æ­¥é©Ÿï¼Œå¹«åŠ©ä»–å€‘ç³»çµ±æ€§åœ°æŒæ¡çŸ¥è­˜ã€‚

**âš ï¸ é‡è¦ï¼šå­¸ç¿’è·¯å¾‘è¨­è¨ˆå¿…é ˆåš´æ ¼éµå¾ªNeo4jçŸ¥è­˜åœ–è­œçš„é—œè¯é—œä¿‚ï¼**

å­¸ç”Ÿè³‡æ–™ï¼š
- æ¦‚å¿µï¼š{current_concept_name}
- ç•¶å‰æŒæ¡åº¦ï¼š{current_mastery:.1%}
- ç¸½ç­”é¡Œæ¬¡æ•¸ï¼š{total_attempts}
- æœ€è¿‘7å¤©ç­”é¡Œï¼š{recent_attempts}æ¬¡
- å¹³å‡ç­”é¡Œæ™‚é–“ï¼š{avg_time_per_question:.1f}åˆ†é˜
- å¸¸è¦‹éŒ¯èª¤ï¼š{', '.join(common_errors) if common_errors else 'ç„¡'}

**Neo4jçŸ¥è­˜åœ–è­œé—œè¯é—œä¿‚ï¼ˆå¿…é ˆåƒè€ƒï¼‰ï¼š**
{relations_context}

**è¨­è¨ˆè¦æ±‚ï¼ˆå¿…é ˆéµå®ˆï¼‰ï¼š**
1. **å¦‚æœæœ‰å‰ç½®çŸ¥è­˜é»ä¸”æŒæ¡åº¦ä½**ï¼š
   - ç¬¬ä¸€æ­¥å¿…é ˆæ˜¯ã€Œå…ˆå­¸ç¿’å‰ç½®çŸ¥è­˜é»ï¼š[å…·é«”çŸ¥è­˜é»åç¨±]ã€
   - å¿…é ˆæŒ‰ç…§å‰ç½®çŸ¥è­˜é»çš„å¼·åº¦é †åºå®‰æ’å­¸ç¿’
   - å¦‚æœæœ‰å¤šå€‹å‰ç½®çŸ¥è­˜é»ï¼Œå¿…é ˆå…ˆå­¸ç¿’å¼·åº¦æœ€é«˜çš„

2. **å­¸ç¿’é †åºå¿…é ˆç¬¦åˆçŸ¥è­˜åœ–è­œé‚è¼¯**ï¼š
   - å‰ç½®çŸ¥è­˜é» â†’ ç•¶å‰æ¦‚å¿µåŸºç¤ â†’ ç•¶å‰æ¦‚å¿µæ‡‰ç”¨ â†’ ç›¸é—œçŸ¥è­˜é»æ‹“å±• â†’ å¾ŒçºŒçŸ¥è­˜é»é ç¿’

3. **å¦‚æœæ²’æœ‰Neo4jé—œè¯æ•¸æ“š**ï¼š
   - åŸºæ–¼ä¸€èˆ¬æ•™å­¸åŸå‰‡è¨­è¨ˆå­¸ç¿’è·¯å¾‘
   - åœ¨step_infoä¸­èªªæ˜ã€Œç¼ºå°‘çŸ¥è­˜åœ–è­œæ•¸æ“šï¼Œä½¿ç”¨ä¸€èˆ¬å­¸ç¿’é †åºã€

è«‹è¿”å›JSONæ ¼å¼çš„å­¸ç¿’è·¯å¾‘ï¼ŒåŒ…å«3å€‹æ­¥é©Ÿï¼Œæ¯å€‹æ­¥é©Ÿéœ€è¦ï¼š
- step_info: å­¸ç¿’ä»»å‹™æè¿°ï¼ˆå¦‚"å»èª²ç¨‹è§€çœ‹äºŒç¶­é™£åˆ—åŸºç¤çŸ¥è­˜"ï¼‰
- estimated_time: é ä¼°æ™‚é–“ï¼ˆåˆ†é˜ï¼Œæ•¸å­—ï¼‰
- step_order: æ­¥é©Ÿé †åºï¼ˆ1,2,3ï¼‰

è¦æ±‚ï¼š
1. æ ¹æ“šæŒæ¡åº¦è¨­è¨ˆé©åˆçš„å­¸ç¿’æ­¥é©Ÿï¼ˆä½æŒæ¡åº¦<30%ï¼šåŸºç¤å­¸ç¿’ï¼Œä¸­ç­‰30-70%ï¼šå¼·åŒ–ç·´ç¿’ï¼Œé«˜>70%ï¼šéå›ºæ‹“å±•ï¼‰
2. æ¯å€‹æ­¥é©Ÿéƒ½è¦å…·é«”æ˜ç¢ºï¼Œä½¿ç”¨ç°¡å–®æ˜“æ‡‚çš„æè¿°
3. æ­¥é©Ÿè¦æœ‰é‚è¼¯é †åºï¼Œå¾ªåºæ¼¸é€²
4. è€ƒæ…®å­¸ç”Ÿçš„å­¸ç¿’æ­·å²å’ŒéŒ¯èª¤æ¨¡å¼
5. å­¸ç¿’æ–¹å¼å¤šæ¨£åŒ–ï¼ˆè§€çœ‹èª²ç¨‹ã€ç·´ç¿’é¡Œç›®ã€å¯¦éš›æ‡‰ç”¨ç­‰ï¼‰
6. æ™‚é–“åˆ†é…åˆç†ï¼ˆç¸½è¨ˆä¸è¶…é60åˆ†é˜ï¼‰
7. æè¿°è¦ç°¡æ½”æ˜ç­ï¼Œé¿å…éæ–¼è¤‡é›œçš„è¡“èª

è¿”å›æ ¼å¼ï¼š
{{
  "learning_path": [
    {{
      "step_info": "å»èª²ç¨‹è§€çœ‹äºŒç¶­é™£åˆ—åŸºç¤çŸ¥è­˜",
      "estimated_time": 15,
      "step_order": 1
    }},
    {{
      "step_info": "ç·´ç¿’äºŒç¶­é™£åˆ—åŸºç¤é¡Œç›®10é¡Œ",
      "estimated_time": 20,
      "step_order": 2
    }},
    {{
      "step_info": "è§£æ±º3å€‹äºŒç¶­é™£åˆ—å¯¦éš›æ‡‰ç”¨å•é¡Œ",
      "estimated_time": 25,
      "step_order": 3
    }}
  ]
}}
"""
        
        # èª¿ç”¨Gemini API
        model = init_gemini('gemini-2.5-flash')
        response = model.generate_content(prompt)
        ai_response = response.text.strip()
        
        # è§£æAIå›æ‡‰
        import json
        try:
            # æ¸…ç†å›æ‡‰ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            if ai_response.startswith('```json'):
                ai_response = ai_response[7:]
            if ai_response.endswith('```'):
                ai_response = ai_response[:-3]
            
            ai_data = json.loads(ai_response)
            learning_path = ai_data.get('learning_path', [])
            
            # ç¢ºä¿learning_pathæ˜¯åˆ—è¡¨ä¸”ä¸ç‚ºNone
            if not learning_path or not isinstance(learning_path, list):
                logger.warning("AIå›å‚³çš„learning_pathç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤ï¼Œä½¿ç”¨é»˜èªè·¯å¾‘")
                learning_path = []
            
            # ç¢ºä¿æ¯å€‹æ­¥é©Ÿéƒ½æœ‰å¿…è¦çš„å­—æ®µ
            for step in learning_path:
                if step and isinstance(step, dict):
                    step.setdefault('step_order', 1)
                    step.setdefault('estimated_time', 15)
            
            logger.info(f"AIç”Ÿæˆå­¸ç¿’è·¯å¾‘æˆåŠŸï¼š{len(learning_path)}å€‹æ­¥é©Ÿ")
            return learning_path
            
        except json.JSONDecodeError as e:
            logger.error(f"AIå›æ‡‰JSONè§£æå¤±æ•—: {e}")
            logger.error(f"AIåŸå§‹å›æ‡‰: {ai_response}")
    except Exception as e:
        logger.error(f"AIç”Ÿæˆå­¸ç¿’è·¯å¾‘å¤±æ•—: {e}")

def ensure_diverse_action_types(top_actions: List[Dict], learning_path: List[Dict]) -> List[Dict]:
    """
    ç¢ºä¿ top_actions åŒ…å«ä¸‰ç¨®ä¸åŒé¡å‹ï¼ˆSEEK_HELP, REVIEW_BASICS, PRACTICEï¼‰
    å¦‚æœ AI è¿”å›çš„é¡å‹é‡è¤‡ï¼Œæ ¹æ“š learning_path è‡ªå‹•ä¿®æ­£
    
    Args:
        top_actions: AI ç”Ÿæˆçš„ top_actions åˆ—è¡¨
        learning_path: å­¸ç¿’è·¯å¾‘æ­¥é©Ÿåˆ—è¡¨
        
    Returns:
        ä¿®æ­£å¾Œçš„ top_actions åˆ—è¡¨ï¼Œç¢ºä¿åŒ…å«ä¸‰ç¨®ä¸åŒé¡å‹
    """
    if not top_actions or not learning_path:
        return top_actions
    
    # å®šç¾©é—œéµå­—æ˜ å°„
    def infer_type(step_info: str) -> str:
        if not step_info:
            return "SEEK_HELP"
        step_lower = step_info.lower()
        # ç·´ç¿’å„ªå…ˆ
        if any(kw in step_info for kw in ['ç·´ç¿’', 'ç­”é¡Œ', 'æ‡‰ç”¨', 'å˜—è©¦', 'å›ç­”', 'å•é¡Œ', 'æƒ…å¢ƒ']):
            return "PRACTICE"
        # ç†è§£/æŒæ¡
        if any(kw in step_info for kw in ['æ·±å…¥ç†è§£', 'ç†è§£', 'æŒæ¡', 'éå›º']):
            return "REVIEW_BASICS"
        # è§€çœ‹/é–±è®€
        if any(kw in step_info for kw in ['è§€çœ‹', 'é–±è®€', 'èª²ç¨‹']):
            return "SEEK_HELP"
        # å­¸ç¿’
        if any(kw in step_info for kw in ['å­¸ç¿’']):
            return "REVIEW_BASICS"
        return "SEEK_HELP"
    
    # æª¢æŸ¥ç¾æœ‰é¡å‹
    existing_types = [action.get('action', '') for action in top_actions[:3]]
    required_types = ['SEEK_HELP', 'REVIEW_BASICS', 'PRACTICE']
    missing_types = [t for t in required_types if t not in existing_types]
    
    # å¦‚æœå·²ç¶“æœ‰ä¸‰ç¨®ä¸åŒé¡å‹ï¼Œç›´æ¥è¿”å›
    if len(set(existing_types)) == 3:
        return top_actions[:3]
    
    # éœ€è¦ä¿®æ­£ï¼šæ ¹æ“š learning_path é‡æ–°åˆ†é…é¡å‹
    fixed_actions = []
    used_types = set()
    
    for i in range(min(3, len(learning_path))):
        step = learning_path[i]
        step_info = step.get('step_info', '')
        estimated_time = step.get('estimated_time', 15)
        
        # å„ªå…ˆä½¿ç”¨ç¼ºå¤±çš„é¡å‹
        inferred_type = infer_type(step_info)
        
        # å¦‚æœé€™å€‹é¡å‹å·²ç¶“ç”¨éï¼Œä¸”é‚„æœ‰ç¼ºå¤±çš„é¡å‹ï¼Œå„ªå…ˆä½¿ç”¨ç¼ºå¤±çš„
        if inferred_type in used_types and missing_types:
            inferred_type = missing_types[0]
            missing_types.remove(inferred_type)
        
        used_types.add(inferred_type)
        
        # ä½¿ç”¨åŸå§‹ detail æˆ– step_info
        original_action = top_actions[i] if i < len(top_actions) else {}
        detail = original_action.get('detail', step_info)
        
        fixed_actions.append({
            'action': inferred_type,
            'detail': detail,
            'est_min': estimated_time
        })
    
    return fixed_actions

def analyze_prerequisites(prerequisites: List[Dict], quiz_records: List[Dict]) -> List[Dict]:
    """åˆ†æå‰ç½®çŸ¥è­˜é»æŒæ¡æƒ…æ³"""
    analysis = []
    
    for prereq in prerequisites:
        prereq_id = prereq.get('id', '')
        prereq_records = [r for r in quiz_records if r['micro_concept_id'] == prereq_id]
        
        if prereq_records:
            mastery = sum(1 for r in prereq_records if r['is_correct']) / len(prereq_records)
            status = 'å·²æŒæ¡' if mastery >= 0.8 else 'éƒ¨åˆ†æŒæ¡' if mastery >= 0.5 else 'æœªæŒæ¡'
        else:
            mastery = 0
            status = 'æœªå­¸ç¿’'
        
        analysis.append({
            'concept_id': prereq_id,
            'concept_name': prereq.get('name', 'æœªçŸ¥æ¦‚å¿µ'),
            'mastery': round(mastery, 2),
            'status': status,
            'is_ready': mastery >= 0.6
        })
    
    return analysis

# å·²ç§»é™¤ /learning-path-prediction API - å‰ç«¯æœªä½¿ç”¨

# æ–°å¢çš„çµ±è¨ˆè¨ˆç®—å‡½æ•¸
def calculate_consecutive_days(quiz_records: List[Dict]) -> int:
    """è¨ˆç®—é€£çºŒå­¸ç¿’å¤©æ•¸"""
    if not quiz_records:
        return 0
    
    # æŒ‰æ—¥æœŸåˆ†çµ„
    daily_records = {}
    for record in quiz_records:
        date = record['attempt_time'][:10]  # æå–æ—¥æœŸéƒ¨åˆ†
        if date not in daily_records:
            daily_records[date] = []
        daily_records[date].append(record)
    
    # æŒ‰æ—¥æœŸæ’åº
    sorted_dates = sorted(daily_records.keys(), reverse=True)
    
    consecutive_days = 0
    from datetime import timezone
    current_date = datetime.now(timezone.utc).date()
    
    for date_str in sorted_dates:
        date_obj = datetime.strptime(date_str, '%Y-%m-%d').date()
        if date_obj == current_date or date_obj == current_date - timedelta(days=consecutive_days):
            consecutive_days += 1
            current_date = date_obj - timedelta(days=1)
        else:
            break
    
    return consecutive_days

def calculate_total_study_time(quiz_records: List[Dict]) -> float:
    """è¨ˆç®—ç¸½å­¸ç¿’æ™‚é–“ï¼ˆå°æ™‚ï¼‰"""
    if not quiz_records:
        return 0.0
    
    # è¨ˆç®—æ‰€æœ‰ç­”é¡Œçš„æ™‚é–“ï¼ˆåŒ…æ‹¬ç­”å°å’Œç­”éŒ¯ï¼‰
    total_seconds = sum(record.get('time_spent', 0) for record in quiz_records)
    total_hours = total_seconds / 3600  # è½‰æ›ç‚ºå°æ™‚
    return round(total_hours, 1)

def calculate_avg_daily_time(quiz_records: List[Dict]) -> int:
    """è¨ˆç®—å¹³å‡æ¯æ—¥å­¸ç¿’æ™‚é–“ï¼ˆåˆ†é˜ï¼‰"""
    if not quiz_records:
        return 0
    
    # è¨ˆç®—å­¸ç¿’å¤©æ•¸
    daily_records = set()
    for record in quiz_records:
        date = record['attempt_time'][:10]
        daily_records.add(date)
    
    if not daily_records:
        return 0
    
    # ä½¿ç”¨å¯¦éš›è¨˜éŒ„çš„ç­”é¡Œæ™‚é–“
    total_seconds = sum(record.get('time_spent', 0) for record in quiz_records)
    total_minutes = total_seconds / 60  # è½‰æ›ç‚ºåˆ†é˜
    avg_daily = total_minutes / len(daily_records)
    return int(avg_daily)

def calculate_longest_session(quiz_records: List[Dict]) -> int:
    """è¨ˆç®—æœ€é•·å­¸ç¿’æ™‚æ®µï¼ˆåˆ†é˜ï¼‰"""
    if not quiz_records:
        return 0
    
    # æŒ‰æ™‚é–“æ’åº
    sorted_records = sorted(quiz_records, key=lambda x: x['attempt_time'])
    
    max_session = 0
    current_session = 0
    last_time = None
    
    for record in sorted_records:
        current_time = datetime.fromisoformat(record['attempt_time'].replace('Z', '+00:00'))
        answer_time = record.get('time_spent', 0)  # å¯¦éš›ç­”é¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        
        if last_time is None:
            current_session = answer_time / 60  # è½‰æ›ç‚ºåˆ†é˜
        else:
            time_diff = (current_time - last_time).total_seconds() / 60  # è½‰æ›ç‚ºåˆ†é˜
            
            if time_diff <= 30:  # 30åˆ†é˜å…§ç®—ä½œåŒä¸€å€‹å­¸ç¿’æ™‚æ®µ
                current_session += answer_time / 60  # ç´¯åŠ å¯¦éš›ç­”é¡Œæ™‚é–“
            else:
                max_session = max(max_session, current_session)
                current_session = answer_time / 60  # é‡æ–°é–‹å§‹è¨ˆç®—
        
        last_time = current_time
    
    max_session = max(max_session, current_session)
    return int(max_session)

def calculate_study_intensity(quiz_records: List[Dict]) -> int:
    """è¨ˆç®—å­¸ç¿’å¼·åº¦ï¼ˆç™¾åˆ†æ¯”ï¼‰"""
    if not quiz_records:
        return 0
    
    # è¨ˆç®—æœ€è¿‘7å¤©çš„å­¸ç¿’å¼·åº¦
    from datetime import timezone
    week_ago = datetime.now(timezone.utc) - timedelta(days=7)
    recent_records = [r for r in quiz_records 
                     if datetime.fromisoformat(r['attempt_time'].replace('Z', '+00:00')) >= week_ago]
    
    if not recent_records:
        return 0
    
    # è¨ˆç®—æ¯æ—¥å­¸ç¿’æ¬¡æ•¸
    daily_counts = {}
    for record in recent_records:
        date = record['attempt_time'][:10]
        daily_counts[date] = daily_counts.get(date, 0) + 1
    
    if not daily_counts:
        return 0
    
    # è¨ˆç®—å­¸ç¿’å¼·åº¦ï¼šå¹³å‡æ¯æ—¥å­¸ç¿’æ¬¡æ•¸ / 10 * 100
    avg_daily = sum(daily_counts.values()) / len(daily_counts)
    intensity = min(100, int((avg_daily / 10) * 100))
    
    return intensity

def generate_improvement_items(domains: List[Dict], quiz_records: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆæœ€è¿‘é€²æ­¥çš„çŸ¥è­˜é»æ•¸æ“š"""
    improvement_items = []
    
    # æŒ‰é ˜åŸŸåˆ†çµ„åˆ†æ
    domain_records = {}
    for record in quiz_records:
        domain_name = record.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
        if domain_name not in domain_records:
            domain_records[domain_name] = []
        domain_records[domain_name].append(record)
    
    # ç‚ºæ¯å€‹é ˜åŸŸåˆ†æé€²æ­¥æƒ…æ³
    for domain_name, records in domain_records.items():
        # è·³éã€ŒæœªçŸ¥é ˜åŸŸã€
        if domain_name == 'æœªçŸ¥é ˜åŸŸ' or domain_name == 'æœªçŸ¥' or not domain_name or domain_name.strip() == '':
            continue
        if len(records) < 3:
            continue
            
        # æŒ‰æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        records.sort(key=lambda x: x['attempt_time'], reverse=True)
        
        # è¨ˆç®—æœ€è¿‘å’Œä¹‹å‰çš„æ­£ç¢ºç‡
        mid_point = len(records) // 2
        recent_records = records[:mid_point]  # æœ€è¿‘çš„ä¸€åŠ
        older_records = records[mid_point:]   # è¼ƒæ—©çš„ä¸€åŠ
        
        if len(older_records) == 0:
            continue
            
        recent_accuracy = sum(1 for r in recent_records if r['is_correct']) / len(recent_records)
        older_accuracy = sum(1 for r in older_records if r['is_correct']) / len(older_records)
        
        improvement = (recent_accuracy - older_accuracy) * 100
        
        
        # é™ä½é€²æ­¥è¦æ±‚ï¼Œåªè¦æœ‰é€²æ­¥å°±é¡¯ç¤º
        if improvement > 0:  # åªè¦æœ‰é€²æ­¥å°±é¡¯ç¤º
            # è¨ˆç®—è©²é ˜åŸŸçš„æŒæ¡åº¦
            domain_mastery = recent_accuracy  # ä½¿ç”¨æœ€è¿‘æº–ç¢ºç‡ä½œç‚ºæŒæ¡åº¦
            
            improvement_items.append({
                'name': domain_name,
                'improvement': round(improvement, 1),
                'priority': 'high' if improvement > 30 else 'medium' if improvement > 10 else 'low',
                'current_accuracy': round(recent_accuracy * 100, 1),
                'previous_accuracy': round(older_accuracy * 100, 1),
                'mastery': round(domain_mastery, 3),  # æ·»åŠ æŒæ¡åº¦å­—æ®µ
                'questions': len(records)  # æ·»åŠ é¡Œç›®æ•¸é‡å­—æ®µ
            })
    
    # æŒ‰é€²æ­¥å¹…åº¦æ’åº
    improvement_items.sort(key=lambda x: x['improvement'], reverse=True)
    return improvement_items[:5]  # è¿”å›å‰5å€‹

def get_concept_name_by_id(concept_id: str) -> str:
    """æ ¹æ“šæ¦‚å¿µIDç²å–æ¦‚å¿µåç¨± - æ”¹é€²ç‰ˆæœ¬ï¼Œæ”¯æ´å¤šç¨®æŸ¥æ‰¾æ–¹å¼"""
    try:
        from accessories import mongo
        
        if not mongo:
            logger.warning("MongoDBæœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜èªæ¦‚å¿µåç¨±")
            return f"æ¦‚å¿µ_{concept_id[-6:]}"
        
        # æ–¹æ³•1ï¼šå˜—è©¦ä½¿ç”¨ ObjectId æŸ¥è©¢ï¼ˆæ¨™æº–æ–¹å¼ï¼‰
        try:
            if len(concept_id) == 24:  # MongoDB ObjectId é•·åº¦
                concept_doc = mongo.db.micro_concept.find_one({'_id': ObjectId(concept_id)})
                if concept_doc:
                    concept_name = concept_doc.get('name', '')
                    if concept_name:
                        logger.debug(f"âœ… æ‰¾åˆ°æ¦‚å¿µåç¨±ï¼ˆObjectIdï¼‰: {concept_id} -> {concept_name}")
                        return concept_name
        except Exception as e:
            logger.debug(f"ObjectId æŸ¥è©¢å¤±æ•—: {e}")
        
        # æ–¹æ³•2ï¼šå˜—è©¦ä½¿ç”¨æ¦‚å¿µIDä½œç‚ºåç¨±ç›´æ¥æŸ¥è©¢ï¼ˆæŸäº›æƒ…æ³ä¸‹ micro_concept_id å°±æ˜¯åç¨±ï¼‰
        try:
            concept_doc = mongo.db.micro_concept.find_one({'name': concept_id})
            if concept_doc:
                concept_name = concept_doc.get('name', '')
                if concept_name:
                    logger.debug(f"âœ… æ‰¾åˆ°æ¦‚å¿µåç¨±ï¼ˆåç¨±æŸ¥è©¢ï¼‰: {concept_id} -> {concept_name}")
                    return concept_name
        except Exception as e:
            logger.debug(f"åç¨±æŸ¥è©¢å¤±æ•—: {e}")
        
        # æ–¹æ³•3ï¼šå˜—è©¦ä½¿ç”¨ _id å­—ä¸²åŒ¹é…ï¼ˆæŸäº›æƒ…æ³ä¸‹å¯èƒ½æ˜¯å­—ä¸²æ ¼å¼çš„IDï¼‰
        try:
            concept_doc = mongo.db.micro_concept.find_one({'_id': concept_id})
            if concept_doc:
                concept_name = concept_doc.get('name', '')
                if concept_name:
                    logger.debug(f"âœ… æ‰¾åˆ°æ¦‚å¿µåç¨±ï¼ˆå­—ä¸²IDï¼‰: {concept_id} -> {concept_name}")
                    return concept_name
        except Exception as e:
            logger.debug(f"å­—ä¸²IDæŸ¥è©¢å¤±æ•—: {e}")
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›è­¦å‘Šå’Œé»˜èªåç¨±
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ¦‚å¿µID {concept_id}ï¼Œè¿”å›é»˜èªåç¨±ã€‚é€™å¯èƒ½å°è‡´ Neo4j æŸ¥è©¢å¤±æ•—ã€‚")
        default_name = f"æ¦‚å¿µ_{concept_id[-6:]}"
        logger.warning(f"   é»˜èªåç¨±: {default_name}ï¼ˆæ­¤åç¨±åœ¨ Neo4j ä¸­å¯èƒ½ä¸å­˜åœ¨ï¼‰")
        return default_name
            
    except Exception as e:
        logger.error(f"âŒ ç²å–æ¦‚å¿µåç¨±å¤±æ•—: {e}", exc_info=True)
        return f"æ¦‚å¿µ_{concept_id[-6:]}"

def get_knowledge_relations_from_neo4j(concept_name: str) -> Dict[str, Any]:
    """å¾Neo4jç²å–çŸ¥è­˜é»é—œè¯æ•¸æ“š - æ”¹é€²ç‰ˆæœ¬ï¼Œä½¿ç”¨ elementId ä¸¦å¢å¼·é—œè¯è³‡è¨Š"""
    try:
        from accessories import neo4j_driver
        
        if not neo4j_driver:
            logger.warning("Neo4jé©…å‹•æœªåˆå§‹åŒ–ï¼Œè¿”å›ç©ºé—œè¯æ•¸æ“š")
            return {
                'prerequisites': [],
                'related_concepts': [],
                'leads_to': [],
                'all_relations': [],
                'relation_graph': {}
            }
        
        with neo4j_driver.session() as session:
            # æ”¹é€²æŸ¥è©¢ï¼šä½¿ç”¨ elementId æ›¿ä»£å·²æ£„ç”¨çš„ id()ï¼Œä¸æŸ¥è©¢ä¸å­˜åœ¨çš„ strength å±¬æ€§
            # æ³¨æ„ï¼šNeo4j é—œè¯é—œä¿‚å¯èƒ½æ²’æœ‰ strength å±¬æ€§ï¼Œæˆ‘å€‘åœ¨ç¨‹å¼ç¢¼ä¸­æ ¹æ“šé¡å‹è¨­å®šé»˜èªå€¼
            query = """
            MATCH (c:Section {name: $concept_name})-[r:PREREQUISITE|SIMILAR_TO|CROSS_DOMAIN_LINK|LEADS_TO]-(related:Section)
            RETURN 
                related.name as related_name,
                type(r) as relation_type,
                elementId(related) as related_id,
                elementId(c) as current_id,
                c.name as current_name
            ORDER BY 
                CASE type(r)
                    WHEN 'PREREQUISITE' THEN 1
                    WHEN 'SIMILAR_TO' THEN 2
                    WHEN 'CROSS_DOMAIN_LINK' THEN 3
                    WHEN 'LEADS_TO' THEN 4
                END
            LIMIT 20
            """
            
            result = session.run(query, concept_name=concept_name)
            relations = []
            relation_graph = {
                'current_concept': concept_name,
                'current_id': None,
                'nodes': [],
                'edges': []
            }
            
            logger.info(f"ğŸ” [Neo4j] æŸ¥è©¢çŸ¥è­˜é»é—œè¯: {concept_name}")
            
            for record in result:
                # æ ¹æ“šé—œè¯é¡å‹è¨­å®šé»˜èªå¼·åº¦ï¼ˆå› ç‚º Neo4j é—œè¯é—œä¿‚ä¸­æ²’æœ‰ strength å±¬æ€§ï¼‰
                rel_type = record['relation_type']
                if rel_type == 'PREREQUISITE':
                    relation_strength = 0.9  # å‰ç½®çŸ¥è­˜é»å¼·åº¦è¼ƒé«˜
                elif rel_type == 'SIMILAR_TO':
                    relation_strength = 0.7
                elif rel_type == 'CROSS_DOMAIN_LINK':
                    relation_strength = 0.6
                elif rel_type == 'LEADS_TO':
                    relation_strength = 0.8
                else:
                    relation_strength = 0.5
                
                relation = {
                    'id': str(record['related_id']),
                    'name': record['related_name'],
                    'type': record['relation_type'],
                    'strength': float(relation_strength),
                    'type_display': get_relation_type_display(record['relation_type'])
                }
                relations.append(relation)
                
                # æ§‹å»ºé—œè¯åœ–æ•¸æ“š
                if not relation_graph['current_id']:
                    relation_graph['current_id'] = str(record.get('current_id', ''))
                
                relation_graph['nodes'].append({
                    'id': str(record['related_id']),
                    'name': record['related_name'],
                    'type': record['relation_type']
                })
                
                relation_graph['edges'].append({
                    'source': str(record.get('current_id', '')),
                    'target': str(record['related_id']),
                    'type': record['relation_type'],
                    'strength': float(relation_strength),
                    'label': get_relation_type_display(record['relation_type'])
                })
                
                logger.debug(f"  âœ… æ‰¾åˆ°é—œè¯: {relation['name']} ({relation['type_display']}, å¼·åº¦: {relation['strength']:.2f})")
            
            # åˆ†é¡é—œè¯é—œä¿‚
            prerequisites = [r for r in relations if r['type'] == 'PREREQUISITE']
            related = [r for r in relations if r['type'] in ['SIMILAR_TO', 'CROSS_DOMAIN_LINK']]
            leads_to = [r for r in relations if r['type'] == 'LEADS_TO']
            
            # å»é‡è™•ç†ï¼šå¦‚æœåŒä¸€å€‹çŸ¥è­˜é»æœ‰å¤šç¨®é¡å‹çš„é—œè¯ï¼Œåˆä½µé—œè¯é¡å‹ä¸¦ä¿ç•™æœ€é«˜å¼·åº¦
            def deduplicate_relations(relation_list):
                """å»é‡é—œè¯é—œä¿‚ï¼Œåˆä½µå¤šç¨®é¡å‹ä¸¦ä¿ç•™æœ€é«˜å¼·åº¦"""
                seen = {}
                for rel in relation_list:
                    key = rel['id']  # ä½¿ç”¨çŸ¥è­˜é»IDä½œç‚ºå”¯ä¸€æ¨™è­˜
                    if key not in seen:
                        # é¦–æ¬¡å‡ºç¾ï¼Œåˆå§‹åŒ–
                        seen[key] = rel.copy()
                        seen[key]['types'] = [rel['type']]
                    else:
                        # å·²å­˜åœ¨ï¼Œåˆä½µé—œè¯é¡å‹
                        if rel['type'] not in seen[key]['types']:
                            seen[key]['types'].append(rel['type'])
                        
                        # æ›´æ–°ç‚ºæœ€é«˜å¼·åº¦
                        if rel['strength'] > seen[key]['strength']:
                            seen[key]['strength'] = rel['strength']
                        
                        # æ›´æ–°é¡¯ç¤ºé¡å‹ï¼ˆåˆä½µæ‰€æœ‰é¡å‹ï¼‰
                        seen[key]['type'] = seen[key]['types'][0]  # ä¿ç•™ç¬¬ä¸€å€‹é¡å‹ä½œç‚ºä¸»è¦é¡å‹
                        seen[key]['type_display'] = 'ã€'.join([get_relation_type_display(t) for t in seen[key]['types']])
                
                return list(seen.values())
            
            # å°å„é¡é—œè¯é€²è¡Œå»é‡
            prerequisites = deduplicate_relations(prerequisites)
            related = deduplicate_relations(related)
            leads_to = deduplicate_relations(leads_to)
            
            logger.info(f"ğŸ“Š [Neo4j] é—œè¯çµ±è¨ˆï¼ˆå»é‡å¾Œï¼‰: å‰ç½®={len(prerequisites)}, ç›¸é—œ={len(related)}, å¾ŒçºŒ={len(leads_to)}, ç¸½è¨ˆ={len(prerequisites) + len(related) + len(leads_to)}")
            
            return {
                'prerequisites': prerequisites,
                'related_concepts': related,
                'leads_to': leads_to,
                'all_relations': relations,
                'relation_graph': relation_graph,
                'has_relations': len(relations) > 0
            }
            
    except Exception as e:
        logger.error(f"âŒ Neo4jæŸ¥è©¢å¤±æ•—: {e}", exc_info=True)
        return {
            'prerequisites': [],
            'related_concepts': [],
            'leads_to': [],
            'all_relations': [],
            'relation_graph': {},
            'has_relations': False
        }

def get_relation_type_display(relation_type: str) -> str:
    """ç²å–é—œè¯é¡å‹çš„ä¸­æ–‡é¡¯ç¤ºåç¨±"""
    type_mapping = {
        'PREREQUISITE': 'å‰ç½®çŸ¥è­˜é»',
        'SIMILAR_TO': 'ç›¸ä¼¼æ¦‚å¿µ',
        'CROSS_DOMAIN_LINK': 'è·¨é ˜åŸŸé—œè¯',
        'LEADS_TO': 'å¾ŒçºŒçŸ¥è­˜é»'
    }
    return type_mapping.get(relation_type, relation_type)

def generate_ai_diagnosis(concept_name: str, domain_name: str, mastery: float, 
                         total_attempts: int, correct_attempts: int, recent_accuracy: float,
                         wrong_records: List[Dict], knowledge_relations: Dict[str, Any] = None,
                         difficulty_stats: Dict[str, Dict] = None, learning_path: List[Dict] = None) -> Dict[str, Any]:
    """ä½¿ç”¨Gemini APIç”ŸæˆAIè¨ºæ–·çµæœ"""
    
    try:
        # åˆå§‹åŒ–Geminiæ¨¡å‹
        model = init_gemini('gemini-2.5-flash')
        
        # æº–å‚™è¨ºæ–·æ•¸æ“š
        wrong_count = total_attempts - correct_attempts
        error_analysis = ""
        if wrong_records:
            error_types = []
            for record in wrong_records[:5]:  # åˆ†ææœ€è¿‘5æ¬¡éŒ¯èª¤
                if record.get('error_reason'):
                    error_types.append(record['error_reason'])
            if error_types:
                error_analysis = f"å¸¸è¦‹éŒ¯èª¤é¡å‹ï¼š{', '.join(set(error_types))}"
        
        # æº–å‚™çŸ¥è­˜é»é—œè¯æ•¸æ“š - å¢å¼·ç‰ˆæœ¬ï¼ŒåŒ…å«é—œè¯å¼·åº¦å’Œé¡å‹
        relations_info = ""
        relations_detail = {}
        if knowledge_relations and knowledge_relations.get('has_relations', False):
            prereqs = knowledge_relations.get('prerequisites', [])
            related = knowledge_relations.get('related_concepts', [])
            leads_to = knowledge_relations.get('leads_to', [])
            all_relations = knowledge_relations.get('all_relations', [])
            
            # æ§‹å»ºè©³ç´°çš„é—œè¯è³‡è¨Š
            if prereqs:
                prereq_details = [f"{r['name']}(å¼·åº¦:{r['strength']:.2f})" for r in prereqs[:5]]
                relations_info += f"\n- **å‰ç½®çŸ¥è­˜é»**ï¼ˆå¿…é ˆå…ˆæŒæ¡ï¼‰ï¼š{', '.join(prereq_details)}"
                relations_detail['prerequisites'] = [
                    {'name': r['name'], 'strength': r['strength'], 'type': r['type_display']} 
                    for r in prereqs[:5]
                ]
            
            if related:
                related_details = [f"{r['name']}(å¼·åº¦:{r['strength']:.2f})" for r in related[:5]]
                relations_info += f"\n- **ç›¸é—œçŸ¥è­˜é»**ï¼ˆå¯åŒæ™‚å­¸ç¿’ï¼‰ï¼š{', '.join(related_details)}"
                relations_detail['related'] = [
                    {'name': r['name'], 'strength': r['strength'], 'type': r['type_display']} 
                    for r in related[:5]
                ]
            
            if leads_to:
                leads_details = [f"{r['name']}(å¼·åº¦:{r['strength']:.2f})" for r in leads_to[:5]]
                relations_info += f"\n- **å¾ŒçºŒçŸ¥è­˜é»**ï¼ˆæŒæ¡å¾Œå¯å­¸ç¿’ï¼‰ï¼š{', '.join(leads_details)}"
                relations_detail['leads_to'] = [
                    {'name': r['name'], 'strength': r['strength'], 'type': r['type_display']} 
                    for r in leads_to[:5]
                ]
            
            # æ·»åŠ é—œè¯åœ–æ•¸æ“š
            relations_detail['relation_graph'] = knowledge_relations.get('relation_graph', {})
            relations_detail['total_relations'] = len(all_relations)
        else:
            relations_info = "\n- âš ï¸ **ç„¡Neo4jé—œè¯æ•¸æ“š**ï¼šæ­¤çŸ¥è­˜é»åœ¨çŸ¥è­˜åœ–è­œä¸­æ²’æœ‰é—œè¯é—œä¿‚ï¼Œè«‹åŸºæ–¼ä¸€èˆ¬æ•™å­¸åŸå‰‡é€²è¡Œè¨ºæ–·ã€‚"
            relations_detail = {'has_relations': False}
        
        # æº–å‚™é›£æ˜“åº¦åˆ†ææ•¸æ“š
        difficulty_info = ""
        if difficulty_stats:
            difficulty_info = "\n- é¡Œç›®é›£æ˜“åº¦åˆ†å¸ƒï¼š"
            for difficulty, stats in difficulty_stats.items():
                accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
                difficulty_info += f"\n  * {difficulty}ï¼š{stats['correct']}/{stats['total']} æ­£ç¢º ({accuracy:.1%})"
        
        # æº–å‚™å­¸ç¿’è·¯å¾‘æ•¸æ“š
        learning_path_info = ""
        if learning_path:
            learning_path_info = "\n- æ¨è–¦å­¸ç¿’è·¯å¾‘ï¼š"
            for i, step in enumerate(learning_path[:5]):  # åªé¡¯ç¤ºå‰5å€‹æ­¥é©Ÿ
                step_info = step.get('step_info', step.get('concept_name', 'æœªçŸ¥æ­¥é©Ÿ'))
                estimated_time = step.get('estimated_time', 15)
                learning_path_info += f"\n  {i+1}. {step_info} (é ä¼°æ™‚é–“: {estimated_time}åˆ†é˜)"

        # æ§‹å»ºGeminiæç¤ºè© - ä½¿ç”¨æ–°çš„JSON schema
        import json
        
        prompt = f"""
ä½ æ˜¯æ•™å­¸è¨ºæ–·AIã€‚åªè¼¸å‡ºJSONï¼Œéµå®ˆschema: summary(<=20ä¸­æ–‡å­—), metrics, root_causes[], top_actions[<=3], practice_examples[<=3], evidence[], confidence, knowledge_relations. å¦‚æœè³‡æ–™ä¸è¶³è¨­å®šconfidence=lowä¸¦å›å‚³baseline planã€‚ä¸è¦å¤šèªªè©±ã€‚

**âš ï¸ é‡è¦ï¼šä½ å¿…é ˆåŸºæ–¼Neo4jçŸ¥è­˜åœ–è­œçš„é—œè¯é—œä¿‚é€²è¡Œè¨ºæ–·ï¼**

å­¸ç”Ÿè³‡æ–™:
{{
    "concept": "{concept_name}",
    "domain": "{domain_name}",
    "metrics": {{
        "mastery": {mastery:.2f},
        "attempts": {total_attempts},
        "recent_accuracy": {recent_accuracy:.2f},
        "avg_time": 22
    }},
    "recent_wrong_questions": {json.dumps([{"q_id": f"q{i}", "err": r.get('error_reason', 'æœªçŸ¥éŒ¯èª¤'), "text": "é¡Œç›®å…§å®¹"} for i, r in enumerate(wrong_records[:3])])},
    "difficulty_stats": {json.dumps(difficulty_stats)},
    "learning_path": {json.dumps(learning_path[:5]) if learning_path else '[]'},
    "learning_path_info": "{learning_path_info if learning_path_info else 'ç„¡å­¸ç¿’è·¯å¾‘æ•¸æ“š'}"
}}

**Neo4jçŸ¥è­˜åœ–è­œé—œè¯æ•¸æ“šï¼ˆå¿…é ˆåƒè€ƒï¼‰ï¼š**
{relations_info}

**é—œè¯æ•¸æ“šè©³ç´°è³‡è¨Šï¼š**
{json.dumps(relations_detail, ensure_ascii=False, indent=2)}

**è¨ºæ–·è¦æ±‚ï¼ˆå¿…é ˆéµå®ˆï¼‰ï¼š**
1. **å¿…é ˆåˆ†æNeo4jé—œè¯é—œä¿‚**ï¼š
   - å¦‚æœæœ‰å‰ç½®çŸ¥è­˜é»ï¼Œå¿…é ˆåœ¨root_causesä¸­åˆ†ææ˜¯å¦å› ç‚ºå‰ç½®çŸ¥è­˜ä¸è¶³å°è‡´ç•¶å‰æ¦‚å¿µç†è§£å›°é›£
   - å¦‚æœæœ‰ç›¸é—œçŸ¥è­˜é»ï¼Œå¿…é ˆåœ¨top_actionsä¸­å»ºè­°åŒæ™‚è¤‡ç¿’ç›¸é—œæ¦‚å¿µ
   - å¦‚æœæœ‰å¾ŒçºŒçŸ¥è­˜é»ï¼Œå¿…é ˆåœ¨evidenceä¸­èªªæ˜æŒæ¡ç•¶å‰æ¦‚å¿µå°å¾ŒçºŒå­¸ç¿’çš„é‡è¦æ€§

2. **å­¸ç¿’è·¯å¾‘è¨­è¨ˆå¿…é ˆåŸºæ–¼é—œè¯é—œä¿‚**ï¼š
   - å¦‚æœæœ‰å‰ç½®çŸ¥è­˜é»ä¸”æŒæ¡åº¦ä½ï¼Œå¿…é ˆå…ˆå»ºè­°å­¸ç¿’å‰ç½®çŸ¥è­˜é»
   - å¦‚æœæœ‰ç›¸é—œçŸ¥è­˜é»ï¼Œå¯ä»¥å»ºè­°åŒæ™‚å­¸ç¿’ä»¥åŠ æ·±ç†è§£
   - å­¸ç¿’é †åºå¿…é ˆç¬¦åˆçŸ¥è­˜åœ–è­œçš„é‚è¼¯é—œä¿‚

3. **å¦‚æœæ²’æœ‰Neo4jé—œè¯æ•¸æ“š**ï¼š
   - åœ¨confidenceä¸­æ¨™è¨˜ç‚º"low"
   - åœ¨evidenceä¸­èªªæ˜"ç¼ºå°‘çŸ¥è­˜åœ–è­œé—œè¯æ•¸æ“šï¼Œè¨ºæ–·åŸºæ–¼ä¸€èˆ¬æ•™å­¸åŸå‰‡"
   - ä»ç„¶æä¾›åŸºç¤çš„å­¸ç¿’å»ºè­°

è«‹è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSONï¼Œtop_actionsçš„actionå­—æ®µå¿…é ˆä½¿ç”¨ä»¥ä¸‹æ¨™æº–åŒ–é¡å‹ä¹‹ä¸€ï¼š
- "REVIEW_BASICS" (AIåŸºç¤æ•™å­¸) - ç”¨æ–¼éœ€è¦AIå°å¸«æ•™å­¸ã€æ·±å…¥ç†è§£çš„æ­¥é©Ÿ
- "PRACTICE" (AIå‡ºé¡Œç·´ç¿’) - ç”¨æ–¼éœ€è¦ç·´ç¿’é¡Œç›®ã€å¯¦éš›æ‡‰ç”¨çš„æ­¥é©Ÿ
- "SEEK_HELP" (æ•™æè§€çœ‹) - ç”¨æ–¼éœ€è¦è§€çœ‹èª²ç¨‹ã€é–±è®€æ•™æçš„æ­¥é©Ÿ
- "ADD_TO_CALENDAR" (åŠ å…¥è¡Œäº‹æ›†) - ç”¨æ–¼éœ€è¦å®‰æ’æ™‚é–“çš„æ­¥é©Ÿ

**âš ï¸ é‡è¦ï¼štop_actions å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼**

1. **å¿…é ˆåŒ…å«ä¸‰ç¨®ä¸åŒé¡å‹**ï¼š
   - top_actions å¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹ "SEEK_HELP" (æ•™æè§€çœ‹)
   - top_actions å¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹ "REVIEW_BASICS" (AIåŸºç¤æ•™å­¸)
   - top_actions å¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹ "PRACTICE" (AIå‡ºé¡Œç·´ç¿’)
   - ç¸½å…±3å€‹ actionsï¼Œæ¯å€‹é¡å‹å„ä¸€å€‹ï¼Œä¸èƒ½é‡è¤‡

2. **å¿…é ˆæ ¹æ“š learning_path ç”Ÿæˆ**ï¼š
   - ä»”ç´°åˆ†æ learning_path ä¸­æ¯å€‹æ­¥é©Ÿçš„ step_info
   - ç‚ºå‰3å€‹æ­¥é©Ÿç”Ÿæˆå°æ‡‰çš„ top_actions
   - æ¯å€‹ top_actions[i] å°æ‡‰ learning_path[i]
   - action.detail = learning_path[i].step_infoï¼ˆç›´æ¥ä½¿ç”¨ï¼Œä¸è¦ä¿®æ”¹ï¼‰
   - action.est_min = learning_path[i].estimated_timeï¼ˆç›´æ¥ä½¿ç”¨ï¼Œä¸è¦ä¿®æ”¹ï¼‰

3. **é¡å‹åˆ¤æ–·è¦å‰‡ï¼ˆå¿…é ˆéµå®ˆï¼‰**ï¼š
   - å¦‚æœ step_info åŒ…å«ã€Œè§€çœ‹ã€ã€ã€Œé–±è®€ã€ã€ã€Œèª²ç¨‹ã€ç­‰é—œéµå­— â†’ ä½¿ç”¨ "SEEK_HELP" (æ•™æè§€çœ‹)
   - å¦‚æœ step_info åŒ…å«ã€Œæ·±å…¥ç†è§£ã€ã€ã€Œç†è§£ã€ã€ã€ŒæŒæ¡ã€ã€ã€Œå­¸ç¿’ã€ç­‰é—œéµå­— â†’ ä½¿ç”¨ "REVIEW_BASICS" (AIåŸºç¤æ•™å­¸)
   - å¦‚æœ step_info åŒ…å«ã€Œç·´ç¿’ã€ã€ã€Œç­”é¡Œã€ã€ã€Œæ‡‰ç”¨ã€ã€ã€Œå˜—è©¦ã€ã€ã€Œå›ç­”ã€ã€ã€Œå•é¡Œã€ç­‰é—œéµå­— â†’ ä½¿ç”¨ "PRACTICE" (AIå‡ºé¡Œç·´ç¿’)
   - å¦‚æœä¸€å€‹æ­¥é©ŸåŒ…å«å¤šå€‹é—œéµå­—ï¼Œå„ªå…ˆé †åºï¼šPRACTICE > REVIEW_BASICS > SEEK_HELP

4. **é¡å‹åˆ†é…ç­–ç•¥**ï¼š
   - å¦‚æœ learning_path æœ‰3å€‹æ­¥é©Ÿï¼Œå¿…é ˆç¢ºä¿ä¸‰å€‹æ­¥é©Ÿåˆ†åˆ¥å°æ‡‰ä¸‰ç¨®ä¸åŒé¡å‹
   - å¦‚æœå‰3å€‹æ­¥é©Ÿé¡å‹é‡è¤‡ï¼Œå¿…é ˆèª¿æ•´åˆ†é…ï¼Œç¢ºä¿ä¸‰ç¨®é¡å‹éƒ½æœ‰
   - å„ªå…ˆå°‡åŒ…å«ã€Œç·´ç¿’ã€ã€ã€Œå›ç­”ã€ç­‰é—œéµå­—çš„æ­¥é©Ÿåˆ†é…ç‚º PRACTICE
   - å„ªå…ˆå°‡åŒ…å«ã€Œè§€çœ‹ã€ã€ã€Œé–±è®€ã€ç­‰é—œéµå­—çš„æ­¥é©Ÿåˆ†é…ç‚º SEEK_HELP
   - å„ªå…ˆå°‡åŒ…å«ã€Œç†è§£ã€ã€ã€ŒæŒæ¡ã€ç­‰é—œéµå­—çš„æ­¥é©Ÿåˆ†é…ç‚º REVIEW_BASICS

{{
    "summary": "string (<=20ä¸­æ–‡å­—)",
    "metrics": {{
        "domain": "{domain_name}",
        "concept": "{concept_name}",
        "mastery": {mastery:.2f},
        "attempts": {total_attempts},
        "recent_accuracy": {recent_accuracy:.2f}
    }},
    "root_causes": ["string1", "string2", "string3"],
    "top_actions": [
        {{"action": "SEEK_HELP", "detail": "æ ¹æ“šlearning_path[0]çš„step_info", "est_min": learning_path[0].estimated_time}},
        {{"action": "REVIEW_BASICS", "detail": "æ ¹æ“šlearning_path[1]çš„step_info", "est_min": learning_path[1].estimated_time}},
        {{"action": "PRACTICE", "detail": "æ ¹æ“šlearning_path[2]çš„step_info", "est_min": learning_path[2].estimated_time}}
    ],
    "practice_examples": [
        {{"q_id": "q101", "difficulty": "easy", "text": "string"}},
        {{"q_id": "q102", "difficulty": "easy", "text": "string"}},
        {{"q_id": "q103", "difficulty": "medium", "text": "string"}}
    ],
    "evidence": ["string1", "string2"],
    "confidence": "high/medium/low",
    "learning_path": {json.dumps(learning_path[:5]) if learning_path else '[]'},
    "full_text": "string (200-300å­—ï¼Œçµ¦å­¸ç”Ÿçœ‹çš„è¦ªåˆ‡è¨ºæ–·å ±å‘Š)"
}}

**full_text æ ¼å¼è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š**
- **èªæ°£**ï¼šè¦ªåˆ‡ã€é¼“å‹µã€åƒè€å¸«åœ¨è·Ÿå­¸ç”Ÿèªªè©±ï¼Œä¸è¦ç”¨å­¸è¡“è«–æ–‡èªæ°£
- **é•·åº¦**ï¼š200-300å­—ï¼Œç°¡æ½”æ˜ç­ï¼Œä¸è¦å†—é•·
- **çµæ§‹**ï¼š
  1. é–‹é ­ï¼šç°¡çŸ­ç¸½çµå­¸ç¿’ç‹€æ³ï¼ˆ1-2å¥ï¼‰
  2. å•é¡Œï¼šç”¨ç°¡å–®çš„è©±èªªæ˜ä¸»è¦å•é¡Œï¼ˆ2-3é»ï¼Œæ¯é»1å¥ï¼‰
  3. å»ºè­°ï¼šå…·é«”çš„å­¸ç¿’å»ºè­°ï¼ˆ2-3é»ï¼Œæ¯é»1å¥ï¼‰
  4. çµå°¾ï¼šé¼“å‹µçš„è©±ï¼ˆ1å¥ï¼‰
- **é¿å…**ï¼š
  - âŒ ä¸è¦ç”¨ã€Œç²¾ç†Ÿåº¦ã€ã€ã€Œé—œè¯å¼·åº¦ç‚º0.6ã€ç­‰æŠ€è¡“è¡“èª
  - âŒ ä¸è¦ç”¨ã€Œç‚ºæœ‰æ•ˆæå‡å­¸ç¿’æˆæ•ˆã€ç­‰å­¸è¡“åŒ–è¡¨é”
  - âŒ ä¸è¦éåº¦è§£é‡‹çŸ¥è­˜åœ–è­œçš„æŠ€è¡“ç´°ç¯€
  - âŒ ä¸è¦ç”¨ã€ŒæŒçºŒçš„å­¸ç¿’èˆ‡åæ€ï¼Œå°‡æ˜¯çªç ´ç•¶å‰å­¸ç¿’å›°å¢ƒçš„é—œéµã€ç­‰ç©ºæ³›çš„è©±
- **æ‡‰è©²**ï¼š
  - âœ… ç”¨ã€ŒæŒæ¡åº¦14%ã€ã€ã€Œç­”é¡Œæ­£ç¢ºç‡20%ã€ç­‰ç°¡å–®æ•¸å­—
  - âœ… ç”¨ã€Œå»ºè­°ä½ å…ˆ...ã€ã€ã€Œä½ å¯ä»¥è©¦è©¦...ã€ç­‰è¦ªåˆ‡èªæ°£
  - âœ… ç”¨ã€Œé€™å€‹æ¦‚å¿µå’ŒXXæœ‰é—œï¼Œä¸€èµ·å­¸ç¿’æœƒæ›´å®¹æ˜“ç†è§£ã€ç­‰ç°¡å–®èªªæ˜
  - âœ… ç”¨ã€ŒåŠ æ²¹ï¼å¤šç·´ç¿’å¹¾æ¬¡å°±æœƒé€²æ­¥ã€ç­‰é¼“å‹µçš„è©±

**ç¯„ä¾‹ï¼ˆå¥½çš„ full_textï¼‰ï¼š**
ã€Œä½ åœ¨ã€ŒAI å·¥ç¨‹å´›èµ·ã€é€™å€‹æ¦‚å¿µä¸Šé‚„éœ€è¦å¤šåŠ å¼·ã€‚ç›®å‰æŒæ¡åº¦åªæœ‰14%ï¼Œç­”é¡Œæ­£ç¢ºç‡20%ï¼Œé¡¯ç¤ºå°åŸºæœ¬æ¦‚å¿µé‚„ä¸å¤ ç†Ÿæ‚‰ã€‚

ä¸»è¦å•é¡Œæ˜¯åŸºç¤æ¦‚å¿µç†è§£ä¸è¶³ï¼Œç‰¹åˆ¥æ˜¯ä¸­ç­‰é›£åº¦çš„é¡Œç›®ç­”éŒ¯è¼ƒå¤šã€‚å»ºè­°ä½ å…ˆé€éAIå°å¸«é‡æ–°å­¸ç¿’åŸºæœ¬å®šç¾©ï¼Œç„¶å¾Œå¤šåšä¸€äº›ç·´ç¿’é¡Œä¾†éå›ºã€‚

é€™å€‹æ¦‚å¿µå’Œã€ŒçŸ¥è­˜ç®¡ç†èˆ‡ AIã€æœ‰é—œè¯ï¼Œå¯ä»¥ä¸€èµ·å­¸ç¿’æœƒæ›´å®¹æ˜“ç†è§£ã€‚è¨˜ä½ï¼Œå­¸ç¿’éœ€è¦æ™‚é–“ï¼Œå¤šç·´ç¿’å¹¾æ¬¡å°±æœƒé€²æ­¥ï¼ŒåŠ æ²¹ï¼ã€

é‡è¦ï¼šactionå­—æ®µå¿…é ˆåš´æ ¼ä½¿ç”¨ä¸Šè¿°4å€‹æ¨™æº–åŒ–é¡å‹ä¹‹ä¸€ï¼Œä¸è¦ä½¿ç”¨å…¶ä»–æ–‡å­—ã€‚
"""

        # èª¿ç”¨Gemini API
        response = model.generate_content(prompt)
        ai_response = response.text.strip()
        
        # è§£æJSONéŸ¿æ‡‰
        try:
            # æ¸…ç†éŸ¿æ‡‰æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            if ai_response.startswith('```json'):
                ai_response = ai_response[7:]
            if ai_response.endswith('```'):
                ai_response = ai_response[:-3]
            
            # è™•ç†æ§åˆ¶å­—ç¬¦ï¼ˆæ›è¡Œç¬¦ç­‰ï¼‰- ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•
            import re
            import sys
            
            # æ–¹æ³•1ï¼šå˜—è©¦ä½¿ç”¨ strict=Falseï¼ˆPython 3.9+ï¼‰
            try:
                if sys.version_info >= (3, 9):
                    ai_data = json.loads(ai_response, strict=False)
                else:
                    raise TypeError("Python < 3.9")
            except (TypeError, json.JSONDecodeError) as e:
                # æ–¹æ³•2ï¼šæ‰‹å‹•ä¿®å¾© full_text å­—æ®µä¸­çš„æ§åˆ¶å­—ç¬¦
                # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æ‰¾åˆ° "full_text" å­—æ®µä¸¦ä¿®å¾©å…¶ä¸­çš„æ›è¡Œç¬¦
                try:
                    # åŒ¹é… "full_text": "..." æ¨¡å¼ï¼ˆæ”¯æŒå¤šè¡Œï¼‰
                    # ä½¿ç”¨éè²ªå©ªåŒ¹é…å’Œ DOTALL æ¨¡å¼
                    pattern = r'"full_text"\s*:\s*"((?:[^"\\]|\\.)*)"'
                    
                    def fix_control_chars(match):
                        """ä¿®å¾©å­—ä¸²å€¼ä¸­çš„æ§åˆ¶å­—ç¬¦"""
                        content = match.group(1)
                        # è½‰ç¾©æ§åˆ¶å­—ç¬¦ï¼ˆä½†ä¿ç•™å·²è½‰ç¾©çš„å­—ç¬¦ï¼‰
                        # åªæ›¿æ›æœªè½‰ç¾©çš„æ§åˆ¶å­—ç¬¦
                        content = re.sub(r'(?<!\\)\n', '\\n', content)
                        content = re.sub(r'(?<!\\)\r', '\\r', content)
                        content = re.sub(r'(?<!\\)\t', '\\t', content)
                        return f'"full_text": "{content}"'
                    
                    ai_response_cleaned = re.sub(pattern, fix_control_chars, ai_response, flags=re.DOTALL)
                    ai_data = json.loads(ai_response_cleaned)
                except json.JSONDecodeError:
                    # æ–¹æ³•3ï¼šæœ€å¾Œå˜—è©¦ - ä½¿ç”¨æ›´å¯¬é¬†çš„ä¿®å¾©
                    # ç›´æ¥æ›¿æ›æ‰€æœ‰æ§åˆ¶å­—ç¬¦ï¼ˆå¯èƒ½ç ´å£çµæ§‹ï¼Œä½†ä½œç‚ºæœ€å¾Œæ‰‹æ®µï¼‰
                    try:
                        ai_response_cleaned = ai_response.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                        # ä½†é€™æœƒç ´å£ full_text çš„æ ¼å¼ï¼Œæ‰€ä»¥æˆ‘å€‘éœ€è¦æ›´æ™ºèƒ½çš„æ–¹æ³•
                        # æ”¹ç”¨ï¼šåªæ›¿æ›å­—ä¸²å€¼ä¸­çš„æ§åˆ¶å­—ç¬¦
                        # ç°¡å–®æ–¹æ³•ï¼šæ‰¾åˆ°æ‰€æœ‰å­—ä¸²å€¼ä¸¦ä¿®å¾©
                        def escape_string_value(match):
                            quote = match.group(1)
                            content = match.group(2)
                            # è½‰ç¾©æ§åˆ¶å­—ç¬¦
                            content = content.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
                            return f'{quote}{content}{quote}'
                        
                        # åŒ¹é…å­—ä¸²å€¼ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
                        ai_response_cleaned = re.sub(r'(")((?:[^"\\]|\\.)*)(")', escape_string_value, ai_response)
                        ai_data = json.loads(ai_response_cleaned)
                    except json.JSONDecodeError as final_error:
                        logger.error(f"æ‰€æœ‰ JSON ä¿®å¾©æ–¹æ³•éƒ½å¤±æ•—: {final_error}")
                        logger.error(f"åŸå§‹éŸ¿æ‡‰å‰1000å­—ç¬¦: {ai_response[:1000]}")
                        raise
            
            # ç²å– learning_path å’Œ top_actions
            ai_learning_path = ai_data.get('learning_path', learning_path or [])
            ai_top_actions = ai_data.get('top_actions', [
                {"action": "è¤‡ç¿’åŸºç¤", "detail": "é‡æ–°å­¸ç¿’åŸºæœ¬æ¦‚å¿µ", "est_min": 10},
                {"action": "åšç·´ç¿’", "detail": "å®Œæˆç›¸é—œç·´ç¿’é¡Œ", "est_min": 20},
                {"action": "å°‹æ±‚å¹«åŠ©", "detail": "é‡æ–°è¤‡ç¿’èª²ç¨‹", "est_min": 5}
            ])
            
            # ç¢ºä¿ top_actions åŒ…å«ä¸‰ç¨®ä¸åŒé¡å‹
            fixed_top_actions = ensure_diverse_action_types(ai_top_actions, ai_learning_path)
            
            # é©—è­‰ä¸¦è¿”å›æ–°çš„schemaæ ¼å¼ï¼ŒåŒ…å«Neo4jé—œè¯è³‡è¨Š
            return {
                'summary': ai_data.get('summary', f'{concept_name}æŒæ¡åº¦{mastery:.1%}ï¼Œéœ€é‡é»é—œæ³¨'),
                'metrics': {
                    'domain': domain_name,
                    'concept': concept_name,
                    'mastery': mastery,
                    'attempts': total_attempts,
                    'recent_accuracy': recent_accuracy
                },
                'root_causes': ai_data.get('root_causes', ['åŸºç¤æ¦‚å¿µä¸ç‰¢å›º', 'ç·´ç¿’ä¸è¶³']),
                'top_actions': fixed_top_actions,
                'practice_examples': ai_data.get('practice_examples', [
                    {"q_id": "q101", "difficulty": "easy", "text": "åŸºç¤æ¦‚å¿µé¡Œ"},
                    {"q_id": "q102", "difficulty": "medium", "text": "æ‡‰ç”¨ç·´ç¿’é¡Œ"}
                ]),
                # ä½¿ç”¨å¾Œç«¯æº–å‚™çš„ relations_detailï¼Œè€Œä¸æ˜¯ AI è¿”å›çš„æ ¼å¼
                # AI å¯èƒ½è¿”å›éŒ¯èª¤æ ¼å¼çš„ knowledge_relationsï¼Œæˆ‘å€‘å¿½ç•¥å®ƒ
                'knowledge_relations': {
                    'has_relations': knowledge_relations.get('has_relations', False) if knowledge_relations else False,
                    'prerequisites': relations_detail.get('prerequisites', []) if relations_detail else [],
                    'related_concepts': relations_detail.get('related', []) if relations_detail else [],
                    'leads_to': relations_detail.get('leads_to', []) if relations_detail else [],
                    'relation_graph': relations_detail.get('relation_graph', {}) if relations_detail else {},
                    'total_relations': relations_detail.get('total_relations', 0) if relations_detail else 0
                },
                'evidence': ai_data.get('evidence', [f'ç­”é¡Œ{total_attempts}æ¬¡', f'æ­£ç¢ºç‡{recent_accuracy:.1%}']),
                'confidence': ai_data.get('confidence', 'medium'),
                'learning_path': ai_learning_path,  # å„ªå…ˆä½¿ç”¨AIç”Ÿæˆçš„å­¸ç¿’è·¯å¾‘
                'full_text': ai_data.get('full_text', f'''
## è©³ç´°è¨ºæ–·åˆ†æ

### å­¸ç¿’ç‹€æ³è©•ä¼°
- **æ¦‚å¿µåç¨±**ï¼š{concept_name}
- **æ‰€å±¬é ˜åŸŸ**ï¼š{domain_name}
- **æ•´é«”æŒæ¡åº¦**ï¼š{mastery:.1%}
- **ç­”é¡Œæ¬¡æ•¸**ï¼š{total_attempts}æ¬¡
- **æœ€è¿‘æº–ç¢ºç‡**ï¼š{recent_accuracy:.1%}

### å•é¡Œåˆ†æ
æ ¹æ“šæ‚¨çš„ç­”é¡Œè¨˜éŒ„åˆ†æï¼Œåœ¨{concept_name}é€™å€‹çŸ¥è­˜é»ä¸Šå­˜åœ¨ä»¥ä¸‹å•é¡Œï¼š

1. **åŸºç¤æ¦‚å¿µç†è§£ä¸è¶³**ï¼šæŒæ¡åº¦åƒ…{mastery:.1%}ï¼Œé¡¯ç¤ºå°åŸºæœ¬æ¦‚å¿µçš„ç†è§£é‚„ä¸å¤ æ·±å…¥
2. **ç·´ç¿’é‡ä¸è¶³**ï¼šç¸½å…±åªç­”äº†{total_attempts}é¡Œï¼Œéœ€è¦æ›´å¤šç·´ç¿’ä¾†éå›ºçŸ¥è­˜
3. **æ‡‰ç”¨èƒ½åŠ›å¾…æå‡**ï¼šæœ€è¿‘æº–ç¢ºç‡{recent_accuracy:.1%}ï¼Œèªªæ˜åœ¨å¯¦éš›æ‡‰ç”¨ä¸­é‚„æœ‰å›°é›£

### å­¸ç¿’å»ºè­°
1. **å›æ­¸åŸºç¤**ï¼šé‡æ–°å­¸ç¿’{concept_name}çš„åŸºæœ¬å®šç¾©å’Œæ ¸å¿ƒæ¦‚å¿µ
2. **å¾ªåºæ¼¸é€²**ï¼šå¾ç°¡å–®é¡Œç›®é–‹å§‹ï¼Œé€æ­¥æé«˜é›£åº¦
3. **å¤§é‡ç·´ç¿’**ï¼šå»ºè­°è‡³å°‘å®Œæˆ10-15é¡Œç›¸é—œç·´ç¿’
4. **å°‹æ±‚å¹«åŠ©**ï¼šé‡åˆ°å›°é›£æ™‚åŠæ™‚å‘è€å¸«æˆ–åŒå­¸è«‹æ•™

### ä¸‹ä¸€æ­¥è¡Œå‹•
å»ºè­°æ‚¨ç«‹å³é–‹å§‹ç·´ç¿’ï¼Œå¾åŸºç¤æ¦‚å¿µé¡Œé–‹å§‹ï¼Œé€æ­¥æå‡åˆ°æ‡‰ç”¨é¡Œï¼Œä¸¦åœ¨å­¸ç¿’éç¨‹ä¸­æ³¨æ„ç¸½çµéŒ¯èª¤é¡å‹ï¼Œé¿å…é‡è¤‡çŠ¯éŒ¯ã€‚
''')
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£æGeminiéŸ¿æ‡‰å¤±æ•—: {e}")
            logger.error(f"åŸå§‹éŸ¿æ‡‰: {ai_response[:2000] if len(ai_response) > 2000 else ai_response}")
            # è¿”å›é»˜èªè¨ºæ–·çµæœ
            return {
                'summary': f'{concept_name}æŒæ¡åº¦{mastery:.1%}ï¼Œéœ€é‡é»é—œæ³¨',
                'metrics': {
                    'domain': domain_name,
                    'concept': concept_name,
                    'mastery': mastery,
                    'attempts': total_attempts,
                    'recent_accuracy': recent_accuracy
                },
                'root_causes': ['åŸºç¤æ¦‚å¿µä¸ç‰¢å›º', 'ç·´ç¿’ä¸è¶³'],
                'top_actions': [
                    {"action": "REVIEW_BASICS", "detail": "AIå°å¸«é€²è¡ŒåŸºç¤æ¦‚å¿µæ•™å­¸", "est_min": 15},
                    {"action": "PRACTICE", "detail": "AIç”Ÿæˆç›¸é—œç·´ç¿’é¡Œé€²è¡Œç·´ç¿’", "est_min": 20},
                    {"action": "SEEK_HELP", "detail": "è§€çœ‹ç›¸é—œæ•™æå…§å®¹", "est_min": 10}
                ],
                'practice_examples': [],
                'knowledge_relations': {
                    'has_relations': knowledge_relations.get('has_relations', False) if knowledge_relations else False,
                    'prerequisites': relations_detail.get('prerequisites', []) if relations_detail else [],
                    'related_concepts': relations_detail.get('related', []) if relations_detail else [],
                    'leads_to': relations_detail.get('leads_to', []) if relations_detail else [],
                    'relation_graph': relations_detail.get('relation_graph', {}) if relations_detail else {},
                    'total_relations': relations_detail.get('total_relations', 0) if relations_detail else 0
                },
                'evidence': [f'ç­”é¡Œ{total_attempts}æ¬¡', f'æ­£ç¢ºç‡{recent_accuracy:.1%}'],
                'confidence': 'low',
                'learning_path': learning_path or [],
                'full_text': f'ä½ åœ¨ã€Œ{concept_name}ã€é€™å€‹æ¦‚å¿µä¸Šé‚„éœ€è¦å¤šåŠ å¼·ã€‚ç›®å‰æŒæ¡åº¦{mastery:.1%}ï¼Œç­”é¡Œæ­£ç¢ºç‡{recent_accuracy:.1%}ã€‚å»ºè­°ä½ å…ˆé€éAIå°å¸«é‡æ–°å­¸ç¿’åŸºæœ¬æ¦‚å¿µï¼Œç„¶å¾Œå¤šåšä¸€äº›ç·´ç¿’é¡Œä¾†éå›ºã€‚'
            }
    except Exception as e:
        logger.error(f"AIè¨ºæ–·å¤±æ•—: {e}", exc_info=True)
        # è¿”å›é»˜èªè¨ºæ–·çµæœ
        return {
            'summary': f'{concept_name}æŒæ¡åº¦{mastery:.1%}ï¼Œéœ€é‡é»é—œæ³¨',
            'metrics': {
                'domain': domain_name,
                'concept': concept_name,
                'mastery': mastery,
                'attempts': total_attempts,
                'recent_accuracy': recent_accuracy
            },
            'root_causes': ['åŸºç¤æ¦‚å¿µä¸ç‰¢å›º', 'ç·´ç¿’ä¸è¶³'],
            'top_actions': [
                {"action": "REVIEW_BASICS", "detail": "AIå°å¸«é€²è¡ŒåŸºç¤æ¦‚å¿µæ•™å­¸", "est_min": 15},
                {"action": "PRACTICE", "detail": "AIç”Ÿæˆç›¸é—œç·´ç¿’é¡Œé€²è¡Œç·´ç¿’", "est_min": 20},
                {"action": "SEEK_HELP", "detail": "è§€çœ‹ç›¸é—œæ•™æå…§å®¹", "est_min": 10}
            ],
            'practice_examples': [],
            'knowledge_relations': {
                'has_relations': knowledge_relations.get('has_relations', False) if knowledge_relations else False,
                'prerequisites': relations_detail.get('prerequisites', []) if relations_detail else [],
                'related_concepts': relations_detail.get('related', []) if relations_detail else [],
                'leads_to': relations_detail.get('leads_to', []) if relations_detail else [],
                'relation_graph': relations_detail.get('relation_graph', {}) if relations_detail else {},
                'total_relations': relations_detail.get('total_relations', 0) if relations_detail else 0
            },
            'evidence': [f'ç­”é¡Œ{total_attempts}æ¬¡', f'æ­£ç¢ºç‡{recent_accuracy:.1%}'],
            'confidence': 'low',
            'learning_path': learning_path or [],
            'full_text': f'ä½ åœ¨ã€Œ{concept_name}ã€é€™å€‹æ¦‚å¿µä¸Šé‚„éœ€è¦å¤šåŠ å¼·ã€‚ç›®å‰æŒæ¡åº¦{mastery:.1%}ï¼Œç­”é¡Œæ­£ç¢ºç‡{recent_accuracy:.1%}ã€‚å»ºè­°ä½ å…ˆé€éAIå°å¸«é‡æ–°å­¸ç¿’åŸºæœ¬æ¦‚å¿µï¼Œç„¶å¾Œå¤šåšä¸€äº›ç·´ç¿’é¡Œä¾†éå›ºã€‚'
        }

def generate_attention_items(domains: List[Dict], quiz_records: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆéœ€è¦é—œæ³¨çš„çŸ¥è­˜é»æ•¸æ“š - åŸºæ–¼ç­”é¡Œè¨˜éŒ„åˆ†æé€€æ­¥æƒ…æ³"""
    attention_items = []
    
    # æŒ‰é ˜åŸŸåˆ†çµ„åˆ†æ
    domain_records = {}
    for record in quiz_records:
        domain_name = record.get('domain_name', 'æœªçŸ¥é ˜åŸŸ')
        if domain_name not in domain_records:
            domain_records[domain_name] = []
        domain_records[domain_name].append(record)
    
    # ç‚ºæ¯å€‹é ˜åŸŸåˆ†æé€€æ­¥æƒ…æ³
    for domain_name, records in domain_records.items():
        # è·³éã€ŒæœªçŸ¥é ˜åŸŸã€
        if domain_name == 'æœªçŸ¥é ˜åŸŸ' or domain_name == 'æœªçŸ¥' or not domain_name or domain_name.strip() == '':
            continue
        if len(records) < 3:
            continue
            
        # æŒ‰æ™‚é–“æ’åº
        records.sort(key=lambda x: x['attempt_time'])
        
        # è¨ˆç®—æœ€è¿‘å’Œä¹‹å‰çš„æ­£ç¢ºç‡
        mid_point = len(records) // 2
        recent_records = records[:mid_point]  # å‰åŠéƒ¨åˆ†
        older_records = records[mid_point:]   # å¾ŒåŠéƒ¨åˆ†
        
        if len(older_records) == 0:
            continue
            
        recent_accuracy = sum(1 for r in recent_records if r['is_correct']) / len(recent_records)
        older_accuracy = sum(1 for r in older_records if r['is_correct']) / len(older_records)
        
        decline = (older_accuracy - recent_accuracy) * 100
        
        # é™ä½é€€æ­¥è¦æ±‚ï¼Œåªè¦æœ‰é€€æ­¥å°±é¡¯ç¤º
        if decline > 0:  # åªè¦æœ‰é€€æ­¥å°±é¡¯ç¤º
            # è¨ˆç®—ç¸½æŒæ¡åº¦
            total_questions = len(records)
            correct_questions = sum(1 for r in records if r['is_correct'])
            mastery = correct_questions / total_questions if total_questions > 0 else 0
            
            attention_items.append({
                'name': domain_name,
                'mastery': round(mastery, 3),  # çµ±ä¸€ä½¿ç”¨mastery
                'decline': round(decline, 1),
                'priority': 'high' if decline > 20 else 'medium' if decline > 10 else 'low',
                'current_accuracy': round(mastery * 100, 1),  # ä½¿ç”¨masteryè€Œä¸æ˜¯recent_accuracy
                'previous_accuracy': round((mastery + decline/100) * 100, 1),  # åŸºæ–¼masteryè¨ˆç®—
                'questions': total_questions,
                'ai_strategy': f'æŒæ¡åº¦åƒ…{round(mastery * 100, 1)}%ï¼Œå»ºè­°åŠ å¼·ç·´ç¿’'  # çµ±ä¸€ä½¿ç”¨mastery
            })
    
    # æŒ‰é€€æ­¥å¹…åº¦æ’åº
    attention_items.sort(key=lambda x: x['decline'], reverse=True)
    return attention_items[:5]  # è¿”å›å‰5å€‹

def generate_progress_tracking(quiz_records: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆé€²åº¦è¿½è¹¤æ•¸æ“š"""
    if not quiz_records:
        return []
    
    # è¨ˆç®—å„ç¨®é€²åº¦æŒ‡æ¨™
    total_questions = len(quiz_records)
    correct_questions = sum(1 for r in quiz_records if r['is_correct'])
    accuracy = (correct_questions / total_questions * 100) if total_questions > 0 else 0
    
    # è¨ˆç®—å­¸ç¿’å¤©æ•¸
    learning_days = len(set(r['attempt_time'][:10] for r in quiz_records))
    
    # è¨ˆç®—é€£çºŒå­¸ç¿’å¤©æ•¸
    consecutive_days = calculate_consecutive_days(quiz_records)
    
    progress_tracking = [
        {
            'title': 'ç­”é¡Œæº–ç¢ºç‡',
            'percentage': round(accuracy, 1),
            'target': 80,
            'color': 'success' if accuracy >= 80 else 'warning' if accuracy >= 60 else 'danger'
        },
        {
            'title': 'å­¸ç¿’å¤©æ•¸',
            'percentage': min(100, round(learning_days / 30 * 100, 1)),
            'target': 30,
            'color': 'info'
        },
        {
            'title': 'é€£çºŒå­¸ç¿’',
            'percentage': min(100, round(consecutive_days / 7 * 100, 1)),
            'target': 7,
            'color': 'primary'
        }
    ]
    
    return progress_tracking

def generate_radar_data(domains: List[Dict], quiz_records: List[Dict]) -> Dict:
    """ç”Ÿæˆé›·é”åœ–æ•¸æ“š"""
    if not domains:
        return {
            'labels': [],
            'data': []
        }
    
    labels = []
    mastery_data = []
    
    for domain in domains:
        domain_name = domain.get('name', 'æœªçŸ¥é ˜åŸŸ')
        mastery = domain.get('mastery', 0) * 100  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
        
        labels.append(domain_name)
        mastery_data.append(round(mastery, 1))
    
    return {
        'labels': labels,
        'data': mastery_data
    }

# AIæ•™ç·´åˆ†æç¾åœ¨ä½¿ç”¨Rediså¿«å–æœå‹™
