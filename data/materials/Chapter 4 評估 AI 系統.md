# Chapter 4 評估 AI 系統

---

在本章中，我們將深入探討如何有效評估 AI 系統的效能、可靠性與公正性。成功的 AI 系統不僅僅是能執行任務，更重要的是能夠在各種情境下，以可靠、公正且可預測的方式達成預期目標。透過學習各種評估指標與方法，您將能夠選擇最適合您的 AI 應用場景的評估策略，並據此改進您的模型。

---

## 4.1 核心概念：為何與如何評估 AI 系統

評估 AI 系統是機器學習生命週期中不可或缺的一環。它幫助我們理解模型的表現，識別其優勢與劣勢，並指導模型的改進方向。

### 4.1.1 評估的目的

評估 AI 系統的目的主要有以下幾點：

*   **效能衡量 (Performance Measurement)**：量化模型完成任務的精確度、效率與品質。
*   **模型選擇 (Model Selection)**：在多個候選模型中，根據評估結果選擇最佳的模型。
*   **超參數調優 (Hyperparameter Tuning)**：根據評估指標的變化來調整模型的超參數，以達到最佳效能。
*   **可靠性與穩健性 (Reliability & Robustness)**：確保模型在面對不同、甚至是惡意輸入時，仍能保持穩定表現。
*   **公平性與偏差檢測 (Fairness & Bias Detection)**：識別模型是否存在對特定群體不公平的待遇或偏差。
*   **部署決策 (Deployment Decision)**：判斷模型是否已達到足夠的標準，可以部署到實際應用中。

### 4.1.2 評估的數據劃分

在評估 AI 系統時，正確的數據劃分至關重要，以避免「數據洩漏 (Data Leakage)」和「過度擬合 (Overfitting)」的問題。通常將數據集劃分為三個部分：

*   **訓練集 (Training Set)**：用於模型學習模式和參數。這是模型「看」到的數據。
*   **驗證集 (Validation Set)**：用於在訓練過程中調整模型超參數，並進行初步的模型選擇。此數據集不直接參與模型參數的訓練，但會間接影響訓練過程。
*   **測試集 (Test Set)**：用於在模型完全訓練完成後，對其最終效能進行獨立、無偏的評估。模型在訓練和驗證階段都未曾「看」過這部分數據。

**核心觀念：**
測試集應該是模型完全未知的數據，以真實反映模型在未見過數據上的泛化能力。
常見的劃分比例為 70% 訓練集、15% 驗證集、15% 測試集，或 80% 訓練集、20% 測試集（如果不需要獨立的驗證集）。

**與相鄰概念的關聯：**
正確的數據劃分與**交叉驗證 (Cross-Validation)** 緊密相關。交叉驗證是一種更穩健的驗證技術，它將訓練集進一步劃分為多個子集，輪流作為訓練和驗證，以減少評估結果對特定數據劃分的依賴性，提供更穩定的效能估計。

---

## 4.2 典型評估指標與其推導

不同的 AI 任務需要不同的評估指標。本節將介紹針對分類、迴歸和生成式任務的常見指標。

### 4.2.1 分類任務評估指標

分類任務的目標是將數據點歸類到預定義的類別中。二元分類（兩個類別）是最基礎的形式。

#### 4.2.1.1 混淆矩陣 (Confusion Matrix)

**定義/核心觀念：**
混淆矩陣是一種表格，用於視覺化分類模型在測試集上的效能。它總結了真實類別與模型預測類別之間的一致性和差異。

**結構：**
對於二元分類，混淆矩陣通常有四個象限：

|               | 預測為正 (Predicted Positive) | 預測為負 (Predicted Negative) |
| :------------ | :---------------------------- | :---------------------------- |
| **實際為正**  | 真陽性 (True Positive, TP)    | 偽陰性 (False Negative, FN)   |
| **實際為負**  | 偽陽性 (False Positive, FP)   | 真陰性 (True Negative, TN)    |

*   **TP (True Positive)**：模型正確地預測為正類別，且實際也是正類別。
*   **FN (False Negative)**：模型錯誤地預測為負類別，但實際是正類別（錯過）。
*   **FP (False Positive)**：模型錯誤地預測為正類別，但實際是負類別（誤報）。
*   **TN (True Negative)**：模型正確地預測為負類別，且實際也是負類別。

**例子：**
假設一個模型用於檢測病人是否患有某種疾病（正類別：有病，負類別：無病）。
*   TP：實際有病，模型診斷為有病。
*   FN：實際有病，模型診斷為無病（漏診）。
*   FP：實際無病，模型診斷為有病（誤診）。
*   TN：實際無病，模型診斷為無病。

#### 4.2.1.2 從混淆矩陣推導的指標

基於混淆矩陣，我們可以推導出多種關鍵的分類指標。

1.  **準確率 (Accuracy)**
    *   **定義：** 模型正確預測的樣本數佔總樣本數的比例。
    *   **公式：**
        $$ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} $$
    *   **用途：** 當數據集類別分佈比較均衡時，是一個直觀的整體效能指標。
    *   **關聯：** 在類別不平衡的數據集中，單獨使用 Accuracy 可能會產生誤導。

2.  **精確度 (Precision)**
    *   **定義：** 在所有模型預測為正類別的樣本中，實際為正類別的比例。
    *   **公式：**
        $$ \text{Precision} = \frac{TP}{TP + FP} $$
    *   **用途：** 衡量模型在預測正類別時的準確性，減少誤報。例如，垃圾郵件檢測中，高 Precision 意味著很少將正常郵件誤判為垃圾郵件。
    *   **關聯：** 通常與 Recall (召回率) 形成權衡，提高 Precision 可能會降低 Recall。

3.  **召回率 (Recall) / 靈敏度 (Sensitivity) / 真陽性率 (True Positive Rate, TPR)**
    *   **定義：** 在所有實際為正類別的樣本中，模型成功預測為正類別的比例。
    *   **公式：**
        $$ \text{Recall} = \frac{TP}{TP + FN} $$
    *   **用途：** 衡量模型識別正類別的能力，減少漏報。例如，疾病診斷中，高 Recall 意味著很少漏診患病者。
    *   **關聯：** 在某些應用中（如安全監控、疾病預測），Recall 比 Precision 更重要。

4.  **F1 分數 (F1-Score)**
    *   **定義：** Precision 和 Recall 的調和平均數。當 Precision 和 Recall 都很高時，F1-Score 才會高。
    *   **公式：**
        $$ \text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} $$
    *   **用途：** 在 Precision 和 Recall 同等重要時，或當類別分佈不平衡時，F1-Score 是比 Accuracy 更好的綜合指標。
    *   **關聯：** F1-Score 綜合考慮了模型的精確性和完整性。

5.  **特異度 (Specificity) / 真陰性率 (True Negative Rate, TNR)**
    *   **定義：** 在所有實際為負類別的樣本中，模型成功預測為負類別的比例。
    *   **公式：**
        $$ \text{Specificity} = \frac{TN}{TN + FP} $$
    *   **用途：** 衡量模型識別負類別的能力。
    *   **關聯：** 是 TPR 的補充，TPR 關注正類別，TNR 關注負類別。

#### 4.2.1.3 ROC 曲線 (Receiver Operating Characteristic Curve) 與 AUC (Area Under the Curve)

**定義/核心觀念：**
ROC 曲線是一種視覺化工具，用於展示二元分類模型在所有可能分類閾值下的表現。它繪製了真陽性率 (TPR) 對偽陽性率 (FPR) 的曲線。

*   **TPR (True Positive Rate) = Recall**
*   **FPR (False Positive Rate) = $\frac{FP}{FP + TN}$**

**推導：**
大多數分類模型會輸出一個介於 0 到 1 之間的分數（例如，機率），然後根據一個閾值將其轉換為二元預測（例如，分數 > 0.5 則預測為正類）。通過改變這個閾值，我們可以得到一系列不同的 (FPR, TPR) 對，將這些點連接起來就形成了 ROC 曲線。

**AUC (Area Under the Curve)**
*   **定義：** ROC 曲線下方的面積。AUC 值介於 0 到 1 之間。
*   **用途：** 提供了一個單一數值來總結模型在所有可能閾值下的整體分類效能。
    *   AUC = 1 表示完美分類器。
    *   AUC = 0.5 表示模型與隨機猜測一樣好（或一樣差）。
    *   AUC < 0.5 表示模型比隨機猜測還差，可能需要檢查預測機率是否反轉。
*   **優勢：** 對於類別不平衡的數據集，AUC 是比 Accuracy 更穩健的指標，因為它不依賴於單一的分類閾值。
*   **關聯：** 可以視為模型將隨機選擇的正樣本排在隨機選擇的負樣本之前的機率。

---

### 4.2.2 迴歸任務評估指標

迴歸任務的目標是預測一個連續的數值。

1.  **均方誤差 (Mean Squared Error, MSE)**
    *   **定義：** 預測值與真實值之差的平方的平均值。
    *   **公式：**
        $$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $$
        其中 $y_i$ 是真實值，$\hat{y}_i$ 是預測值，$n$ 是樣本數。
    *   **用途：** 對於較大的誤差有更高的懲罰，因為誤差被平方了。
    *   **關聯：** 數學上易於處理，是許多優化演算法的目標函數。單位是目標變數的平方。

2.  **均方根誤差 (Root Mean Squared Error, RMSE)**
    *   **定義：** MSE 的平方根。
    *   **公式：**
        $$ \text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} $$
    *   **用途：** 與目標變數具有相同的單位，更具可解釋性。
    *   **關聯：** 仍對大誤差敏感。

3.  **平均絕對誤差 (Mean Absolute Error, MAE)**
    *   **定義：** 預測值與真實值之差的絕對值的平均值。
    *   **公式：**
        $$ \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| $$
    *   **用途：** 對於異常值 (outliers) 的敏感度低於 MSE/RMSE，因為它不對誤差進行平方。
    *   **關聯：** 單位與目標變數相同，可解釋性好。

4.  **R 平方 (R-squared, $R^2$)**
    *   **定義：** 衡量模型解釋因變量變異的比例。一個值為 1 意味著模型完美預測，值為 0 意味著模型解釋不了任何變異（與預測平均值一樣差），負值意味著模型比預測平均值還差。
    *   **公式：**
        $$ R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} $$
        其中 $\bar{y}$ 是真實值的平均值。
    *   **用途：** 提供模型擬合優度的一個百分比解釋，容易理解。
    *   **關聯：** 在加入更多解釋變數時，即使這些變數對模型沒有實際幫助，$R^2$ 也可能增加。因此，調整後的 $R^2$ (Adjusted $R^2$) 在評估多變量迴歸模型時更常用。

---

### 4.2.3 生成式 AI 評估指標（進階）

生成式 AI（如大型語言模型、圖像生成模型）的評估比傳統分類/迴歸更複雜，往往需要兼顧客觀指標和人類判斷。

1.  **BLEU (Bilingual Evaluation Understudy)**
    *   **定義/核心觀念：** 一種用於評估機器翻譯輸出的分數，衡量生成的文本與一組參考翻譯之間 n-gram 重疊的程度。
    *   **推導：** 計算 1-gram 到 4-gram 的精確度，並應用一個簡潔懲罰因子（如果生成文本比參考文本短）。
    *   **用途：** 機器翻譯、文本摘要等任務。
    *   **關聯：** 雖然是常用的自動指標，但 BLEU 不一定總能捕捉到語義的流暢性和自然性。

2.  **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**
    *   **定義/核心觀念：** 一組用於評估自動文本摘要和機器翻譯的指標，主要基於召回率，衡量生成的文本覆蓋參考文本關鍵信息的程度。
    *   **推導：** ROUGE-N 關注 n-gram 重疊，ROUGE-L 關注最長公共子序列，ROUGE-S 關注跳躍二元組（允許不連續的詞）。
    *   **用途：** 文本摘要、機器翻譯。
    *   **關聯：** 與 BLEU 互補，BLEU 側重精確度，ROUGE 側重召回率。

3.  **Perplexity (困惑度)**
    *   **定義/核心觀念：** 衡量語言模型預測樣本的下一個詞的難度。困惑度越低，表示模型對文本的預測能力越強，模型對文本的理解和生成能力越好。
    *   **公式（簡化）：**
        $$ \text{Perplexity}(W) = \left( \prod_{i=1}^N \frac{1}{P(w_i|w_1, ..., w_{i-1})} \right)^{1/N} $$
        或者更常見的是，熵的指數形式：$2^{-\frac{1}{N} \sum_{i=1}^N \log_2 P(w_i|w_1, ..., w_{i-1})}$
    *   **用途：** 語言模型、語音識別、文本生成等。
    *   **關聯：** 可以作為評估語言模型質量的一個代理指標。

---

## 4.3 與相鄰概念的關聯

評估 AI 系統不僅僅是計算指標，它與 AI 的整個開發生命週期和更廣泛的倫理考量都緊密相連。

### 4.3.1 評估與模型訓練、調優的關係

*   **指導訓練：** 評估指標是模型訓練過程中優化器（Optimizer）和損失函數（Loss Function）的「北極星」。雖然損失函數直接用於梯度下降，但評估指標提供了更具解釋性的模型效能視角。
*   **模型選擇：** 在多個模型架構（例如，不同的神經網路層數、不同樹深度）之間進行選擇時，我們會根據驗證集上的評估指標來決定哪個模型是最佳的。
*   **超參數調優：** 學習率、批量大小、正則化強度等超參數的選擇，通常是通過網格搜索 (Grid Search)、隨機搜索 (Random Search) 或貝葉斯優化 (Bayesian Optimization) 等方法，根據驗證集上的評估指標來優化的。

### 4.3.2 評估與 AI 倫理、公平性的關係

*   **偏見檢測：** 傳統的效能指標（如 Accuracy）可能無法揭示模型對不同群體（如不同性別、種族、年齡）是否存在偏見。透過針對特定群體計算 Precision、Recall 或專門的公平性指標（如 Disparate Impact、Equal Opportunity Difference），可以發現模型潛在的歧視性行為。
*   **負責任 AI (Responsible AI)：** 評估公平性、透明度和可解釋性是構建負責任 AI 系統的核心。模型的評估應擴展到技術效能之外，納入社會影響和倫理考量。
*   **透明度與可解釋性 (Explainability)：** 即使模型效能很高，如果我們無法理解它是如何做出決策的，就難以信任它，也難以發現潛在的偏見。可解釋性工具（如 LIME, SHAP）可以幫助我們理解模型的決策依據。

### 4.3.3 評估與實際部署的關係

*   **離線評估 vs. 線上評估：** 
    *   **離線評估：** 使用歷史數據在開發環境中進行的評估。本章大部分內容屬於離線評估。
    *   **線上評估：** 在模型部署到生產環境後，透過 A/B 測試、多臂老虎機 (Multi-armed Bandit) 等技術，收集真實用戶反饋並進行的評估。線上評估能夠反映模型在真實環境中的實際表現和業務影響。
*   **監控：** 模型部署後，需要持續監控其效能指標、數據漂移 (Data Drift) 和概念漂移 (Concept Drift)，以便及時發現模型效能下降並進行再訓練或調整。
*   **業務目標對齊：** 選擇評估指標時，必須考慮它們是否與實際的業務目標對齊。例如，在電商推薦系統中，點擊率 (CTR) 和轉化率 (Conversion Rate) 可能比單純的預測精確度更重要。

---

## 4.4 進階內容：穩健性與公平性評估

除了標準效能指標，現代 AI 系統還需要關注其在面對挑戰性輸入和不同用戶群體時的表現。

### 4.4.1 穩健性 (Robustness) 評估

穩健性衡量模型在面對數據中的微小變動、雜訊或惡意攻擊時，仍能保持其效能的能力。

*   **對抗性範例 (Adversarial Examples)：** 透過人眼難以察覺的微小擾動，故意修改輸入數據（如圖像或文本），導致模型做出錯誤預測。
    *   **評估方法：** 生成對抗性範例，並測量模型在這些範例上的錯誤率。常用的生成方法有 FGSM (Fast Gradient Sign Method), PGD (Projected Gradient Descent) 等。
*   **輸入數據擾動：** 評估模型在面對自然雜訊（如圖像模糊、語音失真）或缺失數據時的表現。
    *   **評估方法：** 在測試集上添加不同程度的隨機雜訊，或隨機遮蔽部分輸入，然後重新評估模型。

### 4.4.2 公平性 (Fairness) 評估

公平性評估旨在識別和量化模型對不同受保護屬性群體（如性別、種族、年齡）是否存在偏見。

*   **保護屬性 (Protected Attributes)：** 指那些不應該影響模型決策的敏感特徵。
*   **公平性指標：**
    1.  **統計平等 (Demographic Parity / Statistical Parity)**
        *   **定義：** 不同群體的模型預測結果應具有相同的正類別機率。即 $P(\hat{Y}=1 | A=a_1) = P(\hat{Y}=1 | A=a_2)$。
        *   **用途：** 確保模型在不同群體中的整體預測是平衡的。
    2.  **機會均等 (Equal Opportunity)**
        *   **定義：** 在實際結果為正類別的樣本中，不同群體被模型正確識別為正類別的機率應相等（即召回率相等）。即 $P(\hat{Y}=1 | Y=1, A=a_1) = P(\hat{Y}=1 | Y=1, A=a_2)$。
        *   **用途：** 確保模型在提供「機會」（如貸款批准、錄取資格）時，不會因受保護屬性而產生偏差。
    3.  **預測率均等 (Equalized Odds)**
        *   **定義：** 在實際結果為正類別和負類別的樣本中，不同群體被模型正確識別的機率都應相等（即 TPR 和 FPR 都相等）。即 $P(\hat{Y}=1 | Y=1, A=a_1) = P(\hat{Y}=1 | Y=1, A=a_2)$ 且 $P(\hat{Y}=1 | Y=0, A=a_1) = P(\hat{Y}=1 | Y=0, A=a_2)$。
        *   **用途：** 比機會均等更嚴格，要求模型在所有情況下都表現出公平性。
*   **關聯：** 不同的公平性定義往往無法同時滿足，需要在應用場景中權衡選擇。

---

## 4.5 常見錯誤與澄清

在評估 AI 系統時，有一些常見的陷阱需要避免。

*   **錯誤 1：數據洩漏 (Data Leakage)**
    *   **描述：** 在模型訓練過程中，無意中使用了來自測試集或未來數據的信息。例如，在特徵工程階段使用了整個數據集（包括測試集）來計算統計量（如平均值、標準差），或者使用了未來才可得的資訊作為特徵。
    *   **澄清：** 嚴格確保訓練、驗證、測試集之間的分離。所有基於數據的處理（如標準化、缺失值填充）都應該只基於訓練集的信息來學習，然後應用到驗證集和測試集。交叉驗證的每一折 (fold) 也必須維持這種分離。

*   **錯誤 2：在不平衡數據集上使用 Accuracy**
    *   **描述：** 當一個類別的樣本數量遠多於另一個類別時（如 95% 負類，5% 正類），即使模型將所有樣本都預測為負類，也能達到 95% 的 Accuracy。這是一種虛假的「高效能」。
    *   **澄清：** 對於不平衡數據集，應優先使用 Precision、Recall、F1-Score、AUC-ROC 等指標，這些指標更能反映模型對稀有類別的識別能力。

*   **錯誤 3：只關注單一指標**
    *   **描述：** 過分依賴一個單一指標，而忽略了其他可能重要的方面。例如，過分追求高 Recall 而導致大量 False Positive。
    *   **澄清：** 應根據應用場景和業務目標，綜合考慮多個評估指標。理解每個指標的優缺點及其背後的意義。例如，在醫療診斷中，漏診（FN）的成本可能遠高於誤診（FP），因此 Recall 會比 Precision 更受重視。

*   **錯誤 4：缺乏基線 (Baseline) 比較**
    *   **描述：** 沒有與簡單的、傳統的或現有的方法進行比較，使得模型的效能提升難以被客觀衡量。
    *   **澄清：** 總是設定一個合理的基線模型（例如，隨機猜測、最頻繁類別預測、簡單的統計模型等），並評估您的 AI 模型相對於基線的提升。這有助於證明模型的價值。

*   **錯誤 5：過度優化驗證集 (Overfitting to Validation Set)**
    *   **描述：** 在超參數調優和模型選擇階段，反覆在驗證集上進行測試和調整，導致模型在驗證集上表現很好，但在從未見過的測試集上表現不佳。
    *   **澄清：** 驗證集應用於超參數調優和初步模型選擇，但測試集應該只在模型開發的最後階段，且僅用於一次最終評估。如果需要多次測試，考慮使用多個測試集或更魯棒的交叉驗證策略。

---

## 4.6 小練習（附詳解）

### 小練習 1：分類指標計算

假設您訓練了一個模型來預測某個電子郵件是否為垃圾郵件。在測試集上，模型得到了以下結果：

*   實際為垃圾郵件，模型預測為垃圾郵件：80 封
*   實際為垃圾郵件，模型預測為正常郵件：20 封
*   實際為正常郵件，模型預測為垃圾郵件：10 封
*   實際為正常郵件，模型預測為正常郵件：890 封

請計算該模型的 Accuracy, Precision, Recall, F1-Score。

**步驟：**

1.  建立混淆矩陣。
2.  識別 TP, FN, FP, TN 的值。
3.  使用公式計算各項指標。

**詳解：**

1.  **建立混淆矩陣 (假設「垃圾郵件」為正類別)：**

    |               | 預測為垃圾郵件 (P) | 預測為正常郵件 (N) |
    | :------------ | :------------------ | :------------------ |
    | **實際為垃圾郵件**  | 80 (TP)             | 20 (FN)             |
    | **實際為正常郵件**  | 10 (FP)             | 890 (TN)            |

2.  **識別 TP, FN, FP, TN：**
    *   $TP = 80$
    *   $FN = 20$
    *   $FP = 10$
    *   $TN = 890$
    *   總樣本數 $N = TP + FN + FP + TN = 80 + 20 + 10 + 890 = 1000$

3.  **計算各項指標：**
    *   **Accuracy (準確率)：**
        $$ \text{Accuracy} = \frac{TP + TN}{N} = \frac{80 + 890}{1000} = \frac{970}{1000} = 0.97 \text{ 或 } 97\% $$
    *   **Precision (精確度)：**
        $$ \text{Precision} = \frac{TP}{TP + FP} = \frac{80}{80 + 10} = \frac{80}{90} \approx 0.8889 \text{ 或 } 88.89\% $$
    *   **Recall (召回率)：**
        $$ \text{Recall} = \frac{TP}{TP + FN} = \frac{80}{80 + 20} = \frac{80}{100} = 0.80 \text{ 或 } 80\% $$
    *   **F1-Score (F1 分數)：**
        $$ \text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = 2 \times \frac{0.8889 \times 0.80}{0.8889 + 0.80} = 2 \times \frac{0.71112}{1.6889} \approx 0.8412 \text{ 或 } 84.12\% $$

### 小練習 2：選擇合適的評估指標

假設您正在為一個心臟病診斷系統開發 AI 模型。這個系統的目標是從病人的醫療數據中，預測他們是否患有心臟病。

請考慮以下兩種情境，並說明您會優先關注哪個評估指標，以及為什麼：

1.  **情境 A：** 醫院資源有限，您希望盡可能減少對未患病者的誤診，以避免不必要的進一步檢查和心理負擔。
2.  **情境 B：** 醫院面臨心臟病患者的早期診斷挑戰，您希望盡可能找出所有患病者，即使這意味著少量健康的人會被誤診。

**步驟：**

1.  理解兩種情境的側重點。
2.  回顧 Precision 和 Recall 的定義及其應用場景。
3.  根據情境，選擇並解釋最合適的指標。

**詳解：**

1.  **理解情境：**
    *   **正類別 (Positive Class)：** 患有心臟病
    *   **負類別 (Negative Class)：** 未患心臟病
    *   **FP (False Positive)：** 將未患病者診斷為患病者（誤診）
    *   **FN (False Negative)：** 將患病者診斷為未患病者（漏診）

2.  **回顧指標：**
    *   **Precision (精確度)：** 衡量預測為正類別的樣本中，真正為正類別的比例。高 Precision 意味著低 FP。
    *   **Recall (召回率)：** 衡量實際為正類別的樣本中，被模型成功識別為正類別的比例。高 Recall 意味著低 FN。

3.  **選擇與解釋：**

    *   **情境 A (減少誤診，避免不必要的檢查)：**
        *   **優先關注的指標：** **Precision (精確度)**
        *   **原因：** 在這個情境下，醫院希望避免將未患病者誤診為患病者 (FP)，因為這會導致不必要的侵入性檢查、醫療資源的浪費以及病人的精神壓力。高 Precision 意味著在模型預測有病的人中，真正有病的比例很高，從而減少了誤診 (FP) 的數量。

    *   **情境 B (盡可能找出所有患病者，早期診斷)：**
        *   **優先關注的指標：** **Recall (召回率)**
        *   **原因：** 在這個情境下，早期發現所有心臟病患者是首要任務，漏診 (FN) 的後果可能比誤診 (FP) 更嚴重（例如，延誤治療可能危及生命）。高 Recall 意味著模型能夠成功識別出絕大多數的實際患病者，即使這可能伴隨著一些健康個體的誤診 (FP)。在醫療領域，特別是對於嚴重疾病，通常會優先追求高 Recall 以降低漏診的風險。

---

## 4.7 延伸閱讀 / 參考

*   **機器學習教科書：**
    *   [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) by Aurélien Géron (提供實作層面的評估範例)
    *   [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James et al. (提供統計學習理論下的評估方法)
*   **公平性與偏差：**
    *   [公平性、可解釋性、責任制 (Fairness, Accountability, and Transparency in AI)](https://fatconference.org/) - 相關學術會議與資源。
    *   [Google AI Blog: What is Responsible AI?](https://blog.google/technology/ai/responsible-ai-principles/)
*   **穩健性與對抗性學習：**
    *   [Adversarial Examples in the Physical World](https://arxiv.org/abs/1607.02533)
    *   [CleverHans Library](https://github.com/cleverhans-lab/cleverhans) - 專門用於對抗性機器學習的 Python 庫。
*   **生成式模型評估：**
    *   [BLEU: a Method for Automatic Evaluation of Machine Translation](https://www.aclweb.org/anthology/P02-1040.pdf)
    *   [ROUGE: A Package for Automatic Evaluation of Summaries](https://aclanthology.org/W04-1013.pdf)