### 8-1 數據調理與增強

#### 核心概念：為什麼我們需要數據調理與增強？

在機器學習與深度學習領域，數據是模型表現的基石。「垃圾進，垃圾出」(Garbage In, Garbage Out) 這句話深刻揭示了數據品質的重要性。原始數據往往充滿雜訊、遺失值、不一致的格式，或是數量不足以訓練出穩健的模型。為了解決這些問題，我們需要「數據調理」與「數據增強」這兩大關鍵技術。

-   **定義/核心觀念**
    -   **數據調理 (Data Conditioning / Data Preprocessing)**：指的是對原始數據進行一系列預處理操作，使其更乾淨、一致、規範化，並轉換成適合機器學習模型輸入的格式。它關注於提升數據的「品質」與「可用性」。
    -   **數據增強 (Data Augmentation)**：指的是透過對現有數據進行轉換或生成新的變體，以擴大訓練數據集的大小和多樣性。它關注於增加數據的「數量」與「多樣性」，以提高模型的泛化能力。

-   **目的**
    -   **提升數據品質**：透過清洗、正規化等步驟，減少數據中的錯誤與噪音，使模型能夠學習到更真實的模式。
    -   **擴大數據量**：當數據量稀缺時，數據增強能有效增加訓練樣本，避免模型過擬合，並提高其在未見數據上的表現。
    -   **改善模型效能**：無論是數據調理還是增強，其最終目標都是為了讓模型能夠更有效率地學習，並產出更準確、更穩健的預測。

-   **與相鄰概念的關聯**
    數據調理與增強是機器學習工作流程中「數據準備」階段的核心環節，與「特徵工程」(Feature Engineering) 緊密相關。特徵工程是從原始數據中提取或創建新的特徵，而數據調理則確保這些特徵的品質與格式適合模型，數據增強則可能在此基礎上擴展特徵空間的樣本。兩者都是為了讓模型能夠從數據中學習到更多有價值的資訊。

-----

#### 數據調理 (Data Conditioning)

數據調理是任何機器學習專案不可或缺的第一步。它確保了數據的「健康」狀態，為後續的模型訓練打下堅實基礎。

##### 1. 數據清洗 (Data Cleaning)

-   **定義/核心觀念**
    數據清洗旨在識別並修正或移除數據中的錯誤、不一致、遺失值、異常值和重複值，確保數據的完整性、一致性和準確性。

-   **例子或推導**
    -   **缺失值處理 (Missing Values)**：
        -   **核心觀念**：當數據集中某些特徵的值遺失時，模型無法直接處理。
        -   **方法**：
            1.  **刪除**：如果缺失值佔比很小，或某一行/列缺失值過多，可以選擇刪除整行或整列。
            2.  **填充**：
                -   **統計量填充**：用該特徵的平均值 (Mean)、中位數 (Median) 或眾數 (Mode) 填充。
                -   **預測填充**：使用其他特徵訓練一個模型來預測缺失值。
                -   **固定值填充**：用一個常數（如0）填充。
        -   **例子**：考慮一個 `年齡` 特徵，其中包含缺失值。若使用中位數填充，先計算所有已知年齡的中位數，然後用該值替換所有缺失的年齡。

    -   **異常值處理 (Outliers)**：
        -   **核心觀念**：異常值是數據集中與大多數數據點顯著不同的值，它們可能是數據輸入錯誤，也可能是真實但極端的事件。異常值可能對模型訓練產生負面影響。
        -   **方法**：
            1.  **識別**：
                -   **統計方法**：使用標準差 (Standard Deviation) (例如：超出平均值 $\pm 3\sigma$)、四分位距 (IQR) (例如：超出 $Q1 - 1.5 \times IQR$ 或 $Q3 + 1.5 \times IQR$)。
                -   **可視化**：箱形圖 (Box Plot)、散佈圖 (Scatter Plot)。
            2.  **處理**：
                -   **刪除**：移除含有異常值的數據點。
                -   **截斷/轉換**：將異常值替換為鄰近的非異常最大/最小值，或對數據進行對數轉換等。
        -   **例子**：在房價數據集中，一間價值數億的豪宅可能是異常值。如果模型目標是預測普通住宅價格，則可能需要將其截斷或移除。

    -   **重複值處理 (Duplicates)**：
        -   **核心觀念**：數據集中存在完全相同的記錄，可能導致模型過度學習。
        -   **方法**：識別並移除重複的數據行。
        -   **例子**：客戶數據庫中，同一位客戶的資訊被輸入了兩次。

-   **與相鄰概念的關聯**
    數據清洗是數據調理的第一步，它直接影響後續轉換和縮放的有效性。沒有乾淨的數據，任何精巧的數據轉換都可能建立在錯誤的基礎上。

##### 2. 數據轉換與編碼 (Data Transformation & Encoding)

-   **定義/核心觀念**
    數據轉換是指改變數據的格式或結構，使其更適合模型的處理；數據編碼則是將非數值型數據轉換為數值型表示。

-   **例子或推導**
    -   **類別變數編碼 (Categorical Variable Encoding)**：
        -   **核心觀念**：機器學習模型通常只能處理數值型數據。
        -   **方法**：
            1.  **標籤編碼 (Label Encoding)**：將每個唯一的類別值映射到一個整數。例如，`['紅', '綠', '藍']` 變成 `[0, 1, 2]`。適用於類別之間存在序關係的情況（如：小、中、大）。
            2.  **獨熱編碼 (One-Hot Encoding)**：將每個類別變數轉換為多個二進制（0或1）特徵。例如，`['紅', '綠', '藍']` 變成 `[1,0,0], [0,1,0], [0,0,1]`。適用於類別之間沒有序關係的情況，避免模型錯誤地推斷序關係。
        -   **例子**：一個包含 `城市` (City) 特徵的數據集，如 `['台北', '高雄', '台中']`。若使用獨熱編碼，會創建三個新特徵 `is_台北`, `is_高雄`, `is_台中`。

    -   **特徵工程 (Feature Engineering)**：
        -   **核心觀念**：從原始數據中創建新的特徵，以提高模型的性能。這可以涉及到組合現有特徵、從時間戳中提取資訊等。
        -   **例子**：
            -   **組合特徵**：將 `長度` 和 `寬度` 結合，創建 `面積` 特徵。
            -   **時間序列特徵**：從 `日期` 欄位中提取 `年份`、`月份`、`星期幾`、`是否為週末`。

-   **與相鄰概念的關聯**
    數據轉換是將原始數據變成模型可以理解的語言，它是特徵工程的實踐部分。良好的數據轉換可以極大地簡化模型學習的任務，有時甚至比更複雜的模型本身更能提升性能。

##### 3. 數據縮放與正規化 (Data Scaling & Normalization)

-   **定義/核心觀念**
    數據縮放是指調整數據的數值範圍，以防止某些特徵因其數值範圍過大而主導模型訓練，特別是對基於距離或梯度的算法至關重要。

-   **例子或推導**
    -   **最小-最大正規化 (Min-Max Scaling)**：
        -   **核心觀念**：將數據縮放到一個固定的範圍，通常是 $[0, 1]$ 或 $[-1, 1]$。
        -   **公式**：
            $$X_{normalized} = \frac{X - X_{min}}{X_{max} - X_{min}}$$
        -   **適用場景**：當數據分佈不明確，且希望數據維持在特定範圍內時。對異常值敏感。
        -   **例子**：一個年齡特徵的範圍是 $[10, 80]$。使用 Min-Max Scaling 後，10歲會變成0，80歲會變成1，其他年齡按比例縮放。

    -   **標準化 (Standardization / Z-score Normalization)**：
        -   **核心觀念**：將數據轉換為平均值為0、標準差為1的標準正態分佈。
        -   **公式**：
            $$X_{standardized} = \frac{X - \mu}{\sigma}$$
            其中 $\mu$ 是特徵的平均值，$\sigma$ 是特徵的標準差。
        -   **適用場景**：當數據可能包含異常值，或許多算法（如SVM、邏輯迴歸、神經網路）需要特徵服從標準正態分佈時。對異常值不那麼敏感。
        -   **例子**：將 `收入` 特徵進行標準化。如果平均收入是5萬，標準差是1萬，那麼7萬的收入將變成 $\frac{70000 - 50000}{10000} = 2$。

-   **與相鄰概念的關聯**
    數據縮放是數據調理的最後一步，確保了所有特徵在模型眼中具有「公平」的權重。它直接影響到梯度下降的收斂速度、距離度量的準確性以及許多模型（如支持向量機、K近鄰）的表現。

-----

#### 數據增強 (Data Augmentation)

數據增強是一種強大的技術，特別是在深度學習領域，當訓練數據量不足以防止過擬合時，它能透過生成新的數據變體來擴大訓練集。

##### 1. 圖像數據增強 (Image Data Augmentation)

-   **定義/核心觀念**
    透過對圖像進行一系列隨機但合理的幾何變換、色彩調整等操作，生成視覺上不同但語義上相同的圖像，以增加模型的泛化能力。

-   **例子或推導**
    -   **幾何變換**：
        -   **翻轉 (Flipping)**：水平翻轉（常用於非方向性物體，如貓狗），垂直翻轉（較少用，除非場景允許）。
        -   **旋轉 (Rotation)**：隨機旋轉一定角度（如 $ \pm 15^\circ$）。
        -   **縮放 (Scaling)**：放大或縮小圖像。
        -   **裁剪 (Cropping)**：隨機裁剪圖像的一部分，然後重新縮放回原始尺寸。常用於隨機採樣圖像不同區域。
        -   **平移 (Translation)**：在水平或垂直方向上移動圖像。
    -   **色彩變換**：
        -   **亮度/對比度調整 (Brightness/Contrast Adjustment)**：隨機改變圖像的亮度或對比度。
        -   **飽和度/色調調整 (Saturation/Hue Adjustment)**：改變圖像的飽和度或色調。
    -   **隨機擦除 (Random Erasing)**：在圖像上隨機遮擋一個矩形區域。
    -   **範例**：一張貓的圖片，經過水平翻轉後，仍然是貓；經過微小旋轉後，也仍然是貓。這些變體可以作為新的訓練樣本。

-   **與相鄰概念的關聯**
    圖像增強直接作用於原始圖像數據，擴大了訓練集的規模和多樣性，這對於預防過擬合和提高卷積神經網絡 (CNN) 等模型的魯棒性至關重要。它與數據調理中的特徵工程有異曲同工之妙，都是為了讓模型看到更多「有效」的數據。

##### 2. 文本數據增強 (Text Data Augmentation)

-   **定義/核心觀念**
    透過詞彙替換、句法變換等方式，生成語義上相似但表達形式不同的文本，以擴大訓練集，提高自然語言處理 (NLP) 模型的魯棒性。

-   **例子或推導**
    -   **同義詞替換 (Synonym Replacement)**：用詞語的同義詞替換句子中的隨機詞語。
        -   **例子**：原始句子：「這部**電影**非常**精彩**。」增強後：「這部**影片**非常**出色**。」
    -   **隨機插入/刪除/交換詞 (Random Insertion/Deletion/Swap)**：
        -   **插入**：隨機在句子中插入同義詞或不影響語義的詞。
        -   **刪除**：隨機刪除句子中的詞語。
        -   **交換**：隨機交換句子中兩個詞語的位置。
    -   **回譯 (Back Translation)**：將原始文本翻譯成另一種語言，然後再翻譯回原始語言。這通常會產生語法上略有不同但語義相似的句子。
        -   **例子**：中文 → 英文 → 中文。
    -   **上下文詞替換 (Contextual Word Replacement)**：使用預訓練的語言模型（如BERT）根據上下文來替換詞語。

-   **與相鄰概念的關聯**
    文本增強是NLP領域的特定數據增強技術，旨在解決文本數據量不足的問題。它與文本的預處理（如分詞、去除停用詞）和特徵提取（如詞向量）相輔相成。

##### 3. 音頻數據增強 (Audio Data Augmentation) (簡述)

-   **定義/核心觀念**
    透過改變音頻的頻率、時間特性或引入噪音，來生成新的音頻樣本，提高語音識別、音樂分類等模型的性能。

-   **例子**
    -   **變速 (Time Stretching)**：不改變音高而改變音頻播放速度。
    -   **變調 (Pitch Shifting)**：不改變速度而改變音頻音高。
    -   **添加背景噪音 (Adding Background Noise)**：將不同類型的噪音（如白噪音、環境音）疊加到原始音頻上。
    -   **頻率遮罩 (Frequency Masking) / 時間遮罩 (Time Masking)**：隨機遮蔽音頻頻譜圖的某些頻率或時間區域（類似於圖像的隨機擦除）。

-----

#### 常見錯誤與澄清

-   **誤區一：數據調理「一次性」完成即可。**
    -   **澄清**：數據調理是一個迭代的過程。在模型訓練初期，可能會進行初步的調理。然而，當模型表現不佳時，往往需要回溯到數據調理階段，重新審視缺失值處理策略、異常值閾值或不同的數據縮放方法。有時，特徵工程的結果也可能促使數據調理的調整。

-   **誤區二：數據增強是萬靈丹，越多越好。**
    -   **澄清**：雖然數據增強能有效擴大數據集，但並非越多越好。不當的增強策略可能引入無用的噪音，甚至生成與真實數據分佈差異過大的「假」數據，從而誤導模型學習錯誤的模式。例如，將人臉圖像垂直翻轉（頭朝下）通常是無效的增強。增強的種類和程度應根據任務和數據特性謹慎選擇，並依賴領域知識。

-   **誤區三：數據調理和數據增強可以互相替代。**
    -   **澄清**：兩者目的不同，數據調理是基礎，數據增強是錦上添花。數據調理主要處理數據本身的「健康」問題（缺失、錯誤、不一致），確保數據是可用的。數據增強則是在數據可用且乾淨的基礎上，旨在擴大數據的「規模」和「多樣性」。你不能用數據增強來解決數據品質問題（如用增強來填補缺失值），也無法用數據調理來彌補數據量嚴重不足的問題。

-----

#### 小練習 (附詳解)

##### 小練習一：數據調理 - 缺失值與標準化

你得到一個包含客戶資訊的數據集，其中包含 `年齡 (Age)` 和 `收入 (Income)` 兩欄。請完成以下任務：

1.  檢查 `年齡` 欄位是否有缺失值。若有，請使用該欄位的**中位數**填充。
2.  對處理完缺失值的 `年齡` 欄位和 `收入` 欄位進行**標準化**。

**原始數據 (Python 字典形式)**：
```python
data = {
    '客戶ID': [1, 2, 3, 4, 5, 6, 7, 8],
    '年齡': [25, 30, None, 45, 22, 50, None, 35],
    '收入': [50000, 60000, 45000, 80000, 40000, 90000, 55000, 70000]
}
```

**詳解**：

1.  **導入必要的函式庫**
    ```python
    import pandas as pd
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    ```

2.  **創建 DataFrame**
    ```python
    data = {
        '客戶ID': [1, 2, 3, 4, 5, 6, 7, 8],
        '年齡': [25, 30, np.nan, 45, 22, 50, np.nan, 35], # 使用np.nan表示缺失值
        '收入': [50000, 60000, 45000, 80000, 40000, 90000, 55000, 70000]
    }
    df = pd.DataFrame(data)
    print("原始 DataFrame:\n", df)
    ```
    **輸出**：
    ```
    原始 DataFrame:
        客戶ID    年齡      收入
    0       1  25.0   50000
    1       2  30.0   60000
    2       3   NaN   45000
    3       4  45.0   80000
    4       5  22.0   40000
    5       6  50.0   90000
    6       7   NaN   55000
    7       8  35.0   70000
    ```

3.  **處理缺失值**
    *   計算 `年齡` 欄位的中位數。
    *   使用中位數填充 `年齡` 欄位的缺失值。
    ```python
    median_age = df['年齡'].median()
    df['年齡'].fillna(median_age, inplace=True)
    print("\n填充缺失值後的 DataFrame:\n", df)
    ```
    **推導**：
    `年齡` 欄位的有效值為 `[25, 30, 45, 22, 50, 35]`。排序後為 `[22, 25, 30, 35, 45, 50]`。
    中位數是 `(30 + 35) / 2 = 32.5`。
    **輸出**：
    ```
    填充缺失值後的 DataFrame:
        客戶ID    年齡      收入
    0       1  25.0   50000
    1       2  30.0   60000
    2       3  32.5   45000
    3       4  45.0   80000
    4       5  22.0   40000
    5       6  50.0   90000
    6       7  32.5   55000
    7       8  35.0   70000
    ```

4.  **對 `年齡` 和 `收入` 進行標準化**
    *   選擇需要標準化的欄位。
    *   初始化 `StandardScaler`。
    *   對選定的欄位進行 `fit_transform`。
    ```python
    features_to_scale = ['年齡', '收入']
    scaler = StandardScaler()
    df[features_to_scale] = scaler.fit_transform(df[features_to_scale])
    print("\n標準化後的 DataFrame:\n", df)
    ```
    **輸出** (數值會有浮點誤差，以下為示意)：
    ```
    標準化後的 DataFrame:
        客戶ID       年齡       收入
    0       1 -1.040188 -0.890871
    1       2 -0.443907 -0.370488
    2       3 -0.145767 -1.146063
    3       4  1.040188  0.650280
    4       5 -1.390494 -1.395755
    5       6  1.636470  1.170664
    6       7 -0.145767 -0.635679
    7       8  0.152066  0.129896
    ```
    **結果分析**：`年齡` 和 `收入` 欄位現在的平均值接近0，標準差接近1。

##### 小練習二：數據增強 - 圖像翻轉與旋轉 (概念性)

你有一張簡單的 3x3 圖像（用數字矩陣表示）。請完成以下任務：

1.  對原始圖像進行**水平翻轉**。
2.  對原始圖像進行**順時針旋轉90度**。

**原始圖像矩陣**：
```
[[1, 2, 3],
 [4, 5, 6],
 [7, 8, 9]]
```

**詳解**：

1.  **表示原始圖像**
    ```python
    import numpy as np

    image = np.array([
        [1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]
    ])
    print("原始圖像:\n", image)
    ```
    **輸出**：
    ```
    原始圖像:
     [[1 2 3]
     [4 5 6]
     [7 8 9]]
    ```

2.  **水平翻轉 (Horizontal Flip)**
    *   每一行的元素順序反轉。
    ```python
    horizontal_flipped_image = np.fliplr(image) # 或者 image[:, ::-1]
    print("\n水平翻轉後的圖像:\n", horizontal_flipped_image)
    ```
    **推導**：
    第一行 `[1, 2, 3]` 翻轉後變成 `[3, 2, 1]`。
    第二行 `[4, 5, 6]` 翻轉後變成 `[6, 5, 4]`。
    第三行 `[7, 8, 9]` 翻轉後變成 `[9, 8, 7]`。
    **輸出**：
    ```
    水平翻轉後的圖像:
     [[3 2 1]
     [6 5 4]
     [9 8 7]]
    ```

3.  **順時針旋轉90度 (Rotate 90 Degrees Clockwise)**
    *   將圖像的行變成列，並反轉新列的順序。
    ```python
    rotated_image = np.rot90(image, k=-1) # k=-1 表示逆時針90度，等同於順時針270度，或使用 np.transpose 和 np.fliplr 組合
    # 更直接的順時針90度旋轉 (先轉置，再垂直翻轉)
    rotated_image_clockwise = np.flipud(image.T)
    print("\n順時針旋轉90度後的圖像:\n", rotated_image_clockwise)
    ```
    **推導**：
    原始圖像轉置 (transpose) 後：
    ```
    [[1, 4, 7],
     [2, 5, 8],
     [3, 6, 9]]
    ```
    然後垂直翻轉 (flipud)：
    第一行 `[1, 4, 7]` 變為 `[3, 6, 9]` (原轉置的最後一行)
    第二行 `[2, 5, 8]` 變為 `[2, 5, 8]` (原轉置的第二行)
    第三行 `[3, 6, 9]` 變為 `[1, 4, 7]` (原轉置的第一行)
    **輸出**：
    ```
    順時針旋轉90度後的圖像:
     [[7 4 1]
     [8 5 2]
     [9 6 3]]
    ```

-----

#### 延伸閱讀/參考

-   **數據預處理基礎**
    -   Géron, Aurélien. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems* (2nd ed.). O'Reilly Media. (特別是第2章「End-to-End Machine Learning Project」和第3章「Classification」中的數據準備部分)。
    -   VanderPlas, Jake. (2016). *Python Data Science Handbook: Essential Tools for Working with Data*. O'Reilly Media. (特別是Pandas和Scikit-Learn的相關章節)。

-   **圖像數據增強**
    -   Shorten, C., & Khoshgoftaar, T. M. (2019). A survey on image data augmentation for deep learning. *Journal of Big Data*, 6(1), 1-48. (對於圖像增強技術的全面概述)。
    -   Albumentations 函式庫：一個快速且靈活的圖像增強開源函式庫，支援多種常見的圖像增強操作。

-   **文本數據增強**
    -   Wei, J., & Zou, K. (2019). EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. *arXiv preprint arXiv:1901.11196*. (介紹了簡單但有效的文本增強技術)。
    -   `nlpaug` 函式庫：一個專為NLP數據增強設計的開源函式庫。

-   **音頻數據增強**
    -   `librosa` 和 `audiomentations` 函式庫：提供多種音頻處理和增強功能。