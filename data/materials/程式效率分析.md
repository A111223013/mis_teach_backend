### 第一章：程式效率分析導論

#### 為什麼要分析程式效率？

**核心觀念：**
在軟體開發中，程式碼的功能性固然重要，但其執行效率也同樣關鍵。分析程式效率的目的，是為了了解程式在處理不同規模輸入時，所需消耗的「資源」。這些資源主要指時間（執行速度）和空間（記憶體使用量）。資源是有限的，低效率的程式不僅會導致使用者體驗不佳，更可能增加系統營運成本，甚至造成系統崩潰。

**例子：**
想像一個網路購物平台，如果搜尋商品需要數十秒，顧客很快就會流失。又例如，一個處理大數據的應用程式，如果其排序演算法的效率低下，可能需要數小時甚至數天才能完成一個任務，這在實際應用中是無法接受的。因此，預先評估並優化程式效率，是軟體工程師的核心技能之一。

**與相鄰概念的關聯：**
程式效率分析與「演算法設計」和「資料結構」緊密相關。一個好的演算法搭配合適的資料結構，是達成高效率程式的基石。在設計演算法時，效率分析是評估不同解決方案優劣的標準。

-----

#### 什麼是程式效率？

**核心觀念：**
程式效率主要透過兩個指標來衡量：

1.  **時間複雜度 (Time Complexity)：**
    衡量程式執行時間隨著輸入資料規模（通常表示為 $N$）增長而變化的趨勢。它並非指絕對的執行時間（因為這受限於硬體、編譯器、作業系統等因素），而是指操作數量的增長模式。

2.  **空間複雜度 (Space Complexity)：**
    衡量程式在執行過程中所需記憶體空間隨著輸入資料規模 $N$ 增長而變化的趨勢。這包括程式本身的指令、常數、變數以及遞迴呼叫堆疊等所需的空間。

**定義：**
時間複雜度與空間複雜度通常使用「漸進分析 (Asymptotic Analysis)」來表示，即當輸入規模 $N$ 趨近於無限大時，程式效率的變化趨勢。最常用的符號是 **大 O 符號 (Big O Notation)**，它描述了演算法執行時間或空間使用的「上界」或「最差情況」的增長率。

-----

### 第二章：時間複雜度與漸進分析

#### 時間複雜度核心概念： Big O 符號 (Big O Notation)

**定義：**
大 O 符號 $O(g(N))$ 用來表示一個演算法的執行時間或空間需求，在輸入規模 $N$ 趨於無限大時，其增長率不會超過 $g(N)$ 的某個常數倍。它描述了最壞情況下的性能上限。
數學上，如果存在常數 $c > 0$ 和 $N_0 > 0$，使得對於所有的 $N \ge N_0$，都有 $T(N) \le c \cdot g(N)$，則 $T(N)$ 屬於 $O(g(N))$。

**推導：如何從程式碼估算操作次數，並簡化為 Big O 形式**
分析程式碼時，我們通常會計算「基本操作」的次數（例如：賦值、比較、算術運算、函式呼叫等）。然後，將這些操作次數表示為輸入規模 $N$ 的函數 $T(N)$，再套用 Big O 規則進行簡化：

1.  **忽略常數：** $O(c \cdot f(N)) = O(f(N))$。因為常數倍數不影響增長趨勢。
2.  **忽略低階項：** $O(f(N) + g(N))$，如果當 $N$ 很大時 $f(N)$ 的增長速度遠快於 $g(N)$，則 $O(f(N) + g(N)) = O(f(N))$。例如，$O(N^2 + N) = O(N^2)$。

**常見時間複雜度類型：**

*   **$O(1)$ - 常數時間 (Constant Time)：**
    *   **定義：** 執行時間不隨輸入規模 $N$ 的變化而變化。
    *   **例子：** 陣列/列表通過索引存取元素、基本算術運算、變數賦值。
    *   ```python
        def get_first_element(arr):
            return arr[0] # O(1) 操作
        ```

*   **$O(\log N)$ - 對數時間 (Logarithmic Time)：**
    *   **定義：** 執行時間與輸入規模的對數成正比。通常出現在每次操作都將問題規模減半的演算法中。
    *   **例子：** 二元搜尋 (Binary Search)。
    *   **推導：** 每次搜尋都將搜尋範圍縮小一半，從 $N \to N/2 \to N/4 \to \dots \to 1$。假設進行 $k$ 次操作，則 $N/2^k = 1 \Rightarrow N = 2^k \Rightarrow k = \log_2 N$。
    *   ```python
        def binary_search(arr, target):
            left, right = 0, len(arr) - 1
            while left <= right: # 每次迭代，範圍減半
                mid = (left + right) // 2
                if arr[mid] == target:
                    return mid
                elif arr[mid] < target:
                    left = mid + 1
                else:
                    right = mid - 1
            return -1
        ```

*   **$O(N)$ - 線性時間 (Linear Time)：**
    *   **定義：** 執行時間與輸入規模 $N$ 成正比。
    *   **例子：** 遍歷整個陣列/列表、線性搜尋。
    *   ```python
        def sum_array(arr):
            total = 0
            for x in arr: # 迴圈執行 N 次
                total += x
            return total
        ```

*   **$O(N \log N)$ - 線性對數時間 (Linear-Logarithmic Time)：**
    *   **定義：** 執行時間與 $N$ 乘以 $\log N$ 成正比。通常是將問題分解為子問題（$O(\log N)$），每個子問題處理需要 $O(N)$。
    *   **例子：** 合併排序 (Merge Sort)、快速排序 (Quick Sort) 的平均情況。
    *   **推導：** 例如合併排序，分解步驟產生 $\log N$ 層，每層合併操作需要 $O(N)$ 時間。

*   **$O(N^2)$ - 平方時間 (Quadratic Time)：**
    *   **定義：** 執行時間與輸入規模 $N$ 的平方成正比。通常出現在巢狀迴圈中，內層迴圈與外層迴圈都依賴於 $N$。
    *   **例子：** 泡沫排序 (Bubble Sort)、選擇排序 (Selection Sort)、插入排序 (Insertion Sort)。
    *   ```python
        def bubble_sort(arr):
            n = len(arr)
            for i in range(n): # 外層迴圈執行 N 次
                for j in range(0, n - i - 1): # 內層迴圈執行 N-i-1 次 (約 N 次)
                    if arr[j] > arr[j + 1]:
                        arr[j], arr[j + 1] = arr[j + 1], arr[j]
        ```

*   **$O(2^N)$ - 指數時間 (Exponential Time)：**
    *   **定義：** 執行時間隨著 $N$ 的增長呈指數級增長，非常慢。通常表示一種窮舉搜索或遞迴演算法沒有優化。
    *   **例子：** 遞迴計算未經優化的費波那契數列、旅行推銷員問題 (TSP) 的暴力解法。
    *   ```python
        def fibonacci_recursive(n):
            if n <= 1:
                return n
            return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)
        ```
        （此函式重複計算許多子問題，導致效率低下）

*   **$O(N!)$ - 階乘時間 (Factorial Time)：**
    *   **定義：** 執行時間增長速度極快，比指數時間還要慢得多。通常表示對所有可能的排列進行操作。
    *   **例子：** 解決旅行推銷員問題 (TSP) 的暴力解法 (產生所有路徑排列)。

**與相鄰概念的關聯：**
除了 Big O ($O$) 符號（上界，最差情況），還有：
*   **Big Omega ($\Omega$) 符號：** 描述演算法的「下界」或「最佳情況」的增長率。
*   **Big Theta ($\Theta$) 符號：** 當演算法的漸進上界和下界相同時，表示其「緊密界限」或「平均情況」的增長率。
    在實際應用中，Big O 最常用，因為我們通常關注程式在最差情況下的表現。

-----

### 第三章：空間複雜度

#### 空間複雜度核心概念

**定義：**
空間複雜度是衡量一個演算法在執行過程中，除了輸入資料本身所佔用的空間之外，還需要多少額外記憶體空間的指標。它也用 Big O 符號表示，表示隨著輸入規模 $N$ 增長，額外記憶體使用的趨勢。

**種類：**

1.  **輸入空間 (Input Space)：**
    指輸入資料本身所佔用的記憶體空間。這通常不計入演算法的「輔助空間複雜度」，但在計算「總空間複雜度」時會考慮。

2.  **輔助空間 (Auxiliary Space)：**
    指演算法在執行過程中，除了輸入資料外，額外申請的記憶體空間。這是我們通常分析的空間複雜度。

3.  **總空間 (Total Space)：**
    輸入空間 + 輔助空間。

**與時間複雜度的關聯：**
時間和空間效率往往存在權衡 (Trade-off)。有時為了減少執行時間（提高時間效率），我們可能需要使用更多的記憶體空間（降低空間效率）；反之亦然。例如，動態規劃通常會使用一個表格來儲存中間結果，以避免重複計算（降低時間複雜度），但這會增加空間複雜度。

-----

#### 常見空間複雜度分析範例

*   **$O(1)$ - 常數空間 (Constant Space)：**
    *   **定義：** 演算法額外使用的記憶體空間不隨輸入規模 $N$ 的變化而變化。
    *   **例子：**
        ```python
        def swap_elements(arr, i, j):
            # 僅使用幾個固定變數來交換，不隨 N 變化
            temp = arr[i]
            arr[i] = arr[j]
            arr[j] = temp
            return arr
        ```
        大多數「原地 (in-place)」排序算法（如泡沫排序、選擇排序）輔助空間複雜度為 $O(1)$。

*   **$O(N)$ - 線性空間 (Linear Space)：**
    *   **定義：** 演算法額外使用的記憶體空間與輸入規模 $N$ 成正比。
    *   **例子：**
        1.  **複製陣列：**
            ```python
            def copy_array(arr):
                new_arr = []
                for x in arr:
                    new_arr.append(x) # new_arr 的大小與 arr 成正比
                return new_arr
            ```
        2.  **遞迴函式呼叫堆疊：**
            許多遞迴函式（特別是尾遞迴優化不奏效或沒有尾遞迴優化的語言）在遞迴深度與輸入 $N$ 成正比時，其呼叫堆疊會消耗 $O(N)$ 空間。
            ```python
            def factorial_recursive(n):
                if n == 0:
                    return 1
                return n * factorial_recursive(n - 1) # 遞迴深度為 N
            ```

*   **$O(\log N)$ - 對數空間 (Logarithmic Space)：**
    *   **定義：** 演算法額外使用的記憶體空間與輸入規模的對數成正比。
    *   **例子：**
        二元搜尋（非遞迴版本通常是 $O(1)$，但有些遞迴實現其呼叫堆疊可能是 $O(\log N)$）、某些分治演算法。

-----

### 第四章：程式效率分析實戰技巧

#### 如何分析迴圈與遞迴

*   **迴圈：**
    *   **單一迴圈：** 計算迴圈執行多少次。如果迴圈從 0 到 $N-1$ 執行，則是 $O(N)$。
        ```python
        for i in range(N): # 執行 N 次
            # O(1) 操作
        ```
        時間複雜度為 $O(N \times O(1)) = O(N)$。
    *   **巢狀迴圈：** 將內層迴圈的執行次數乘以外層迴圈的執行次數。
        ```python
        for i in range(N): # 外層 N 次
            for j in range(N): # 內層 N 次
                # O(1) 操作
        ```
        時間複雜度為 $O(N \times N \times O(1)) = O(N^2)$。
    *   **對數迴圈：** 如果迴圈控制變數每次迭代都乘以或除以一個常數，則是 $O(\log N)$。
        ```python
        i = 1
        while i < N: # 執行 log N 次
            i *= 2
            # O(1) 操作
        ```
        時間複雜度為 $O(\log N)$。

*   **遞迴：**
    分析遞迴函式的時間複雜度通常需要建立遞迴關係式 (Recurrence Relation)，並解出其 Big O。
    *   **範例：** 費波那契數列 (未優化)
        $T(N) = T(N-1) + T(N-2) + O(1)$
        這個關係式通常會導致 $O(2^N)$ 的複雜度。
    *   **範例：** 二元搜尋
        $T(N) = T(N/2) + O(1)$
        這個關係式會導致 $O(\log N)$ 的複雜度。
    *   **主定理 (Master Theorem)：** 是一個用於解決某些特定形式遞迴關係式（常用於分治演算法）的強大工具，但對於初學者而言可能較為進階。

#### 最佳情況、最差情況與平均情況

*   **最佳情況 (Best Case)：**
    指演算法在最理想的輸入情況下，所需消耗的最小資源。例如，在線性搜尋中，如果目標元素是陣列的第一個，則只需一次比較，時間複雜度為 $O(1)$。通常用 Big Omega ($\Omega$) 符號表示。

*   **最差情況 (Worst Case)：**
    指演算法在最不利的輸入情況下，所需消耗的最大資源。例如，在線性搜尋中，如果目標元素是陣列的最後一個，或者不在陣列中，則需要遍歷整個陣列，時間複雜度為 $O(N)$。這是 Big O 符號通常描述的情況，因為它提供了一個性能上限，保證演算法不會比這個更慢。

*   **平均情況 (Average Case)：**
    指演算法在所有可能輸入情況下，所需消耗資源的平均值。這通常需要對所有輸入的可能性及其概率進行統計分析，計算起來較為複雜。例如，快速排序的平均時間複雜度是 $O(N \log N)$，但其最差情況是 $O(N^2)$。通常用 Big Theta ($\Theta$) 符號表示。

在實際工程中，我們最常關注的是「最差情況」的時間複雜度（即 Big O），因為它能確保程式在任何情況下都不會超過某個可接受的性能閾值。

-----

### 第五章：常見錯誤與澄清

1.  **誤將常數項或低階項計入 Big O：**
    *   **錯誤：** 認為一個迴圈執行 $3N$ 次的操作是 $O(3N)$，或 $N^2 + N$ 是 $O(N^2 + N)$。
    *   **澄清：** Big O 符號關注的是「增長趨勢」。常數因子和低階項在 $N$ 趨於無限大時的影響微乎其微，因此應被忽略。$O(3N)$ 應簡化為 $O(N)$；$O(N^2 + N)$ 應簡化為 $O(N^2)$。

2.  **混淆 Big O、Omega 和 Theta 符號：**
    *   **錯誤：** 隨意將 $O(N)$、$ \Omega(N)$ 和 $\Theta(N)$ 互換。
    *   **澄清：**
        *   $O(N)$ 表示**上界**（不大於某個 $cN$），常用於描述**最差情況**。
        *   $\Omega(N)$ 表示**下界**（不小於某個 $cN$），常用於描述**最佳情況**。
        *   $\Theta(N)$ 表示**緊密界限**（既不大於也不小於某個 $cN$，即在 $c_1N$ 和 $c_2N$ 之間），常用於描述**平均情況**或當最佳和最差情況相同時。
        在日常溝通中，人們常使用 $O(N)$ 來泛指時間複雜度，但精確理解這些符號的差異很重要。

3.  **忽略資料結構對效率的影響：**
    *   **錯誤：** 假設對所有資料結構的操作都有相同的時間複雜度。
    *   **澄清：** 不同的資料結構對相同的操作（例如插入、刪除、查找）有不同的時間複雜度。
        *   在陣列中按索引查找是 $O(1)$，但插入/刪除可能需要 $O(N)$。
        *   在連結列表中按值查找是 $O(N)$，但頭部插入是 $O(1)$。
        *   在雜湊表中查找通常是 $O(1)$（平均情況），但在最差情況下可能退化為 $O(N)$。
        選擇正確的資料結構對整體程式效率至關重要。

4.  **過度優化 (Premature Optimization)：**
    *   **錯誤：** 在程式碼還未完成或瓶頸不明確時，就花費大量時間去優化一些微不足道的效率點。
    *   **澄清：** 「過早優化是萬惡之源」(Premature optimization is the root of all evil)。應先確保程式碼正確、清晰且可維護。只有在確定某個部分是效能瓶頸（透過效能分析工具 Profiler 找出）時，才應該投入資源去優化它。很多時候，程式的瓶頸並不在於你想像的地方。

-----

### 第六章：小練習（附詳解）

#### 小練習 1：分析時間複雜度

請分析以下 Python 函式的時間複雜度 (Big O)：

```python
def example_function_1(n):
    count = 0
    for i in range(n):
        count += 1
    for j in range(n):
        for k in range(n):
            count += 1
    return count
```

**詳解：**

1.  **分析第一個迴圈：**
    *   `for i in range(n):` 這個迴圈會執行 `n` 次。
    *   `count += 1` 是一個 $O(1)$ 的基本操作。
    *   所以，第一個迴圈的總時間複雜度是 $O(n \times 1) = O(n)$。

2.  **分析第二個巢狀迴圈：**
    *   `for j in range(n):` 外層迴圈執行 `n` 次。
    *   `for k in range(n):` 內層迴圈在每次外層迴圈執行時，都會執行 `n` 次。
    *   `count += 1` 是一個 $O(1)$ 的基本操作。
    *   所以，第二個巢狀迴圈的總時間複雜度是 $O(n \times n \times 1) = O(n^2)$。

3.  **合併複雜度：**
    *   整個函式的總時間複雜度是各部分複雜度的和：$O(n) + O(n^2)$。
    *   根據 Big O 的簡化規則（忽略低階項），當 $n$ 很大時，$n^2$ 的增長速度遠大於 $n$。
    *   因此，最終的時間複雜度是 $O(n^2)$。

---

#### 小練習 2：分析空間複雜度

請分析以下 Python 函式的空間複雜度 (Big O)：

```python
def example_function_2(arr):
    if not arr:
        return []
    
    new_list = []
    for x in arr:
        new_list.append(x * 2)
    return new_list
```

**詳解：**

1.  **分析輸入空間：**
    *   輸入 `arr` 是一個列表，其大小為 `N`（假設 `len(arr) == N`）。這部分空間是由函式外部傳入的，通常不計入輔助空間複雜度。

2.  **分析輔助空間：**
    *   `if not arr: return []`：在空列表情況下，只返回一個空列表，佔用 $O(1)$ 空間。
    *   `new_list = []`：初始化一個空列表，佔用 $O(1)$ 空間。
    *   `for x in arr: new_list.append(x * 2)`：這個迴圈會遍歷 `arr` 中的所有 `N` 個元素。每次迭代，一個新的元素 `x * 2` 會被追加到 `new_list` 中。
    *   最終，`new_list` 將會包含 `N` 個元素，因此它佔用的記憶體空間與輸入列表 `arr` 的大小成正比。

3.  **結論：**
    *   由於 `new_list` 的大小取決於輸入 `arr` 的大小 `N`，因此該函式的輔助空間複雜度是 $O(N)$。

-----

### 第七章：延伸閱讀

*   **演算法設計與分析 (Algorithm Design and Analysis)：**
    深入學習各種經典演算法（排序、搜尋、圖論等）的設計原理、複雜度分析方法以及如何選擇和優化。推薦教材如《演算法導論》(Introduction to Algorithms, CLRS)。

*   **資料結構 (Data Structures)：**
    理解不同資料結構（陣列、連結串列、樹、圖、雜湊表等）的內部工作原理以及它們在不同操作（插入、刪除、查找）上的時間和空間複雜度。選擇合適的資料結構是優化程式效率的關鍵。

*   **主定理 (Master Theorem)：**
    對於分析分治演算法的遞迴關係式，主定理是一個非常有用的工具。它可以快速地確定許多遞迴演算法的漸進時間複雜度。

*   **效能測試與分析工具 (Profiling Tools)：**
    在實際應用中，光靠理論分析可能不足以找出所有效能瓶頸。學習使用如 Python 的 `cProfile`、Java 的 VisualVM、或瀏覽器開發者工具中的 Performance 標籤等專業效能分析工具，可以幫助你精確定位程式碼中的熱點 (hotspot)。

*   **攤銷分析 (Amortized Analysis)：**
    某些演算法操作的平均成本會比最壞情況的成本要低得多。攤銷分析可以給出一個操作序列的平均性能保證，而不是單個操作的最壞情況性能。例如，Python 列表中 `append()` 操作的攤銷時間複雜度為 $O(1)$。