# 演算法效率分析

-----

### 緒論：為什麼需要分析演算法效率？

#### 核心觀念：資源消耗與預測

當我們編寫程式時，不僅要確保程式碼能正確執行，更要考慮它執行得「好不好」。演算法效率分析就是一套工具，用來評估演算法在執行時所需耗費的**計算資源**，主要包括：

1.  **時間 (Time Complexity)**：演算法執行完成所需的時間。
2.  **空間 (Space Complexity)**：演算法執行完成所需佔用的記憶體空間。

之所以需要分析效率，是因為它關乎：
*   **效能預測**：在不同規模的輸入下，演算法會有怎樣的表現？
*   **資源管理**：在有限的計算資源下，如何選擇最適合的演算法？
*   **最佳化決策**：當多個演算法都能解決問題時，哪一個更優？
*   **可擴展性 (Scalability)**：當輸入資料量急劇增加時，演算法能否保持可用性？

#### 典型例子：排序演算法

想像一個簡單的排序問題：將 $N$ 個數字從小到大排列。
*   **冒泡排序 (Bubble Sort)**：在最壞情況下，需要比較約 $N^2$ 次。當 $N=1000$ 時，約需 100 萬次操作。
*   **快速排序 (Quick Sort)**：在平均情況下，需要比較約 $N \log N$ 次。當 $N=1000$ 時，約需 $1000 \times \log_2 1000 \approx 1000 \times 10 = 10000$ 次操作。

雖然實際執行的時間還會受硬體、編譯器等因素影響，但從操作次數的**成長趨勢**來看，快速排序在處理大量資料時會顯著快於冒泡排序。這就是效率分析的核心價值：**我們關心的是演算法執行時間或空間消耗隨輸入規模 $N$ 增長的速度，而非絕對值。**

#### 與相鄰概念的關聯

演算法的優劣，除了效率外，還需考量：
*   **正確性 (Correctness)**：演算法是否總能產生預期的正確結果。這是最基本的條件。
*   **可讀性 (Readability)**：程式碼是否易於理解和維護。
*   **健壯性 (Robustness)**：程式碼能否處理無效或異常的輸入。

效率分析與這些因素共同構成了一個「好演算法」的完整定義。一個錯誤但快速的演算法毫無價值；一個正確但慢到無法使用的演算法也解決不了實際問題。

-----

### 時間複雜度 (Time Complexity)

#### 核心概念：基本操作計數與漸進分析

**時間複雜度**衡量的是演算法執行所需要的「操作次數」如何隨著輸入數據量 $N$ 的增加而變化。我們不關心精確的執行時間，因為那受硬體、作業系統、編譯器等環境因素影響，而是關心其**成長趨勢**。

**定義**：
時間複雜度是指演算法執行時間與輸入大小 $N$ 之間的函數關係，通常用**基本操作的執行次數**來表示。

**核心觀念**：
*   **基本操作 (Elementary Operation)**：一個在固定時間內完成的操作，例如：算術運算（加、減、乘、除）、賦值、比較、陣列索引存取等。我們假設這些操作耗時相同（單位時間）。
*   **忽略常數**：我們通常不關心精確的操作次數，因為常數因子會因機器、語言不同而異。例如，$2N$ 和 $N$ 在 $N$ 很大時，其成長趨勢都是線性的。
*   **忽略低次項**：當 $N$ 很大時，高次項對函數成長的影響遠大於低次項。例如，$N^2 + N$ 在 $N$ 很大時，主要由 $N^2$ 項決定。
*   **漸進分析 (Asymptotic Analysis)**：關注當 $N$ 趨近於無限大時，演算法效能的行為。

**例子：基本操作計數**

```cpp
// 範例一：簡單迴圈
void fun1(int N) {
    int sum = 0; // 1 次操作
    for (int i = 0; i < N; i++) { // 迴圈執行 N 次
        sum += i; // N 次操作
    }
    // 總操作次數 T(N) = 1 + N
}
```
對於 `fun1`，當 $N$ 很大時，`N` 項是主導，其時間複雜度趨勢是線性的。

```cpp
// 範例二：巢狀迴圈
void fun2(int N) {
    int count = 0; // 1 次操作
    for (int i = 0; i < N; i++) { // 外層迴圈 N 次
        for (int j = 0; j < N; j++) { // 內層迴圈 N 次
            count++; // N * N 次操作
        }
    }
    // 總操作次數 T(N) = 1 + N * N = N^2 + 1
}
```
對於 `fun2`，當 $N$ 很大時，`N^2` 項是主導，其時間複雜度趨勢是平方的。

#### 大 O 符號 (Big O Notation)

大 O 符號是最常用的漸進符號，它描述了演算法執行時間的**上界 (Upper Bound)**，也就是在**最壞情況 (Worst Case)** 下的效能表現。

**定義**：
給定兩個函數 $f(N)$ 和 $g(N)$，如果存在正的常數 $c$ 和 $N_0$，使得對於所有的 $N \ge N_0$，$f(N) \le c \cdot g(N)$ 成立，則稱 $f(N)$ 屬於 $O(g(N))$。
數學表示：$f(N) = O(g(N))$

**核心觀念**：
*   **忽略常數因子**：$O(2N)$ 等同於 $O(N)$。
*   **忽略低次項**：$O(N^2 + N)$ 等同於 $O(N^2)$。
*   **表示最壞情況**：在設計演算法時，我們通常會關注最壞情況下的效能，因為這確保了演算法在任何情況下都能提供可接受的效能保證。

**例子：大 O 符號的推導**

對於 `fun1`，$T(N) = N + 1$。
我們可以找到 $c=2$ 和 $N_0=1$。當 $N \ge 1$ 時，$N+1 \le 2N$ 成立。
所以，$T(N) = O(N)$。

對於 `fun2`，$T(N) = N^2 + 1$。
我們可以找到 $c=2$ 和 $N_0=1$。當 $N \ge 1$ 時，$N^2+1 \le 2N^2$ 成立。
所以，$T(N) = O(N^2)$。

**推導規則總結**：
1.  **取最高次項**：例如 $N^3 + 2N^2 + 5 = O(N^3)$。
2.  **忽略常數係數**：例如 $5N^3 = O(N^3)$。
3.  **多個操作相加**：如果演算法包含多個連續執行的部分，總時間複雜度是各部分時間複雜度的最大值。
    例如，如果一個部分是 $O(N)$，另一個部分是 $O(N^2)$，則總體是 $O(N^2)$。
4.  **多個操作相乘**：如果演算法包含巢狀結構（例如巢狀迴圈），總時間複雜度是各部分時間複雜度的乘積。
    例如，外層迴圈 $N$ 次，內層迴圈 $N$ 次，則總體是 $O(N \cdot N) = O(N^2)$。

#### 常見時間複雜度類別

以下是一些常見的時間複雜度類別，按效率從高到低（即速度從快到慢）排列：

*   $O(1)$ **常數時間 (Constant Time)**
    *   **定義**：執行時間不隨輸入大小 $N$ 變化。
    *   **例子**：
        *   陣列依索引存取元素：`arr[5]`
        *   基本算術運算：`a = b + c`
        *   判斷奇偶性
    *   無論輸入數據量多大，這些操作的執行時間都是固定的。

*   $O(\log N)$ **對數時間 (Logarithmic Time)**
    *   **定義**：執行時間與輸入大小 $N$ 的對數成正比。通常以 2 為底 ($\log_2 N$)。
    *   **例子**：
        *   **二分搜尋 (Binary Search)**：每次搜尋都將搜尋範圍減半。
        *   平衡二元搜尋樹 (AVL tree, Red-Black tree) 的插入、刪除、搜尋操作。
    *   這類演算法效率很高，即使 $N$ 很大，執行時間也不會增加太多。

*   $O(N)$ **線性時間 (Linear Time)**
    *   **定義**：執行時間與輸入大小 $N$ 成正比。
    *   **例子**：
        *   **線性搜尋 (Linear Search)**：遍歷整個列表尋找元素。
        *   遍歷陣列或列表一次，計算總和或尋找最大值。
        *   列印列表中的所有元素。
    *   $N$ 增加一倍，執行時間也大致增加一倍。

*   $O(N \log N)$ **線性對數時間 (Linearithmic Time)**
    *   **定義**：執行時間與 $N$ 乘以 $N$ 的對數成正比。
    *   **例子**：
        *   **快速排序 (Quick Sort)**、**合併排序 (Merge Sort)** 等高效排序演算法在平均情況下。
        *   堆積排序 (Heap Sort)。
    *   在處理大量數據時，這是非常高效的排序方法。

*   $O(N^2)$ **平方時間 (Quadratic Time)**
    *   **定義**：執行時間與輸入大小 $N$ 的平方成正比。
    *   **例子**：
        *   **冒泡排序 (Bubble Sort)**、**選擇排序 (Selection Sort)**、**插入排序 (Insertion Sort)** 等簡單排序演算法在最壞情況下。
        *   計算所有元素對 (pairs) 的操作（巢狀迴圈）。
    *   當 $N$ 較大時，這種演算法會變得非常慢。

*   $O(N^3)$ **立方時間 (Cubic Time)**
    *   **定義**：執行時間與輸入大小 $N$ 的立方成正比。
    *   **例子**：
        *   三個巢狀迴圈，每個迴圈執行 $N$ 次。
        *   矩陣乘法。
    *   在實際應用中，通常只適用於較小的 $N$ 值。

*   $O(2^N)$ **指數時間 (Exponential Time)**
    *   **定義**：執行時間隨 $N$ 呈指數級增長。
    *   **例子**：
        *   遞迴計算費波那契數列的低效版本。
        *   解決某些組合問題的窮舉法，如旅行推銷員問題 (TSP) 的暴力解法。
    *   這種演算法只能處理非常小規模的輸入。

*   $O(N!)$ **階乘時間 (Factorial Time)**
    *   **定義**：執行時間隨 $N$ 呈階乘級增長。
    *   **例子**：
        *   生成所有排列組合的窮舉法。
    *   這是效率最低的一種，即使 $N$ 很小也會非常慢。

#### 最佳、最差與平均情況 (Best, Worst, and Average Cases)

有些演算法的執行時間不只取決於輸入大小 $N$，還取決於輸入數據的**具體排列方式**。

*   **最差情況 (Worst Case)**：演算法執行時間最長時的輸入。大 O 符號通常描述的就是最差情況下的複雜度，因為它提供了性能的**保證下限**。
*   **最佳情況 (Best Case)**：演算法執行時間最短時的輸入。通常用大 Omega 符號 ($\Omega$) 描述。
*   **平均情況 (Average Case)**：所有可能輸入的平均執行時間。平均情況分析通常更複雜，需要假設輸入數據的分佈。

**例子：線性搜尋**

```cpp
int linear_search(int arr[], int N, int target) {
    for (int i = 0; i < N; i++) {
        if (arr[i] == target) {
            return i;
        }
    }
    return -1;
}
```

*   **最佳情況**：目標元素 `target` 位於陣列的第一個位置。此時，只需要 1 次比較，時間複雜度為 $O(1)$。
*   **最差情況**：目標元素位於陣列的最後一個位置，或者根本不存在於陣列中。此時，需要比較 $N$ 次，時間複雜度為 $O(N)$。
*   **平均情況**：假設目標元素在陣列中每個位置的機率相等，且元素存在的機率為 $p$。則平均比較次數約為 $(N+1)/2$。時間複雜度為 $O(N)$。

-----

### 空間複雜度 (Space Complexity)

#### 核心概念：額外記憶體消耗

**空間複雜度**衡量的是演算法在執行過程中所需佔用的**額外記憶體空間**。與時間複雜度類似，我們也關注其隨輸入大小 $N$ 的成長趨勢，並使用大 O 符號來表示。

**定義**：
空間複雜度是指演算法執行所需額外記憶體空間與輸入大小 $N$ 之間的函數關係。

**核心觀念**：
*   **額外空間**：通常指的是除了輸入數據本身所佔用的空間之外，演算法在執行過程中動態分配或使用的空間。這包括：
    *   **變數**：演算法中聲明的局部變數、臨時變數等。
    *   **數據結構**：演算法為解決問題而創建的輔助數據結構（如陣列、鏈結串列、堆疊、佇列、哈希表等）。
    *   **遞迴堆疊 (Recursion Stack)**：遞迴函式呼叫時，系統為每個呼叫分配的記憶體空間（包含參數、局部變數和返回地址）。
*   **不包含輸入本身**：通常，我們不將輸入數據本身佔用的空間計入空間複雜度，除非題目特別說明。

**例子：空間複雜度分析**

```cpp
// 範例一：O(1) 常數空間
int sum_array(int arr[], int N) {
    int total = 0; // 1 個整數變數，O(1) 空間
    for (int i = 0; i < N; i++) { // 1 個整數變數 i，O(1) 空間
        total += arr[i];
    }
    return total;
}
```
這個函數只使用了固定數量的變數 `total` 和 `i`，它們不隨 $N$ 的增長而改變。因此，空間複雜度為 $O(1)$。

```cpp
// 範例二：O(N) 線性空間
int* copy_array(int arr[], int N) {
    int* new_arr = (int*)malloc(N * sizeof(int)); // 分配一個大小為 N 的整數陣列
    for (int i = 0; i < N; i++) {
        new_arr[i] = arr[i];
    }
    return new_arr;
}
```
這個函數創建了一個新的陣列 `new_arr`，其大小與輸入 $N$ 成正比。因此，空間複雜度為 $O(N)$。

```cpp
// 範例三：遞迴的空間複雜度
long long factorial(int N) {
    if (N == 0) {
        return 1;
    }
    return N * factorial(N - 1); // 每次遞迴呼叫都會在堆疊上佔用空間
}
```
`factorial` 函式是一個遞迴函式。每次遞迴呼叫都會在執行堆疊 (call stack) 上佔用一定的空間，用於儲存函式參數 `N`、局部變數和返回地址。當 `N` 遞減到 0 時，會有 $N$ 層函式呼叫堆疊。因此，其空間複雜度為 $O(N)$。

#### 與時間複雜度分析的關聯

空間複雜度的分析方法與時間複雜度非常相似，也使用大 O 符號。在實際應用中，我們常常需要在時間和空間之間進行權衡 (trade-off)。一個演算法可能會以犧牲空間來換取更快的執行時間，反之亦然。

例如：
*   **合併排序 (Merge Sort)**：時間複雜度為 $O(N \log N)$，但通常需要 $O(N)$ 的額外空間來儲存合併過程中的臨時陣列。
*   **原地排序 (In-place Sort)**：如堆積排序，時間複雜度為 $O(N \log N)$，但空間複雜度通常為 $O(1)$，因為它不需要大量額外空間。

-----

### 數學工具：漸進符號 (Asymptotic Notations)

除了大 O 符號，還有其他兩個重要的漸進符號，用於更精確地描述演算法的效率。

#### 大 O 符號 ($O$)：上界 (Upper Bound)

*   **定義**：$f(N) = O(g(N))$，表示存在正的常數 $c$ 和 $N_0$，使得對於所有的 $N \ge N_0$，$f(N) \le c \cdot g(N)$。
*   **意義**：表示演算法的執行時間**不會比** $g(N)$ 增長得更快。它給出了一個最壞情況的上限。
*   **例子**：
    *   $3N+2 = O(N)$ (因為當 $N \ge 2$ 時，$3N+2 \le 4N$)
    *   $N^2 = O(N^3)$ (嚴格來說這是成立的，但通常我們會尋找更緊密的上界)
    *   $N^2 = O(N^2)$

#### 大 Omega 符號 ($\Omega$)：下界 (Lower Bound)

*   **定義**：$f(N) = \Omega(g(N))$，表示存在正的常數 $c$ 和 $N_0$，使得對於所有的 $N \ge N_0$，$f(N) \ge c \cdot g(N)$。
*   **意義**：表示演算法的執行時間**至少會和** $g(N)$ 增長得一樣快。它給出了一個最佳情況的下限。
*   **例子**：
    *   $3N+2 = \Omega(N)$ (因為當 $N \ge 1$ 時，$3N+2 \ge 1 \cdot N$)
    *   $N^3 = \Omega(N^2)$
    *   $N^2 = \Omega(N^2)$

#### 大 Theta 符號 ($\Theta$)：緊密界 (Tight Bound)

*   **定義**：$f(N) = \Theta(g(N))$，表示存在正的常數 $c_1, c_2$ 和 $N_0$，使得對於所有的 $N \ge N_0$，$c_1 \cdot g(N) \le f(N) \le c_2 \cdot g(N)$。
*   **意義**：表示演算法的執行時間與 $g(N)$ 的增長速度**相同**。它同時給出了上界和下界，提供了最精確的描述。
*   **關聯**：如果 $f(N) = O(g(N))$ **並且** $f(N) = \Omega(g(N))$，那麼 $f(N) = \Theta(g(N))$。
*   **例子**：
    *   $3N+2 = \Theta(N)$
    *   $\frac{1}{2}N^2 - 3N = \Theta(N^2)$
    *   一個排序演算法的平均情況時間複雜度通常用 $\Theta$ 表示。

**總結**：
*   $O$ 給出**上限**：你的演算法最慢也不會超過這個速度。
*   $\Omega$ 給出**下限**：你的演算法最快也達不到比這個更快的速度。
*   $\Theta$ 給出**緊密界**：你的演算法的速度就是這個級別。

在實際分析中，大 O 符號是最常用來描述演算法最壞情況時間複雜度的。

-----

### 常見錯誤與澄清

1.  **只看迴圈次數，忽略內部操作**
    *   **錯誤**：認為 `for (int i = 0; i < N; i++) { func_takes_N_time(); }` 的複雜度是 $O(N)$。
    *   **澄清**：如果 `func_takes_N_time()` 本身需要 $O(N)$ 的時間，那麼總複雜度將是 $O(N \cdot N) = O(N^2)$。總是將內部操作的複雜度也考慮進去。

2.  **混淆 $O, \Omega, \Theta$ 符號**
    *   **錯誤**：認為 $O(N)$ 等同於 $N$。
    *   **澄清**：$O$ 符號表示的是**上界**，例如一個演算法的複雜度可能是 $O(N^2)$，這只說明它不會比 $N^2$ 慢，但它實際上可能是 $O(N)$。我們通常會尋找最緊密的上界。而 $\Theta(N)$ 則表示精確的漸進行為，即 $N$。

3.  **忽略遞迴的複雜度分析**
    *   **錯誤**：只看遞迴函式本身的程式碼，認為它很短所以是 $O(1)$。
    *   **澄清**：遞迴函式會產生呼叫堆疊，其複雜度需要通過遞迴關係式 (Recurrence Relation) 來分析，例如 $T(N) = aT(N/b) + f(N)$。空間複雜度也要考慮遞迴深度。

4.  **誤以為常數因子不重要**
    *   **錯誤**：認為 $O(N)$ 演算法就一定比 $O(N^2)$ 演算法快。
    *   **澄清**：在大 $N$ 的情況下，漸進複雜度是決定性因素。但在小 $N$ 的情況下，常數因子可能非常重要。例如，一個 $1000N$ 的演算法可能比 $0.01N^2$ 的演算法在 $N < 100000$ 時表現更差。只有當 $N$ 達到一定閾值後，漸進複雜度才開始主導。

5.  **只考慮最差情況，忽略平均情況**
    *   **錯誤**：總是認為 $O(N^2)$ 的排序演算法就一定很慢。
    *   **澄清**：例如，快速排序的最差情況是 $O(N^2)$，但其平均情況是 $O(N \log N)$，而且通常常數因子很小，使其在實踐中表現優秀。有些演算法在最差情況下效能很差，但在絕大多數實際應用中的平均情況表現良好。理解演算法在不同情況下的表現很重要。

-----

### 小練習 (附詳解)

#### 練習一：分析時間複雜度

請分析以下 C++ 程式碼片段的時間複雜度，並用大 O 符號表示：

```cpp
void mystery_function(int N) {
    // Part 1
    for (int i = 0; i < N; i++) {
        std::cout << i << std::endl;
    }

    // Part 2
    for (int i = 0; i < N; i++) {
        for (int j = i; j < N; j++) {
            std::cout << i * j << std::endl;
        }
    }

    // Part 3
    int k = 1;
    while (k < N) {
        k *= 2;
        std::cout << k << std::endl;
    }
}
```

**詳解**：

1.  **分析 Part 1**：
    *   外層迴圈從 `i = 0` 執行到 `N-1`，共執行 $N$ 次。
    *   迴圈內部操作 (`std::cout << i << std::endl;`) 為常數時間 $O(1)$。
    *   因此，Part 1 的時間複雜度為 $N \times O(1) = O(N)$。

2.  **分析 Part 2**：
    *   外層迴圈從 `i = 0` 執行到 `N-1`。
    *   內層迴圈 `j` 的起始值取決於 `i`。
        *   當 `i = 0` 時，`j` 從 0 到 `N-1`，執行 $N$ 次。
        *   當 `i = 1` 時, `j` 從 1 到 `N-1`，執行 $N-1$ 次。
        *   ...
        *   當 `i = N-1` 時, `j` 從 `N-1` 到 `N-1`，執行 1 次。
    *   總執行次數為 $N + (N-1) + \dots + 1 = \frac{N(N+1)}{2} = \frac{1}{2}N^2 + \frac{1}{2}N$。
    *   迴圈內部操作 (`std::cout << i * j << std::endl;`) 為常數時間 $O(1)$。
    *   因此，Part 2 的時間複雜度為 $O(N^2)$（忽略低次項和常數係數）。

3.  **分析 Part 3**：
    *   變數 `k` 從 1 開始，每次迴圈都乘以 2 (`k *= 2`)，直到 `k` 大於等於 `N`。
    *   這意味著 `k` 的值序列是 $1, 2, 4, 8, \dots, 2^x \ge N$。
    *   我們需要找到 `x` 的值，使得 $2^x \approx N$，即 $x = \log_2 N$。
    *   迴圈執行大約 $\log_2 N$ 次。
    *   迴圈內部操作 (`k *= 2; std::cout << k << std::endl;`) 為常數時間 $O(1)$。
    *   因此，Part 3 的時間複雜度為 $O(\log N)$。

**最終複雜度**：
整個函式的時間複雜度是各個部分的最大值。
$max(O(N), O(N^2), O(\log N)) = O(N^2)$。

因此，`mystery_function` 的時間複雜度為 $\mathbf{O(N^2)}$。

---

#### 練習二：分析空間複雜度

請分析以下 Python 程式碼片段的空間複雜度，並用大 O 符號表示：

```python
def process_data(data_list):
    # data_list 是一個包含 N 個元素的列表

    # Part 1
    total_sum = 0
    for item in data_list:
        total_sum += item

    # Part 2
    temp_list = []
    for i in range(len(data_list) - 1, -1, -1):
        temp_list.append(data_list[i])

    # Part 3
    # 假設這是一個遞迴函式
    def recursive_sum(arr, index):
        if index < 0:
            return 0
        return arr[index] + recursive_sum(arr, index - 1)
    
    # 呼叫遞迴函式
    final_recursive_sum = recursive_sum(data_list, len(data_list) - 1)

    return total_sum, temp_list, final_recursive_sum
```
**註**：在分析空間複雜度時，我們通常不計入輸入參數 `data_list` 佔用的空間，除非演算法在內部複製了它。

**詳解**：

1.  **分析 Part 1**：
    *   `total_sum`：一個整數變數，佔用 $O(1)$ 空間。
    *   `item`：迴圈迭代器，在每次迭代時佔用 $O(1)$ 空間。
    *   此部分不產生額外隨 $N$ 增長的空間。
    *   因此，Part 1 的空間複雜度為 $O(1)$。

2.  **分析 Part 2**：
    *   `temp_list`：一個新的列表，其大小與輸入 `data_list` 的長度 `N` 成正比。它會複製 `N` 個元素。
    *   `i`：迴圈迭代器，佔用 $O(1)$ 空間。
    *   因此，Part 2 的空間複雜度為 $O(N)$。

3.  **分析 Part 3 (遞迴函式 `recursive_sum`)**：
    *   `recursive_sum` 是一個遞迴函式。當它被呼叫時，系統會在呼叫堆疊 (call stack) 上為每個函式呼叫儲存參數 (`arr`, `index`) 和返回地址等資訊。
    *   遞迴深度：從 `len(data_list) - 1` 到 `-1`，遞迴深度為 `N`。
    *   每個堆疊幀 (stack frame) 佔用 $O(1)$ 空間。
    *   因此，遞迴呼叫所佔用的最大堆疊空間為 $N \times O(1) = O(N)$。
    *   此部分的空間複雜度為 $O(N)$。

**最終複雜度**：
整個函式的空間複雜度是各個部分所佔用的額外空間的最大值（因為這些空間通常是依次或同時存在的，特別是對於遞迴堆疊和動態創建的數據結構）。
$max(O(1), O(N), O(N)) = O(N)$。

因此，`process_data` 的空間複雜度為 $\mathbf{O(N)}$。

-----

### 延伸閱讀/參考

1.  **Master Theorem for Recurrence Relations**：當分析遞迴演算法（如分治法）的時間複雜度時，主定理是一個強大的工具。它提供了一種直接解決形式為 $T(N) = aT(N/b) + f(N)$ 的遞迴關係式的方法。
    *   參考資料：[MIT OpenCourseWare - Introduction to Algorithms - Lecture 4: Recurrences, Solving Recurrences](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-notes/MIT6_046JS15_lec04.pdf)

2.  **Amortized Analysis (攤還分析)**：有時，單次操作的最壞情況複雜度很高，但一系列操作的平均成本卻很低。攤還分析就是用來分析這種情況，給出一個操作序列的平均複雜度。
    *   參考資料：[GeeksforGeeks - Amortized Analysis](https://www.geeksforgeeks.org/amortized-analysis-set-1-introduction/)

3.  **資料結構與演算法經典教材**：
    *   **《演算法導論 (Introduction to Algorithms)》** by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein (通常簡稱 CLRS)：這是演算法領域的聖經，包含了最詳盡的演算法分析方法和實例。
    *   **《演算法 (Algorithms)》** by Robert Sedgewick and Kevin Wayne：另一本經典教材，注重實作和應用。

4.  **複雜度類別 (Complexity Classes)**：深入了解演算法效率，會接觸到計算複雜度理論，如 P、NP、NP-Complete 等複雜度類別，它們探討的是問題本身的固有難度。
    *   參考資料：[Wikipedia - Complexity Class](https://en.wikipedia.org/wiki/Complexity_class)