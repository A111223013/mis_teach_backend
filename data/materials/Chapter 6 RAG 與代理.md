# Chapter 6: RAG 與代理

在大型語言模型 (LLM) 的應用開發中，我們經常面臨知識限制、資訊時效性與幻覺等挑戰。本章將深入探討兩種強大的解決方案：檢索增強生成 (Retrieval-Augmented Generation, RAG) 與 AI 代理 (AI Agent)，並闡述它們如何協同工作，共同拓展 LLM 的能力邊界。

-----

### 1) 核心概念/定義

#### 1.1 什麼是 RAG (Retrieval-Augmented Generation)？

-   **定義：** RAG 是一種結合了**檢索 (Retrieval)** 與 **生成 (Generation)** 的技術，旨在透過從外部知識庫中檢索相關資訊，來增強大型語言模型 (LLM) 的生成能力。它允許 LLM 在生成回應時，不僅依賴其預訓練時學到的參數化知識，還能利用外部的、即時的、特定領域的非參數化知識。

-   **核心觀念：**
    -   **彌補知識盲區：** LLM 的知識是其訓練資料的快照，存在時效性與特定領域知識的不足。RAG 透過外部知識庫補充了這一點。
    -   **減少幻覺 (Hallucination)：** LLM 有時會「編造」事實上不存在的資訊。RAG 提供事實依據，使生成內容更可信、準確。
    -   **可解釋性：** 由於回答基於檢索到的具體文檔片段，使用者可以追溯資訊來源，提高信任度。
    -   **數據隱私與控制：** 敏感或專有資料無需納入 LLM 訓練，只需存儲於受控的知識庫中。

#### 1.2 什麼是 AI 代理 (AI Agent)？

-   **定義：** AI 代理是一個能夠**感知環境、規劃行動、執行動作並從結果中學習**的實體。它不僅僅是單純的回應使用者指令，而是能夠自主地執行一系列步驟來達成複雜目標，甚至能夠自我修正與迭代。

-   **核心觀念：**
    -   **感知 (Perception)：** 代理能夠接收並理解環境的輸入（例如：使用者查詢、工具輸出、數據流）。
    -   **規劃 (Planning)：** 代理能夠分析其目標，並分解為一系列子任務或步驟，決定如何達成目標。這通常涉及基於 LLM 的「思考」過程。
    -   **行動 (Action)：** 代理能夠執行具體的動作，例如調用外部工具 (APIs)、生成回應、修改內部狀態等。
    -   **反思/學習 (Reflection/Learning)：** 代理能夠評估其行動的結果，判斷是否成功，並從中學習以優化未來的規劃和行動。
    -   **工具使用 (Tool Use)：** 這是代理的關鍵能力，允許 LLM 超越其文本生成限制，與外部世界互動，如搜尋網路、執行程式碼、訪問資料庫等。

-----

### 2) 典型例子與轉換/推導

#### 2.1 RAG 的工作流程與實作考量

RAG 的核心思想是在 LLM 生成答案前，先從一個大型的外部資料庫中檢索出與使用者查詢最相關的資訊片段，然後將這些資訊作為上下文，連同原始查詢一起提供給 LLM，讓 LLM 基於這些額外資訊來生成回答。

-   **工作流程：**
    1.  **資料預處理 (Data Preprocessing)：**
        -   收集原始資料 (文件、網頁、數據庫記錄)。
        -   將資料分割成較小的、有意義的**文本區塊 (Chunks)**。Chunking 策略至關重要，需考慮區塊大小、重疊部分等，以確保每個區塊包含足夠的上下文但又不會過大。
        -   將每個文本區塊轉換為其對應的**向量嵌入 (Vector Embeddings)**。這通常使用預訓練的嵌入模型 (如 OpenAI `text-embedding-ada-002`, Google `text-embedding-004`) 完成。
        -   將這些向量嵌入與原始文本區塊一同儲存到**向量資料庫 (Vector Database)** 中。
    2.  **使用者查詢 (User Query)：**
        -   使用者提出一個問題或指令。
        -   將使用者查詢也轉換為向量嵌入。
    3.  **檢索 (Retrieval)：**
        -   使用查詢向量在向量資料庫中進行**相似性搜尋 (Similarity Search)**，找出與查詢向量最相似的 $k$ 個文本區塊。這些區塊被認為是與使用者問題最相關的資訊。
        -   **(可選) 重新排名 (Re-ranking)：** 對檢索到的初步結果進行二次排序，以提高相關性和多樣性。
    4.  **增強提示詞 (Prompt Augmentation)：**
        -   將原始使用者查詢與檢索到的 $k$ 個相關文本區塊結合，構建一個增強後的提示詞 (Prompt)。通常結構為：「請根據以下提供的參考資訊來回答問題：[相關文本區塊] 問題：[原始查詢]」。
    5.  **生成 (Generation)：**
        -   將增強後的提示詞發送給大型語言模型 (LLM)。
        -   LLM 根據這些上下文資訊生成最終回答。

-   **實作考量：**
    -   **Chunking 策略：** 影響檢索的精確度和效率。常見方法有固定大小、基於語句、遞迴分割等。
    -   **Embedding 模型選擇：** 需選擇與任務和資料類型匹配的模型，影響檢索結果的品質。
    -   **向量資料庫：** 選擇合適的向量資料庫 (如 Pinecone, Weaviate, Chroma, Faiss, Milvus) 來高效儲存和查詢向量。
    -   **提示詞工程：** 即使有好的檢索結果，也需要設計有效的提示詞來引導 LLM 利用這些資訊。
    -   **成本與延遲：** 檢索步驟會增加額外延遲和成本，需平衡系統性能。

#### 2.2 代理的結構與決策機制

AI 代理的強大之處在於其能夠執行多步驟的推理和行動。其核心通常是一個 LLM，充當代理的「大腦」。

-   **基本結構：**
    -   **LLM (語言模型核心)：** 作為代理的「大腦」，負責理解目標、進行推理、規劃行動、執行決策和生成回應。
    -   **工具集 (Toolbox)：** 代理可以調用的外部功能或 API 集合，例如網路搜尋、計算器、程式碼解釋器、資料庫查詢介面等。
    -   **記憶 (Memory)：**
        -   **短期記憶 (Short-term Memory)：** 主要指當前對話的上下文或當前任務的執行狀態，確保對話連貫性。
        -   **長期記憶 (Long-term Memory)：** 代理從過去的經驗中學習到的知識或策略，幫助代理改進未來的決策。可以透過向量資料庫儲存經驗記憶。

-   **決策機制 (思考/行動循環)：**
    AI 代理的行為通常遵循一個迭代的「觀察-思考-行動」循環，以 ReAct (Reasoning + Acting) 模式最為典型。

    1.  **觀察 (Observation)：** 代理接收來自環境的輸入，例如使用者查詢、工具執行結果、錯誤訊息等。
    2.  **思考 (Thought)：** LLM 分析當前觀察，結合其目標和記憶，進行推理：
        -   我現在的目標是什麼？
        -   我應該採取什麼行動來實現這個目標？
        -   我需要使用哪個工具？應該給這個工具什麼參數？
        -   我的下一步是什麼？
        -   我是否已經達到目標？
    3.  **行動 (Action)：** 根據「思考」的結果，代理執行一個具體的動作。這可能是：
        -   **工具調用 (Tool Call)：** 選擇並調用工具集中的某個工具，將必要的參數傳遞給它。
        -   **生成回應 (Generate Response)：** 如果代理認為已達到目標，則直接生成回應給使用者。
        -   **內部狀態更新 (Internal State Update)：** 更新記憶或任務進度。
    4.  **結果觀察 (Observation of Result)：** 代理接收到行動的結果（例如工具的輸出、API 的響應、程式碼執行結果、或錯誤訊息）。這個結果又會作為下一次「觀察」的輸入，循環往復，直到達成目標或無法繼續。

    這種循環使得代理能夠逐步解決複雜問題，並在過程中根據工具的響應調整其策略。

-----

### 3) 與相鄰概念的關聯

#### 3.1 RAG 與傳統檢索系統的差異

傳統的檢索系統 (如搜尋引擎、文檔檢索系統) 主要目標是根據用戶查詢返回相關的文檔列表或文檔片段。使用者需要自己閱讀這些結果，從中提取資訊。

-   **檢索方式：** 傳統檢索依賴關鍵字匹配、TF-IDF、BM25 等。RAG 則依賴語義搜索，透過向量相似度匹配，能理解查詢的深層含義。
-   **輸出形式：** 傳統檢索返回原始文檔或連結。RAG 的最終輸出是 LLM 生成的、整合了檢索資訊的**自然語言回答**。
-   **處理複雜性：** RAG 不僅能找到資訊，還能對資訊進行總結、歸納和推理，提供更直接、連貫的答案。
-   **目標：** 傳統檢索旨在「找到資訊」。RAG 旨在「基於資訊生成答案」。

#### 3.2 代理與 RAG 的關係：代理如何利用 RAG

RAG 可以看作是 AI 代理能力集中的一個強大「工具」或「模組」。代理和 RAG 的關係是互補和協作的。

-   **RAG 作為代理的工具：** 當代理在執行其任務（例如回答使用者問題、完成某項調查）時，如果發現自身缺乏某方面的知識或需要最新資訊，它可以**調用 RAG 系統作為一個工具**。代理會構造一個問題，將其發送給 RAG 工具，並將 RAG 返回的增強資訊用於其後續的思考和行動。
    -   **例子：** 代理的任務是「回答關於最新的 AI 趨勢」。代理可能會首先調用一個 RAG 工具，查詢其知識庫中關於「AI 趨勢」的最新文檔，然後利用 RAG 返回的資訊來生成回答。
-   **RAG 增強代理的知識與記憶：** RAG 可以作為代理長期記憶或知識獲取機制的一部分。代理在規劃和思考時，可以透過 RAG 系統獲取其訓練時未包含的、或需要實時更新的知識，從而提升其決策的準確性和深度，減少「幻覺」。
-   **RAG 提升代理的可解釋性與可靠性：** 透過 RAG，代理在回答某些問題時可以引用具體的檢索來源，這有助於使用者驗證資訊的準確性，提升代理的透明度和可靠性。

#### 3.3 代理與 Function Calling 的關係

-   **Function Calling 是代理實現工具使用的基礎機制之一。** 許多現代 LLM (如 OpenAI 的 GPT-3.5/4 系列、Google 的 Gemini) 提供 `function calling` (或 `tool use`) 能力。這意味著 LLM 不僅能生成自然語言文本，還能生成結構化的 JSON 輸出，明確建議調用哪個函數 (或工具) 以及傳遞哪些參數。
-   **代理的執行器 (Executor) 解析 Function Calling：** 當 LLM 作為代理的大腦，在「思考」階段決定需要調用一個工具時，它會輸出一個 `function call` 的結構。代理框架中的執行器會捕捉這個輸出，解析 JSON，然後實際調用後端定義好的工具函數，並將工具的輸出返回給 LLM 進行下一次「觀察」和「思考」。
-   **Function Calling 是底層實現，代理是高層概念：** Function Calling 提供了一種標準化的方式，讓 LLM 能夠與外部世界互動。而 AI 代理則是一個更廣泛的概念，它利用 Function Calling (以及其他機制，如記憶、規劃邏輯) 來實現更複雜、更自主的行為。可以說，Function Calling 是代理實現其「行動」步驟的關鍵技術之一。

-----

### 4) 進階內容

#### 4.1 RAG 的進階策略

-   **查詢擴展 (Query Expansion)：**
    -   **問題重寫 (Query Rewriting)：** LLM 先分析使用者原始查詢，將其改寫為更適合檢索的幾種變體，然後對所有變體進行檢索，融合結果。
    -   **子問題生成 (Sub-question Generation)：** 對於複雜問題，LLM 可以將其分解為幾個子問題，分別進行 RAG 檢索，再將所有檢索結果整合成最終答案。
-   **多階段 RAG (Multi-hop RAG)：**
    -   第一次檢索可能只找到部分資訊。LLM 根據第一次檢索結果提出新的、更精確的問題，進行第二次甚至多次檢索，逐步完善對複雜問題的理解。
-   **RAG-Fusion / HyDE (Hypothetical Document Embeddings)：**
    -   **HyDE：** LLM 首先基於原始查詢「假想」一個可能包含答案的文檔，然後將這個假想文檔的嵌入用於檢索，而不是直接使用查詢的嵌入。
    -   **RAG-Fusion：** 透過 LLM 生成多個查詢變體，對每個變體進行向量檢索，然後將所有檢索結果合併，並進行重新排名。
-   **優化 Chunking 策略：**
    -   **元數據篩選 (Metadata Filtering)：** 每個文本區塊可以附帶元數據（如文件類型、日期、作者、主題），檢索時可根據元數據進行初步篩選，提高相關性。
    -   **父子 Chunking (Parent-Child Chunking)：** 檢索時先找到較小的、精確匹配的「子塊」，然後回溯到包含該子塊的完整「父塊」或更多上下文，以提供更全面的資訊。
-   **實時 RAG (Real-time RAG)：** 結合 streaming API 或低延遲檢索，使檢索到的內容能更快地影響 LLM 的生成過程，特別適用於需要最新資訊的場景。
-   **評估指標：**
    -   **檢索評估：** Recall (召回率), Precision (精確率), Hit Rate, MRR (平均倒數排名)。
    -   **生成評估：** Faithfulness (忠實性/事實依據), Answer Relevancy (答案相關性), Context Relevancy (上下文相關性)。

#### 4.2 代理的進階應用與挑戰

-   **多代理協作 (Multi-Agent Systems)：**
    -   將複雜任務分解為多個子任務，每個子任務由一個專門的 AI 代理負責。這些代理之間可以協商、溝通和協作，共同完成目標。例如，一個代理負責資料蒐集，一個代理負責分析，一個代理負責報告生成。
-   **自主代理 (Autonomous Agents)：**
    -   代理能夠在沒有人類持續干預的情況下，設定自己的目標、規劃行動、執行任務並從結果中學習。例如，AutoGPT 和 BabyAGI 嘗試實現這種高度自主的行為。
-   **記憶與學習機制：**
    -   更精巧的長期記憶管理，不只是簡單的檢索，還包括知識圖譜構建、經驗提取和通用化，讓代理能真正從經驗中「學習」。
    -   反思 (Reflection) 機制讓代理能夠檢討過去的錯誤，並改進其規劃策略。
-   **工具的動態選擇與生成：**
    -   代理不僅能使用預定義的工具，甚至能夠根據需求動態地生成或修改工具。
-   **代理的安全性與倫理挑戰：**
    -   **誤用工具：** 代理可能會以非預期或有害的方式使用工具。
    -   **無限循環：** 代理可能陷入不斷嘗試而無法達成目標的循環。
    -   **偏見傳播：** 如果訓練資料或工具本身存在偏見，代理可能會放大這些偏見。
    -   **缺乏人類監督：** 高度自主的代理可能執行超出人類預期的行動。
-   **評估代理的性能：**
    -   由於代理的行為複雜且非確定性高，評估其性能是一個巨大挑戰。需要設計能夠衡量目標達成率、效率、安全性和魯棒性的綜合指標。

-----

### 5) 常見錯誤與澄清

#### 5.1 RAG 的常見錯誤

-   **Chunking 不當：**
    -   **錯誤：** 文本區塊過小，導致上下文不足；或區塊過大，導致檢索不精確或超出 LLM 的上下文視窗限制。
    -   **澄清：** 應根據內容類型和 LLM 的上下文視窗動態調整 chunking 策略，並考慮區塊間的重疊以確保語義連貫性。
-   **Embedding 模型與任務不匹配：**
    -   **錯誤：** 使用通用嵌入模型處理高度專業或小眾領域的資料，導致語義匹配效果差。
    -   **澄清：** 選擇針對特定領域或語言優化的嵌入模型，或考慮微調 (fine-tune) 嵌入模型以提高相關性。
-   **忽略重新排名 (Re-ranking)：**
    -   **錯誤：** 直接使用向量搜尋排名前 $k$ 的結果，而不進一步優化。向量相似度不完全等於語義相關度。
    -   **澄清：** 在初次檢索後，應用更精密的重新排名模型 (如交叉編碼器 Cross-Encoders) 來提高結果的精確度和相關性。
-   **提示詞工程不佳：**
    -   **錯誤：** 即使檢索到高品質的資訊，LLM 也無法有效利用，因為提示詞沒有明確指示 LLM 如何使用這些資訊。
    -   **澄清：** 提示詞應清晰地引導 LLM，例如「請根據以下提供的資訊來回答問題，如果資訊中沒有提到，請說明無法回答。」
-   **過度依賴檢索結果而忽略 LLM 自身知識：**
    -   **錯誤：** 有時 LLM 自身就擁有正確的知識，但 RAG 系統強行要求它只根據檢索結果回答，可能限制其能力。
    -   **澄清：** 設計彈性的 RAG 策略，讓 LLM 在檢索結果不足或不確定時，可以適當利用其內部知識，或者明確指出資訊來源。

#### 5.2 代理的常見錯誤

-   **工具設計不當：**
    -   **錯誤：** 工具粒度過大（一個工具承擔太多功能）或過小（需要調用多個微小工具才能完成一個簡單任務），或缺乏必要的工具。
    -   **澄清：** 工具應設計為清晰、獨立、功能明確的模組，並提供全面的工具集，以滿足代理達成目標所需的一切操作。
-   **LLM 的規劃能力不足：**
    -   **錯誤：** LLM 在複雜任務中難以進行多步驟推理，導致決策循環中斷或錯誤，無法有效利用工具。
    -   **澄清：** 使用更強大的 LLM，或透過提示詞工程（如 CoT - Chain of Thought, ReAct 框架）增強其推理和規劃能力。
-   **未能有效處理工具失敗：**
    -   **錯誤：** 代理在工具調用失敗時無法從錯誤中恢復，可能陷入無限循環或直接崩潰。
    -   **澄清：** 設計魯棒的錯誤處理機制，讓代理能夠感知錯誤訊息，反思失敗原因，並嘗試替代方案或向用戶尋求澄清。
-   **缺乏有效的記憶機制：**
    -   **錯誤：** 代理無法從過去的經驗中學習，或在長對話中忘記上下文，導致重複操作或前後矛盾。
    -   **澄清：** 整合短期記憶（如對話緩衝）和長期記憶（如向量資料庫儲存的經驗或知識圖譜），幫助代理保持上下文和學習。
-   **無限循環 (Hallucination Loop)：**
    -   **錯誤：** 代理在工具調用和觀察之間陷入循環，例如反覆嘗試使用無效工具，或生成相似的錯誤回應。
    -   **澄清：** 在代理的「思考」過程中加入循環檢測和終止條件，例如最大步驟數、重複觀察檢測、或明確的成功/失敗判斷條件。

-----

### 6) 小練習 (附詳解)

#### 6.1 小練習一：設計 RAG 系統

-   **題目：** 假設你正在為一家新創公司建立一個內部知識庫問答系統。該公司有大量的技術文件（如產品手冊、API 文檔、內部開發規範，格式包括 PDF 和 Markdown）。你需要設計一個能夠提供準確、及時答案的系統，幫助工程師快速找到所需資訊。請設計一個 RAG 系統的核心組件和工作流程。

-   **步驟：**
    1.  **選擇資料源與資料預處理策略：** 如何獲取這些文件？如何將它們處理成適合 RAG 的形式？
    2.  **選擇 Embedding 模型：** 選擇哪種類型的 Embedding 模型？為什麼？
    3.  **選擇向量資料庫：** 選擇哪個向量資料庫？考慮其特性。
    4.  **描述檢索與生成流程：** 完整描述從使用者提問到獲得答案的過程。

-   **詳解：**
    1.  **資料源與資料預處理策略：**
        -   **資料獲取：** 建立一個自動化爬蟲或監聽服務，定期從公司內部文件伺服器、Git 倉庫（存放 Markdown）和文件共享平台（存放 PDF）同步新文件。
        -   **資料解析：**
            -   **PDF 處理：** 使用 OCR (光學字元識別) 技術將 PDF 轉換為可讀文本，或使用 `PyPDF` 等函式庫提取文本。
            -   **Markdown 處理：** 直接解析 Markdown 文件，提取文本內容。
        -   **Chunking 策略：** 考慮採用「語義分割」或「遞迴分割」。
            -   對於技術文檔，通常一個「概念」或「章節」是較好的塊。可以先按標題、段落分割，確保每個塊包含完整的語義單元。
            -   設定合理的塊大小 (例如 500-1000 個字元) 和重疊部分 (例如 10%-20%)，以防止資訊被切斷。
        -   **元數據提取：** 提取文件標題、作者、創建日期、修改日期、所屬產品線、關鍵詞等元數據，儲存與每個文本區塊關聯。
    2.  **選擇 Embedding 模型：**
        -   **選擇：** 考慮使用 OpenAI 的 `text-embedding-ada-002` 或 `text-embedding-3-small/large` (若預算允許，且需要更高性能)，或是開源的如 `BGE` (BAAI General Embedding) 系列模型。
        -   **理由：** 這些模型在通用語義理解方面表現優秀，並且支援多語言（若技術文檔可能包含多種語言），能準確捕捉技術文檔中的專業術語和概念關係。
    3.  **選擇向量資料庫：**
        -   **選擇：** 可以選擇基於雲服務的託管向量資料庫，如 **Pinecone** 或 **Weaviate**，它們提供高可用性、可擴展性。若考慮開源和內部部署，則可選 **Chroma** (輕量級，易於使用) 或 **Milvus** (大規模部署)。
        -   **理由：**
            -   **Pinecone/Weaviate：** 提供索引優化、實時更新、方便的 API 介面、較高的查詢性能，適合企業級應用。
            -   **Chroma/Milvus：** 若預算有限或需要完全掌控數據，它們提供靈活的部署選項和強大的向量搜尋功能。
        -   **功能考量：** 需支援高效的 k-NN (k-Nearest Neighbors) 搜尋、元數據篩選。
    4.  **描述檢索與生成流程：**
        -   **使用者提問：** 工程師透過前端介面輸入問題，例如「如何使用公司的內部 CI/CD 工具進行部署？」
        -   **查詢嵌入：** 系統將使用者問題使用與資料預處理時相同的 Embedding 模型轉換為查詢向量。
        -   **向量檢索：** 將查詢向量發送到向量資料庫，搜尋最相似的 $k$ 個文本區塊 (例如 $k=5$)。同時利用元數據篩選，例如可以限定只在「CI/CD」相關的文件中搜尋。
        -   **重新排名 (可選但推薦)：** 對於檢索到的前 $k$ 個結果，使用一個更精細的交叉編碼器 (Cross-Encoder) 或 LLM 進行相關性重新排名，選出最相關的 2-3 個文本區塊。
        -   **提示詞構建：** 將原始問題和重新排名後的相關文本區塊，構建成一個增強後的提示詞：
            ```markdown
            "您是一位資深技術顧問，請根據以下提供的技術文檔片段來回答問題。如果文檔中沒有足夠的資訊，請禮貌地告知。

            [文件片段 1]
            [文件片段 2]
            [文件片段 3]

            問題：如何使用公司的內部 CI/CD 工具進行部署？"
            ```
        -   **LLM 生成：** 將增強後的提示詞發送給一個強大的 LLM (例如 GPT-4 或 Llama 3)，由 LLM 生成連貫、準確的回答。
        -   **結果展示：** 將 LLM 生成的回答展示給工程師，並可附上檢索到的原始文件來源連結，以供核實。

-----

#### 6.2 小練習二：設計代理行為

-   **題目：** 設計一個 AI 代理，其目標是幫助使用者預訂飯店。這個代理需要能夠處理使用者提供的各種資訊（地點、日期、預算、偏好，例如「帶寵物」或「有健身房」），並最終完成預訂或提供建議。

-   **步驟：**
    1.  **識別代理所需的核心能力（工具）。**
    2.  **描述代理的決策循環（思考、行動）。**
    3.  **考慮如何處理不完整或模糊的查詢。**

-   **詳解：**
    1.  **識別代理所需的核心能力（工具）：**
        -   **飯店搜尋工具 (`search_hotels`):**
            -   **功能：** 根據地點、入住日期、退房日期、人數、預算範圍、設施偏好等篩選條件，查詢可用的飯店列表。
            -   **參數：** `location` (string), `check_in_date` (string, YYYY-MM-DD), `check_out_date` (string, YYYY-MM-DD), `guests` (integer), `min_price` (float, 可選), `max_price` (float, 可選), `amenities` (list of strings, 可選，如 "pet_friendly", "gym", "pool")。
            -   **輸出：** 飯店列表 (包含飯店名稱、地址、評分、價格、可用設施等)。
        -   **飯店詳情工具 (`get_hotel_details`):**
            -   **功能：** 獲取特定飯店的詳細資訊（如圖片、評論、房間類型、取消政策）。
            -   **參數：** `hotel_id` (string)。
            -   **輸出：** 特定飯店的詳細資訊。
        -   **飯店預訂工具 (`book_hotel`):**
            -   **功能：** 完成飯店預訂。
            -   **參數：** `hotel_id` (string), `room_type` (string), `check_in_date` (string), `check_out_date` (string), `guest_name` (string), `payment_info` (string/object)。
            -   **輸出：** 預訂確認訊息或錯誤訊息。
        -   **日期處理工具 (`parse_date`):**
            -   **功能：** 將自然語言描述的日期（如「下週三」、「明天」）轉換為標準 YYYY-MM-DD 格式。
            -   **參數：** `date_string` (string)。
            -   **輸出：** `standardized_date` (string, YYYY-MM-DD)。
        -   **(可選) 評分查詢工具 (`get_reviews`):**
            -   **功能：** 查詢特定飯店的用戶評論。
            -   **參數：** `hotel_id` (string)。

    2.  **描述代理的決策循環（思考、行動）：**
        -   **目標：** 幫助使用者預訂飯店或提供合適建議。
        -   **決策循環 (ReAct 模式)：**

            1.  **觀察 (Observation)：** 接收使用者輸入，例如：「我想在紐約預訂一間帶寵物的飯店，下週一入住，住兩晚，預算 200 到 300 美元。」

            2.  **思考 (Thought)：** LLM 分析輸入。
                -   「使用者想預訂飯店。我需要：地點 (紐約)、入住日期 (下週一)、退房日期 (入住後兩晚)、預算 (200-300)、偏好 (帶寵物)。目前入住和退房日期是自然語言，需要轉換。」
                -   **Action：** 調用 `parse_date` 工具將「下週一」轉換為具體日期。

            3.  **觀察 (Observation)：** `parse_date` 工具返回結果，例如「下週一轉換為 2024-10-21」。
                -   **思考 (Thought)：** LLM 分析：
                    -   「已獲得具體入住日期 (2024-10-21)，退房日期是兩晚後 (2024-10-23)。所有必要參數都已獲取或推導。」
                    -   **Action：** 調用 `search_hotels` 工具。

            4.  **觀察 (Observation)：** `search_hotels` 工具返回結果，例如：
                -   `[{'hotel_id': 'H101', 'name': 'Pet Paradise Inn', 'price': 250, 'rating': 4.5, 'amenities': ['pet_friendly', 'gym']}, ...]`
                -   **思考 (Thought)：** LLM 分析：
                    -   「找到了一些符合條件的飯店。我應該將結果呈現給使用者，詢問他們是否有進一步的偏好，或者直接推薦最合適的飯店。」
                    -   **Action：** 生成回應給使用者：「我在紐約為您找到幾家符合條件的帶寵物飯店。其中 'Pet Paradise Inn' 評分 4.5，每晚 250 美元，有健身房。您是否想了解更多資訊或查看其他選項？」

            5.  **觀察 (Observation)：** 使用者回應：「聽起來不錯，請幫我預訂 Pet Paradise Inn 的標準房。」

            6.  **思考 (Thought)：** LLM 分析：
                -   「使用者決定預訂 'Pet Paradise Inn'。我需要確認房間類型、使用者姓名和付款資訊。」
                -   **Action：** 生成回應給使用者：「好的，請提供您的全名和付款方式，以便我為您預訂 Pet Paradise Inn 的標準房。」

            7.  **觀察 (Observation)：** 使用者提供所需資訊。

            8.  **思考 (Thought)：** LLM 分析：
                -   「已獲得所有預訂所需資訊。」
                -   **Action：** 調用 `book_hotel` 工具。

            9.  **觀察 (Observation)：** `book_hotel` 工具返回預訂確認訊息。
                -   **思考 (Thought)：** LLM 分析：
                    -   「預訂成功。任務完成。」
                    -   **Action：** 生成回應給使用者：「恭喜！您的 Pet Paradise Inn 預訂已成功，確認號碼是 XXXX。祝您旅途愉快！」

    3.  **考慮如何處理不完整或模糊的查詢：**
        -   **追問機制：** 當使用者查詢缺乏關鍵資訊（如地點、日期、預算）時，代理應主動追問，引導使用者提供完整訊息。
            -   **例子：** 使用者：「我想預訂飯店。」
            -   **代理：** 「好的，請問您想在哪個城市預訂？預計什麼時候入住和退房呢？」
        -   **預設值/上下文推斷：** 某些情況下，如果使用者沒有明確說明，代理可以根據對話上下文或預設值進行推斷。例如，如果之前對話一直在討論紐約的飯店，則可推斷地點為紐約。
        -   **選項提供：** 如果查詢模糊或有多個可能的解釋，代理可以提供多個選項讓使用者選擇。
            -   **例子：** 使用者：「我想找一家舒適的飯店。」
            -   **代理：** 「您對『舒適』的定義是什麼呢？是需要有 spa 服務、高評分、還是特定的房間設施呢？」
        -   **逐步引導：** 將複雜的查詢分解為簡單的步驟，一步步引導使用者完成資訊輸入。

-----

### 7) 延伸閱讀/參考

-   **RAG 相關：**
    -   **原始論文：** Patrick Lewis et al. "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." *NeurIPS 2020.* (https://arxiv.org/abs/2005.11472)
    -   **RAG 框架：**
        -   **LangChain：** 一個流行的 LLM 應用開發框架，內建 RAG 模組和工具。
        -   **LlamaIndex：** 另一個專注於 LLM 數據框架，提供多種 RAG 策略。
    -   **向量資料庫：**
        -   **Pinecone** (https://www.pinecone.io/)
        -   **Weaviate** (https://weaviate.io/)
        -   **Chroma** (https://www.trychroma.com/)
        -   **FAISS** (Facebook AI Similarity Search) (https://github.com/facebookresearch/faiss)

-   **AI 代理相關：**
    -   **ReAct 論文：** Shunyu Yao et al. "Reasoning with React: Synergizing Reasoning and Acting in Language Models." *ICLR 2023.* (https://arxiv.org/abs/2210.03629)
    -   **OpenAI Function Calling 文件：** (https://platform.openai.com/docs/guides/function-calling)
    -   **開源代理框架：**
        -   **LangChain Agents：** LangChain 框架中的代理模組。
        -   **AutoGPT：** 一個早期展示自主代理能力的開源專案。
        -   **BabyAGI：** 另一個著名的自主代理實驗專案。
    -   **Google Gemini Tools / Function Calling 文件：** (https://ai.google.dev/docs/guides/function_calling)

-   **綜合資源：**
    -   **"Generative AI with Large Language Models" on Coursera (DeepLearning.AI)：** 包含 RAG 和代理的基礎知識和實踐。
    -   **Hugging Face Blog on RAG：** (https://huggingface.co/blog/retrieval-augmented-generation)
    -   **Lilian Weng's Blog on LLM-powered Autonomous Agents：** (https://lilianweng.github.io/posts/2023-06-23-agent/)