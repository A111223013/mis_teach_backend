# 2-1 訓練數據與建模

機器學習的核心在於讓機器從數據中學習。在這個過程中，「訓練數據」扮演了機器學習的老師，而「建模」則是學生學習、歸納知識的過程。本章將深入探討這兩個核心概念，以及它們之間密不可分的關係。

-----

### 2-1-1 核心概念：訓練數據 (Training Data)

#### 定義與重要性

訓練數據（Training Data）是指用於訓練機器學習模型的數據集合。機器學習模型透過分析這些數據，學習其中的模式、關聯性與規律，以便未來能夠對新的、未見過的數據做出預測或判斷。

訓練數據的品質、數量和代表性，直接決定了模型學習的效果與其最終性能的上限。就好比學生學習，如果老師教導的教材有誤、不完整或與實際情況脫節，學生再怎麼努力也難以學好。因此，訓練數據是整個機器學習流程中，最基礎也最關鍵的要素之一。

#### 組成要素

一般而言，訓練數據由兩大部分組成：

1.  **特徵 (Features) 或輸入變數 ($X$)**：這些是模型用來學習、做出判斷的屬性或變數。它們是數據的描述性資訊。
2.  **目標 (Target) 或輸出變數 ($y$)**：這是模型試圖預測或輸出的結果。在監督式學習中，訓練數據必須包含目標變數，以便模型學習特徵與目標之間的映射關係。

**例子：房價預測**

假設我們希望建立一個模型來預測房屋的價格。

*   **特徵 ($X$)** 可能包括：房屋面積、房間數量、所在地區、屋齡、是否臨近捷運站等。
*   **目標 ($y$)** 則是：房屋的實際成交價格。

模型會從大量的房屋數據中，學習這些特徵如何影響房價的模式，例如：面積越大，價格越高；臨近捷運站的房屋比遠離捷運站的貴。

#### 數據類型與挑戰

訓練數據可以呈現多種形式：

*   **數值數據 (Numerical Data)**：如年齡、收入、溫度、面積等，可以是連續型或離散型。
*   **類別數據 (Categorical Data)**：如性別（男/女）、地區（東區/西區）、產品類別等，通常表示為有限個離散值。
*   **文字數據 (Text Data)**：如評論、文章、郵件內容等。
*   **圖像數據 (Image Data)**：如照片、X光片等。
*   **時間序列數據 (Time Series Data)**：如股票價格、氣溫變化等，數據具有時間先後順序。

在實際應用中，訓練數據往往伴隨著許多挑戰：

*   **數據量不足**：數據太少，模型可能無法學到足夠的通用模式。
*   **數據偏差 (Data Bias)**：數據無法公平地代表真實世界的分佈，導致模型產生偏見或歧視性結果。
*   **數據雜訊 (Noise)**：數據中包含隨機的錯誤或不相關資訊。
*   **缺失值 (Missing Values)**：部分數據點的某些特徵值是空缺的。
*   **異常值 (Outliers)**：數據中存在與大部分數據顯著不同的極端值。

處理這些數據品質問題，是數據預處理（Data Preprocessing）的重要環節，直接影響後續建模的成效。

-----

### 2-1-2 核心概念：建模 (Modeling)

#### 定義與目標

建模（Modeling）是指選擇一個適合的機器學習演算法，並應用它從訓練數據中學習模式的過程。這個過程的目標是建立一個能夠將輸入特徵映射到輸出目標的「模型」。這個模型一旦訓練完成，就可以用來對未曾見過的數據進行預測、分類或決策。

簡單來說，建模就是讓機器「學習」的過程，而學到的成果就是那個「模型」。

#### 建模的基本流程

一個完整的建模過程通常包括以下幾個階段：

1.  **數據準備 (Data Preparation)**：
    *   **數據收集 (Data Collection)**：獲取原始數據。
    *   **數據清洗 (Data Cleaning)**：處理缺失值、異常值、重複數據等。
    *   **數據轉換 (Data Transformation)**：將原始數據轉換為適合模型輸入的格式（例如，將類別數據轉換為數值）。
    *   **特徵工程 (Feature Engineering)**：從現有特徵中創造新的、更有意義的特徵，以提升模型性能。
    *   **數據分割 (Data Splitting)**：將數據分為訓練集、驗證集和測試集。

2.  **模型選擇 (Model Selection)**：
    *   根據問題的類型（迴歸、分類、聚類等）、數據的特性（線性、非線性、數據量大小）以及業務需求，選擇一個或多個合適的機器學習演算法。
    *   例如，預測連續數值用迴歸模型，預測離散類別用分類模型。

3.  **模型訓練 (Model Training)**：
    *   將準備好的訓練數據輸入到選定的演算法中。
    *   演算法會迭代地調整其內部參數，以最小化預測誤差或最大化某個目標函數。這個過程就是模型學習數據模式的過程。
    *   數學上，這通常涉及優化問題，例如梯度下降法來調整模型參數 $\theta$：
        $$ \theta_{new} = \theta_{old} - \alpha \nabla J(\theta) $$
        其中 $J(\theta)$ 是損失函數（Loss Function），$\alpha$ 是學習率（Learning Rate）。

4.  **模型評估 (Model Evaluation)**：
    *   使用獨立的驗證集或測試集來評估模型在未見數據上的性能。
    *   使用各種評估指標（如準確率、精確率、召回率、F1 分數、均方誤差等）來量化模型的表現。
    *   這一步是判斷模型是否「學得好」的關鍵。

5.  **模型部署 (Model Deployment)**：
    *   將訓練並評估合格的模型整合到實際應用系統中，使其能夠對新的即時數據進行預測或決策。

#### 常見的建模任務類型

根據學習方式和目標，建模任務可分為：

*   **監督式學習 (Supervised Learning)**：
    *   訓練數據包含特徵 ($X$) 和對應的目標 ($y$)。模型從已知輸入輸出對中學習。
    *   **分類 (Classification)**：目標是預測離散的類別（例如：垃圾郵件識別、疾病診斷）。
    *   **迴歸 (Regression)**：目標是預測連續的數值（例如：房價預測、股票價格預測）。
*   **非監督式學習 (Unsupervised Learning)**：
    *   訓練數據只有特徵 ($X$)，沒有明確的目標 ($y$)。模型嘗試從數據中發現隱藏的結構或模式。
    *   **聚類 (Clustering)**：將數據點分組到不同的簇中（例如：客戶分群、圖像分割）。
    *   **降維 (Dimensionality Reduction)**：減少數據的特徵數量，同時保留最重要的信息（例如：PCA）。

-----

### 2-1-3 訓練數據與建模的關聯性

訓練數據與建模是機器學習一體兩面的核心，它們之間存在著緊密且互動的關聯性。

#### 數據塑造模型：模型的性能上限由數據決定

*   **「垃圾進，垃圾出」(Garbage In, Garbage Out, GIGO)**：這是機器學習領域廣為流傳的原則。如果訓練數據質量低劣（包含大量錯誤、雜訊、偏差），無論模型演算法多麼複雜先進，最終訓練出的模型也將表現不佳。數據的上限，就是模型性能的上限。
*   **數據分佈影響模型泛化能力**：訓練數據的分佈應盡可能接近真實世界的數據分佈。如果訓練數據無法代表未來實際應用的場景，模型在訓練集上表現再好，到實際應用時也很可能失準，這就是泛化能力（Generalization Ability）不足。
*   **數據量影響模型複雜度**：數據量越大，模型越有可能學習到複雜的模式，抵抗過擬合（Overfitting）的能力也越強。反之，數據量過小可能只能訓練簡單模型，否則容易過擬合。

#### 模型解釋數據：選擇合適模型以最大化數據價值

*   **模型選擇需與數據類型和問題本質匹配**：
    *   對於線性關係的數據，使用線性模型可能已足夠。
    *   對於高度非線性的數據，需要更複雜的模型（如決策樹、神經網路）才能捕捉其複雜性。
    *   選擇不當的模型，可能導致數據中的寶貴信息無法被充分利用，或者產生錯誤的解釋。
*   **特徵工程與模型協同**：在建模前進行的特徵工程，旨在提取或創造對模型學習更有利的特徵。這需要對數據有深入理解，也需要對選定的模型有一定認知，以確保生成的特徵能被模型有效利用。例如，為樹狀模型設計交互特徵可能很有用，而為線性模型設計非線性變換特徵。

#### 迭代與回饋：數據與模型協同優化

機器學習的實踐是一個高度迭代的過程，訓練數據和建模之間的關係並非單向，而是不斷循環回饋的：

1.  **初始數據準備與初步建模**：基於現有數據進行初步的清洗、轉換和模型訓練。
2.  **模型評估與診斷**：分析模型在測試集上的表現。如果模型性能不佳，就需要診斷其原因。
3.  **反饋與優化**：
    *   **數據層面**：是否需要收集更多數據？是否數據存在偏差需要重新採樣？是否需要更深入的清洗或更精妙的特徵工程？（例如，模型在某類數據上表現特別差，可能說明這類數據在訓練集中代表性不足或特徵不夠。）
    *   **模型層面**：是否需要調整模型超參數？是否需要嘗試不同的演算法？是否需要引入集成學習等更複雜的技術？

這個持續的迭代過程確保了數據和模型能夠相互學習、相互優化，最終達到最佳的預測或決策性能。

-----

### 2-1-4 常見錯誤與澄清

#### 錯誤一：只關注模型演算法，忽略數據品質

*   **描述**：許多初學者或開發者會花大量時間研究最新的機器學習演算法、調試模型參數，卻對訓練數據的來源、收集方式、清洗程度或潛在偏差不夠重視。
*   **澄清**：數據是模型的燃料，模型的性能上限由數據質量決定。一個糟糕的數據集，即便使用最先進的深度學習模型，也難以產生有用的結果。反之，一個高質量、經過精心處理的數據集，即使搭配相對簡單的模型，也能獲得令人滿意的性能。
    *   **正確做法**：將數據收集、清洗、預處理和特徵工程視為與模型選擇、訓練同等重要，甚至更重要的環節。投入時間理解數據的業務背景、檢查數據的分佈和潛在偏差。

#### 錯誤二：訓練數據與測試數據混淆，或數據洩漏 (Data Leakage)

*   **描述**：在訓練模型時，無意中使用了來自測試集或驗證集的信息，導致模型在評估時表現「異常地好」，但實際部署時效果卻很差。
*   **澄清**：數據洩漏是指模型在訓練階段接觸到了本不該接觸到的、來自未來或測試集的資訊。這會導致對模型泛化能力的高度樂觀估計。最常見的數據洩漏發生在：
    *   **數據分割前進行特徵縮放或標準化**：應該先分割數據，再對訓練集進行縮放，並將訓練集的縮放參數應用到測試集。
    *   **特徵工程中使用全局統計量**：例如，計算某個特徵的平均值時包含了測試集的數據。
    *   **時間序列數據未按時間分割**：必須確保訓練數據在時間上早於測試數據。
    *   **正確做法**：
        1.  **嚴格分割數據**：將原始數據一次性分為訓練集、驗證集和測試集，且只在訓練集上進行模型訓練。
        2.  **所有預處理、特徵工程步驟只基於訓練集**：例如，計算平均值、標準差、One-Hot 編碼的類別等，都必須從訓練集獲取，然後應用於訓練集、驗證集和測試集。

#### 錯誤三：對訓練數據進行過度擬合 (Overfitting)

*   **描述**：模型在訓練數據上表現完美（或近乎完美），誤差極低，但在未見過的測試數據上表現卻很差。模型學習到了訓練數據中的雜訊和特有模式，而不是通用規律。
*   **澄清**：過度擬合是機器學習中最常見的問題之一。它意味著模型「記憶」了訓練數據，而不是「學習」了其中的本質規律。
    *   **症狀**：訓練誤差遠小於測試誤差。
    *   **原因**：模型過於複雜、訓練數據量不足、特徵過多等。
    *   **正確做法**：
        *   **簡化模型**：使用更簡單的模型。
        *   **增加訓練數據**：如果有足夠數據，這是最有效的解決方案。
        *   **正則化 (Regularization)**：在損失函數中加入懲罰項，限制模型參數的大小，例如 $L1$ 或 $L2$ 正則化。
        *   **交叉驗證 (Cross-Validation)**：更可靠地評估模型性能，有助於檢測過擬合。
        *   **特徵選擇/降維**：減少不必要的特徵。
        *   **提前停止 (Early Stopping)**：在訓練過程中，監控模型在驗證集上的表現，當驗證集性能開始惡化時停止訓練。

-----

### 2-1-5 小練習

#### 小練習一：識別特徵與目標

某電商公司希望預測客戶是否會購買其推出的新款智慧型手機。他們收集了以下關於潛在客戶的數據：

*   **客戶 ID** (唯一識別碼)
*   **年齡** (客戶的歲數)
*   **平均月收入** (客戶的平均月收入)
*   **過去三個月的瀏覽紀錄** (例如：瀏覽手機配件頁面次數)
*   **過去六個月的購買紀錄** (例如：是否購買過任何電子產品，是/否)
*   **是否會購買新款手機** (最終的購買決策，是/否)

**請識別出上述數據中的特徵 (Features) 和目標 (Target)。**

**詳解：**

1.  **理解問題目標**：公司希望「預測客戶是否會購買新款手機」。因此，模型最終需要輸出的就是這個「購買決策」。
2.  **識別目標**：與預測目標直接對應的數據項就是「目標」。
    *   **目標 (Target)**：**是否會購買新款手機** (這是模型需要預測的結果，$y$)。
3.  **識別特徵**：除了目標之外，所有可用於幫助模型做出預測的描述性資訊都是特徵。
    *   **特徵 (Features)**：
        *   **年齡**
        *   **平均月收入**
        *   **過去三個月的瀏覽紀錄**
        *   **過去六個月的購買紀錄**
    *   **注意**：**客戶 ID** 通常不是特徵，因為它是一個唯一的識別碼，不包含任何有助於預測的模式（除非它隱含了某些排序或分組信息，但通常情況下會被排除）。

#### 小練習二：數據品質對建模的影響

一家保險公司正在開發一個模型來預測客戶是否會提出索賠。他們收集了大量的客戶數據，並使用這些數據訓練了一個隨機森林模型。然而，在初步的模型評估中，他們發現模型在訓練集上的準確率高達 98%，但在實際應用於新的客戶數據時，準確率卻只有 60%，遠低於預期。

**請分析可能導致這種情況的原因，並提出至少兩種可能的改進方法。**

**詳解：**

1.  **分析問題**：模型在訓練集上表現極好 (98%)，但在新數據上表現很差 (60%)。這是典型的**過度擬合 (Overfitting)** 現象。模型可能學習了訓練數據的特定細節和雜訊，而未能捕捉到數據的通用模式。

2.  **可能導致過度擬合的原因**：

    *   **訓練數據品質問題**：
        *   **數據洩漏 (Data Leakage)**：訓練集中可能包含了來自測試集或未來數據的「線索」，導致模型在訓練集上表現超好，但這些線索在實際應用中並不存在。例如，某個與結果強相關的特徵，在數據清洗或特徵工程時，不小心使用了全局（包含測試集）的統計信息。
        *   **數據雜訊過多**：訓練數據中包含大量錯誤標籤或不相關的雜訊，模型在嘗試匹配這些雜訊時，變得過於複雜。
    *   **模型複雜度過高**：隨機森林是一個功能強大的集成模型，如果樹的數量過多、樹的深度過深，或每棵樹的葉節點數據量太少，模型很容易過度擬合。
    *   **訓練數據量不足**：如果訓練數據相對於模型的複雜度而言太少，模型可能會將訓練數據中的每一個特徵組合都「記住」，而不是學習通用規律。
    *   **數據分佈不均**：訓練數據可能存在嚴重的類別不平衡（例如，絕大多數客戶都不索賠），導致模型偏向於預測多數類。

3.  **可能的改進方法**：

    1.  **重新檢查數據預處理和特徵工程流程，排除數據洩漏**：
        *   **步驟**：
            1.  **嚴格重新分割數據**：確保訓練集、驗證集和測試集在任何預處理之前就已分離。
            2.  **局部應用預處理**：所有統計計算（如平均值、標準差、類別編碼映射）都必須**只在訓練集上**完成。然後，將這些訓練集學到的參數應用到驗證集和測試集。
            3.  **檢查時間順序**：如果數據有時間屬性，確保訓練集的時間在測試集之前。
            4.  **檢查特徵源頭**：確保沒有任何「未來信息」或「來自結果的信息」被不小心當作特徵納入。

    2.  **調整模型複雜度或引入正則化**：
        *   **步驟**：
            1.  **降低隨機森林的複雜度**：減少樹的數量 (N_estimators)，限制每棵樹的最大深度 (max_depth)，增加每個葉節點的最小樣本數 (min_samples_leaf)。
            2.  **使用交叉驗證 (Cross-Validation)**：在訓練階段使用交叉驗證，可以更穩健地評估模型性能，並有助於在驗證集上找到最佳的超參數組合，從而減少過擬合。
            3.  **提前停止 (Early Stopping)**：如果在訓練過程中使用了迭代優化的模型（例如梯度提升樹），可以在監測模型在驗證集上的性能停止提升時，提前停止訓練。

    3.  **增加訓練數據量或進行數據增強**：
        *   **步驟**：
            1.  **收集更多數據**：如果條件允許，獲取更多代表真實世界分佈的訓練數據是最直接有效的方法。
            2.  **數據增強 (Data Augmentation)**：對於某些數據類型（如圖像、文字），可以透過對現有數據進行輕微變形來創造新的訓練樣本，從而增加數據量。

    4.  **處理數據不平衡問題**：
        *   **步驟**：
            1.  **重採樣 (Resampling)**：對訓練集中的少數類進行過採樣 (Oversampling) 或對多數類進行欠採樣 (Undersampling)。
            2.  **使用合成少數類過採樣技術 (SMOTE)**：生成新的少數類樣本。
            3.  **調整損失函數或模型權重**：讓模型在預測少數類時給予更高的權重。

-----

### 2-1-6 延伸閱讀

*   **數據預處理與特徵工程**：
    *   **書籍**：
        *   *Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists* by Alice Zheng and Amanda Casari.
        *   *Python Data Science Handbook* by Jake VanderPlas (特別是關於 Pandas 和 Scikit-learn 的章節)。
    *   **線上資源**：Kaggle 平台上許多競賽的 Winning Solutions 都會詳細分享數據預處理和特徵工程的技巧。
*   **機器學習基礎理論**：
    *   **書籍**：
        *   *An Introduction to Statistical Learning with Applications in R* by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (對理論和應用都有很好的介紹，提供 Python 範例)。
        *   *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron. (實作導向，但對概念解釋清晰)。
    *   **線上課程**：Coursera 上的 Andrew Ng 的機器學習課程。