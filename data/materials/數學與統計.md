# 機率論基礎：從事件到條件機率

## ### 第一章：機率論核心概念

本章將引導您進入機率論的世界，從最基礎的隨機試驗、樣本空間與事件開始，逐步探討機率的定義、基本性質，並介紹在統計學中至關重要的條件機率與獨立事件。

---

### #### 1.1 隨機試驗、樣本空間與事件

**核心概念**

機率論是研究隨機現象規律的數學分支。在分析任何隨機現象時，我們首先需要定義以下幾個基本概念：

*   **隨機試驗 (Random Experiment)**：一個試驗或過程，其結果在事前無法確定，但在重複進行時，其所有可能結果是已知的。
    *   **特性**：
        1.  每次試驗的結果不可預測。
        2.  所有可能的結果是已知的。
        3.  試驗可以重複進行。
*   **樣本空間 (Sample Space, $S$)**：一個隨機試驗所有可能結果的集合。它是機率論中討論所有事件的「宇宙」。
    *   **分類**：
        *   **有限樣本空間 (Finite Sample Space)**：包含有限個結果。例如，擲一次骰子的結果 $\{1, 2, 3, 4, 5, 6\}$。
        *   **可數無限樣本空間 (Countably Infinite Sample Space)**：包含無限個結果，但這些結果可以與自然數一一對應。例如，直到擲出正面為止所需擲硬幣的次數 $\{1, 2, 3, \dots\}$。
        *   **不可數無限樣本空間 (Uncountably Infinite Sample Space)**：包含無限個結果，且這些結果無法與自然數一一對應。例如，燈泡的壽命 (任何非負實數)。
*   **事件 (Event, $A$)**：樣本空間 $S$ 的任何一個子集。事件表示我們感興趣的某些結果的集合。
    *   **特殊事件**：
        *   **不可能事件 (Impossible Event)**：空集合 $\emptyset$，表示永不會發生的事件。
        *   **必然事件 (Certain Event)**：樣本空間 $S$，表示必然會發生的事件。
    *   **事件的運算**：
        *   **聯集 (Union)**：$A \cup B$ 表示事件 $A$ 發生**或**事件 $B$ 發生（或兩者皆發生）。
        *   **交集 (Intersection)**：$A \cap B$ (或 $AB$) 表示事件 $A$ 發生**且**事件 $B$ 發生。
        *   **補集 (Complement)**：$A^c$ (或 $\bar{A}$) 表示事件 $A$ 不發生。
        *   **互斥事件 (Mutually Exclusive Events)**：若 $A \cap B = \emptyset$，則稱 $A$ 與 $B$ 互斥。表示兩事件不可能同時發生。

**典型例子**

1.  **擲一次硬幣**
    *   隨機試驗：擲一次硬幣。
    *   樣本空間 $S = \{正面, 反面\}$。
    *   事件 $A = \{正面\}$：擲出正面的事件。
    *   事件 $B = \{反面\}$：擲出反面的事件。
    *   $A$ 與 $B$ 是互斥事件。
2.  **擲一次骰子**
    *   隨機試驗：擲一次骰子。
    *   樣本空間 $S = \{1, 2, 3, 4, 5, 6\}$。
    *   事件 $A = \{2, 4, 6\}$：擲出偶數點的事件。
    *   事件 $B = \{1, 3, 5\}$：擲出奇數點的事件。
    *   事件 $C = \{1, 2, 3\}$：擲出點數小於 4 的事件。
    *   $A \cup C = \{1, 2, 3, 4, 6\}$。
    *   $A \cap C = \{2\}$。
    *   $A^c = \{1, 3, 5\} = B$。
    *   $A$ 與 $B$ 互斥，但 $A$ 與 $C$ 不互斥。

**與相鄰概念的關聯**

這些概念是機率論的基石。有了清晰定義的樣本空間和事件，我們才能量化事件發生的可能性，也就是定義「機率」。在集合論中學到的集合運算（聯集、交集、補集）直接應用於事件的運算。

---

### #### 1.2 機率的定義與性質

**核心概念**

機率是衡量事件發生可能性大小的數值。主要有三種定義機率的方式：

1.  **古典機率 (Classical Probability)**：
    *   適用於有限樣本空間，且所有基本結果 (outcome) 發生機會均等的情況。
    *   $$P(A) = \frac{\text{事件 } A \text{ 包含的結果數量}}{\text{樣本空間 } S \text{ 包含的總結果數量}} = \frac{n(A)}{n(S)}$$
    *   **限制**：要求所有基本事件等可能發生，且樣本空間必須有限。
2.  **頻率機率 (Frequency Probability)** (或經驗機率)：
    *   透過重複進行大量試驗，用事件發生的相對頻率來估計其機率。
    *   $$P(A) = \lim_{n \to \infty} \frac{\text{事件 } A \text{ 發生的次數}}{n \text{ (總試驗次數)}}$$
    *   **特性**：適用於任何可重複的隨機試驗，是統計學中估計機率的基礎。
3.  **公理化機率 (Axiomatic Probability)** (Kolmogorov 公理)：
    *   這是現代機率論的嚴格數學基礎，它不規定如何計算機率，而是定義機率函數必須滿足的公理。
    *   設 $S$ 為樣本空間，$\mathcal{F}$ 為 $S$ 的一個事件集合（$\sigma$-代數），函數 $P: \mathcal{F} \to [0, 1]$ 為機率函數，需滿足：
        1.  **非負性 (Non-negativity)**：對於任何事件 $A \in \mathcal{F}$，$P(A) \ge 0$。
        2.  **正規性 (Normalization)**：樣本空間 $S$ 的機率為 1，即 $P(S) = 1$。
        3.  **可加性 (Additivity)**：若 $A_1, A_2, \dots$ 是一系列兩兩互斥的事件 (即 $A_i \cap A_j = \emptyset$ 對於 $i \ne j$)，則它們聯集的機率等於各事件機率之和：
            $$P(A_1 \cup A_2 \cup \dots) = \sum_{i=1}^{\infty} P(A_i)$$
            若只有有限個互斥事件，則 $P(A_1 \cup A_2) = P(A_1) + P(A_2)$。

**機率的推導與性質**

根據 Kolmogorov 公理，可以推導出機率的其他性質：

1.  **補集機率**：$P(A^c) = 1 - P(A)$。
    *   *推導*：因為 $A \cup A^c = S$ 且 $A \cap A^c = \emptyset$，根據公理 2 和 3，$P(S) = P(A) + P(A^c) \implies 1 = P(A) + P(A^c)$。
2.  **不可能事件機率**：$P(\emptyset) = 0$。
    *   *推導*：$P(S) = 1$，又 $S^c = \emptyset$，所以 $P(\emptyset) = 1 - P(S) = 1 - 1 = 0$。
3.  **事件機率範圍**：對於任何事件 $A$， $0 \le P(A) \le 1$。
    *   *推導*：由公理 1 ($P(A) \ge 0$) 和 $P(A) = 1 - P(A^c) \le 1$ (因為 $P(A^c) \ge 0$) 得出。
4.  **廣義加法法則 (General Addition Rule)**：
    *   對於任意兩個事件 $A$ 和 $B$：
        $$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$
    *   *推導*：將 $A \cup B$ 分解為三個互斥事件：$A \cap B^c$, $A^c \cap B$, $A \cap B$。
        $P(A \cup B) = P(A \cap B^c) + P(A^c \cap B) + P(A \cap B)$。
        又 $P(A) = P(A \cap B^c) + P(A \cap B)$，所以 $P(A \cap B^c) = P(A) - P(A \cap B)$。
        同理 $P(A^c \cap B) = P(B) - P(A \cap B)$。
        代入上式即得。
5.  **單調性**：若 $A \subseteq B$，則 $P(A) \le P(B)$。
    *   *推導*：若 $A \subseteq B$，則 $B$ 可以表示為 $A \cup (B \cap A^c)$，其中 $A$ 與 $B \cap A^c$ 互斥。
        所以 $P(B) = P(A) + P(B \cap A^c)$。由於 $P(B \cap A^c) \ge 0$，因此 $P(B) \ge P(A)$。

**典型例子**

*   **擲兩次硬幣的機率**
    *   樣本空間 $S = \{HH, HT, TH, TT\}$。$n(S) = 4$。
    *   假設所有結果等可能。
    *   事件 $A = \{\text{至少一次正面}\} = \{HH, HT, TH\}$。$n(A) = 3$。
    *   $P(A) = n(A)/n(S) = 3/4$。
    *   事件 $B = \{\text{兩次均為正面}\} = \{HH\}$。$n(B) = 1$。
    *   $P(B) = 1/4$。
    *   事件 $C = \{\text{恰好一次正面}\} = \{HT, TH\}$。$n(C) = 2$。
    *   $P(C) = 2/4 = 1/2$。
    *   $P(A \cup B) = P(A) = 3/4$ (因為 $B \subseteq A$)。
    *   $P(A \cap C) = P(C) = 1/2$ (因為 $C \subseteq A$)。

**與相鄰概念的關聯**

古典機率與組合計數（排列組合）密切相關，因為計算 $n(A)$ 和 $n(S)$ 經常需要使用排列組合的知識。頻率機率是統計學中推斷機率的核心思想，例如，透過抽樣調查來估計整體事件發生的機率。公理化機率則提供了一個嚴謹的數學框架，確保機率理論的內部一致性。

---

### #### 1.3 條件機率

**核心概念**

條件機率探討在已知某事件 $B$ 已經發生的情況下，另一個事件 $A$ 發生的機率。這表示我們將樣本空間縮小到事件 $B$ 內部。

*   **定義**：設 $A$ 和 $B$ 是樣本空間 $S$ 中的兩個事件，且 $P(B) > 0$。事件 $A$ 在事件 $B$ 發生的條件下的條件機率記為 $P(A|B)$，定義為：
    $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
*   **理解**：當已知 $B$ 發生時，所有非 $B$ 的結果都不再可能。此時，只有在 $B$ 內部且 $A$ 也發生的結果（即 $A \cap B$）才符合條件。$P(B)$ 充當了新的「樣本空間」的機率，因此用它來歸一化。

**典型例子**

1.  **從一副撲克牌中抽牌**
    *   隨機試驗：從一副標準的 52 張撲克牌中隨機抽一張。
    *   事件 $A = \{\text{抽到紅心}\}$。$P(A) = 13/52 = 1/4$。
    *   事件 $B = \{\text{抽到 K}\}$。$P(B) = 4/52 = 1/13$。
    *   事件 $A \cap B = \{\text{抽到紅心 K}\}$。$P(A \cap B) = 1/52$。
    *   **計算在已知抽到 K 的情況下，它是紅心的機率** $P(A|B)$：
        $$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{1/52}{4/52} = \frac{1}{4}$$
        這很直觀：已知是 K，有 4 張 K (紅心 K, 方塊 K, 梅花 K, 黑桃 K)，其中只有 1 張是紅心 K，所以機率是 $1/4$。
    *   **計算在已知抽到紅心的情況下，它是 K 的機率** $P(B|A)$：
        $$P(B|A) = \frac{P(A \cap B)}{P(A)} = \frac{1/52}{13/52} = \frac{1}{13}$$
        這也很直觀：已知是紅心，有 13 張紅心，其中只有 1 張是 K，所以機率是 $1/13$。

2.  **生產線產品不良率**
    *   某工廠有兩條生產線 $L_1$ 和 $L_2$，分別生產 60% 和 40% 的產品。
    *   $L_1$ 的不良率為 2%，$L_2$ 的不良率為 3%。
    *   事件 $L_1 = \{\text{產品來自 } L_1\}$，$P(L_1) = 0.6$。
    *   事件 $L_2 = \{\text{產品來自 } L_2\}$，$P(L_2) = 0.4$。
    *   事件 $D = \{\text{產品是不良品}\}$。
    *   已知來自 $L_1$ 的產品是不良品的機率 $P(D|L_1) = 0.02$。
    *   已知來自 $L_2$ 的產品是不良品的機率 $P(D|L_2) = 0.03$。
    *   **計算隨機抽取一個產品是不良品的機率** $P(D)$：
        根據全機率公式 (Total Probability Rule)：
        $P(D) = P(D|L_1)P(L_1) + P(D|L_2)P(L_2)$
        $P(D) = (0.02)(0.6) + (0.03)(0.4) = 0.012 + 0.012 = 0.024$。
    *   **計算如果一個產品是不良品，它來自 $L_1$ 的機率** $P(L_1|D)$：
        $$P(L_1|D) = \frac{P(D \cap L_1)}{P(D)} = \frac{P(D|L_1)P(L_1)}{P(D)} = \frac{(0.02)(0.6)}{0.024} = \frac{0.012}{0.024} = 0.5$$
        這是一個貝氏定理的應用。

**與相鄰概念的關聯**

條件機率是理解許多進階機率與統計概念的關鍵：

*   **乘法法則 (Multiplication Rule)**：從條件機率的定義推導而來，用於計算兩個事件同時發生的機率：
    $$P(A \cap B) = P(A|B)P(B) \text{ 或 } P(A \cap B) = P(B|A)P(A)$$
*   **貝氏定理 (Bayes' Theorem)**：利用條件機率反推「原因」的機率。如果我們知道 $P(B|A)$，貝氏定理讓我們可以計算 $P(A|B)$。這是統計推斷中更新信念的核心。
    $$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$
*   **獨立事件**：條件機率幫助我們明確定義和區分獨立事件與非獨立事件。

---

### #### 1.4 獨立事件

**核心概念**

當一個事件的發生不影響另一個事件發生的機率時，我們稱這兩個事件是獨立的。

*   **定義**：事件 $A$ 和 $B$ 被稱為獨立事件，如果：
    $$P(A|B) = P(A) \quad \text{或} \quad P(B|A) = P(B)$$
    (假設條件機率的分母不為零。)
    這意味著即使已知 $B$ 發生，事件 $A$ 發生的機率仍然和 $B$ 未知時的機率一樣。
*   **等價定義 (乘法定義)**：事件 $A$ 和 $B$ 是獨立事件，若且唯若：
    $$P(A \cap B) = P(A)P(B)$$
    這個定義在 $P(A)$ 或 $P(B)$ 為零的情況下也適用，且在計算上更為常用。
    *   *推導*：若 $P(A|B) = P(A)$，則由 $P(A|B) = P(A \cap B)/P(B)$ 可得 $P(A) = P(A \cap B)/P(B)$，進而 $P(A \cap B) = P(A)P(B)$。反之亦然。

**典型例子**

1.  **重複擲骰子**
    *   隨機試驗：連續擲兩次公平的骰子。
    *   事件 $A = \{\text{第一次擲出 6 點}\}$。$P(A) = 1/6$。
    *   事件 $B = \{\text{第二次擲出 3 點}\}$。$P(B) = 1/6$。
    *   第一次擲骰的結果不會影響第二次擲骰的結果，所以 $A$ 和 $B$ 是獨立事件。
    *   根據獨立事件的定義，兩次都擲出指定點數的機率為：
        $$P(A \cap B) = P(A)P(B) = (1/6)(1/6) = 1/36$$
2.  **性別與戴眼鏡的關聯 (非獨立事件)**
    *   在一個班級中：
        *   $P(\text{戴眼鏡}) = 0.4$
        *   $P(\text{是男生}) = 0.6$
        *   $P(\text{是男生且戴眼鏡}) = 0.3$
    *   如果「戴眼鏡」和「是男生」是獨立事件，則 $P(\text{是男生且戴眼鏡})$ 應該等於 $P(\text{是男生}) \times P(\text{戴眼鏡}) = 0.6 \times 0.4 = 0.24$。
    *   然而，實際觀察到的 $P(\text{是男生且戴眼鏡}) = 0.3 \ne 0.24$。
    *   因此，「戴眼鏡」和「是男生」這兩個事件**不獨立**。
    *   我們可以進一步計算條件機率：
        *   $P(\text{戴眼鏡}|\text{是男生}) = \frac{P(\text{是男生且戴眼鏡})}{P(\text{是男生})} = \frac{0.3}{0.6} = 0.5$。
        *   $P(\text{戴眼鏡}) = 0.4$。由於 $0.5 \ne 0.4$，再次確認兩事件不獨立。男生戴眼鏡的機率 ($0.5$) 高於全班學生戴眼鏡的機率 ($0.4$)。

**多個事件的獨立性**

*   **兩兩獨立 (Pairwise Independent)**：如果每對事件都滿足獨立性條件。
*   **相互獨立 (Mutually Independent)**：如果任何一個事件的集合 $A_{i_1}, A_{i_2}, \dots, A_{i_k}$ 都滿足：
    $$P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) = P(A_{i_1})P(A_{i_2})\dots P(A_{i_k})$$
    相互獨立比兩兩獨立的要求更嚴格。相互獨立蘊含兩兩獨立，但反之不成立。

**與相鄰概念的關聯**

獨立事件的概念在機率論和統計學中極為重要，尤其是在以下領域：

*   **重複試驗**：許多統計模型（如二項分佈、泊松分佈）都假設試驗是相互獨立的。例如，從樣本中隨機抽樣通常假設每次抽樣都是獨立的。
*   **變數的獨立性**：在統計學中，隨機變數的獨立性是許多理論和方法的基礎，例如共變數和相關係數的解釋。
*   **條件機率的簡化**：如果事件 $A$ 和 $B$ 獨立，則 $P(A|B) = P(A)$，這簡化了許多複雜的機率計算。

---

## ### 第二章：應用與實作

### #### 2.1 常見錯誤與澄清

1.  **混淆「互斥事件」與「獨立事件」**
    *   **澄清**：
        *   **互斥事件 (Mutually Exclusive Events)**：指兩事件不能同時發生，即 $A \cap B = \emptyset$。如果 $P(A) > 0$ 且 $P(B) > 0$，則 $P(A \cap B) = 0$。
        *   **獨立事件 (Independent Events)**：指一事件的發生不影響另一事件的機率，即 $P(A \cap B) = P(A)P(B)$。
        *   **區別**：如果兩個事件是互斥的且 $P(A)>0, P(B)>0$，那麼它們必然不是獨立的，因為 $P(A \cap B) = 0$ 但 $P(A)P(B) > 0$。反之，如果兩個事件獨立且 $P(A)>0, P(B)>0$，那麼它們不能互斥，因為 $P(A \cap B) = P(A)P(B) > 0$，所以它們可以同時發生。
    *   **口訣**：
        *   互斥事件：不能**同時**發生。
        *   獨立事件：發生與否互不**影響**。

2.  **誤用條件機率公式**
    *   **錯誤**：將 $P(A|B)$ 和 $P(B|A)$ 視為相同。
    *   **澄清**：通常 $P(A|B) \ne P(B|A)$。
        *   $P(A|B)$ 是已知 $B$ 發生的情況下 $A$ 的機率。
        *   $P(B|A)$ 是已知 $A$ 發生的情況下 $B$ 的機率。
    *   例如，醫生告訴你 $P(\text{有病}|\text{檢測陽性})$ 和 $P(\text{檢測陽性}|\text{有病})$ 是非常不同的概念。前者是我們真正關心的（已知檢測結果，判斷疾病的機率），後者是檢測的準確度。貝氏定理正是解決這類「逆機率」問題的工具。

3.  **認為 $P(A)=0$ 等價於事件 $A$ 不可能發生**
    *   **澄清**：在離散樣本空間中，$P(A)=0$ 確實意味著事件 $A$ 是不可能事件。
    *   然而，在連續樣本空間中，一個事件的機率為 0 不代表它不可能發生。例如，從 $[0, 1]$ 區間中隨機選擇一個實數，選中任何特定數值（如 0.5）的機率是 0，但這個數值仍然可能被選中。這在微積分和測度論中有更嚴謹的定義。

---

### #### 2.2 小練習（附詳解）

#### 練習 1：擲骰子與機率計算

假設您擲一次公平的六面骰子。
1.  列出樣本空間 $S$。
2.  事件 $A = \{\text{擲出偶數點}\}$。計算 $P(A)$。
3.  事件 $B = \{\text{擲出點數大於 3}\}$。計算 $P(B)$。
4.  計算 $P(A \cap B)$。
5.  計算 $P(A \cup B)$。
6.  計算 $P(A|B)$。
7.  事件 $C = \{\text{擲出奇數點}\}$。判斷 $A$ 與 $C$ 是否互斥？是否獨立？

**詳解**

1.  **樣本空間 $S$**：
    *   $S = \{1, 2, 3, 4, 5, 6\}$。
2.  **計算 $P(A)$**：
    *   事件 $A = \{\text{擲出偶數點}\} = \{2, 4, 6\}$。
    *   $n(A) = 3$。
    *   $P(A) = \frac{n(A)}{n(S)} = \frac{3}{6} = \frac{1}{2}$。
3.  **計算 $P(B)$**：
    *   事件 $B = \{\text{擲出點數大於 3}\} = \{4, 5, 6\}$。
    *   $n(B) = 3$。
    *   $P(B) = \frac{n(B)}{n(S)} = \frac{3}{6} = \frac{1}{2}$。
4.  **計算 $P(A \cap B)$**：
    *   事件 $A \cap B = \{\text{擲出偶數點且大於 3}\} = \{4, 6\}$。
    *   $n(A \cap B) = 2$。
    *   $P(A \cap B) = \frac{n(A \cap B)}{n(S)} = \frac{2}{6} = \frac{1}{3}$。
5.  **計算 $P(A \cup B)$**：
    *   方法一：直接列出聯集。
        *   $A \cup B = \{\text{擲出偶數點或大於 3}\} = \{2, 4, 5, 6\}$。
        *   $n(A \cup B) = 4$。
        *   $P(A \cup B) = \frac{4}{6} = \frac{2}{3}$。
    *   方法二：使用廣義加法法則。
        *   $P(A \cup B) = P(A) + P(B) - P(A \cap B) = \frac{1}{2} + \frac{1}{2} - \frac{1}{3} = 1 - \frac{1}{3} = \frac{2}{3}$。
6.  **計算 $P(A|B)$**：
    *   使用條件機率公式：
        *   $P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{1/3}{1/2} = \frac{1}{3} \times 2 = \frac{2}{3}$。
    *   直觀理解：已知擲出點數大於 3 (即結果為 $\{4, 5, 6\}$)，在這個縮小的樣本空間中，偶數點是 $\{4, 6\}$，所以機率是 $2/3$。
7.  **判斷 $A$ 與 $C$ 是否互斥？是否獨立？**
    *   事件 $C = \{\text{擲出奇數點}\} = \{1, 3, 5\}$。
    *   **互斥性判斷**：
        *   $A \cap C = \{2, 4, 6\} \cap \{1, 3, 5\} = \emptyset$。
        *   因為交集為空，所以 $A$ 與 $C$ **互斥**。
    *   **獨立性判斷**：
        *   如果獨立，則 $P(A \cap C) = P(A)P(C)$。
        *   我們知道 $P(A \cap C) = P(\emptyset) = 0$。
        *   $P(C) = \frac{n(C)}{n(S)} = \frac{3}{6} = \frac{1}{2}$。
        *   $P(A)P(C) = \frac{1}{2} \times \frac{1}{2} = \frac{1}{4}$。
        *   由於 $0 \ne \frac{1}{4}$，所以 $A$ 與 $C$ **不獨立**。
        *   這也符合我們前面「互斥且非零機率的事件不可能獨立」的結論。

---

#### 練習 2：醫學檢測與貝氏定理

某疾病在總人口中的盛行率為 $0.5\%$ (即 $P(\text{有病}) = 0.005$)。有一種檢測方法，其準確性如下：
*   如果一個人確實有病，檢測結果為陽性的機率是 $99\%$ (即 $P(\text{陽性}|\text{有病}) = 0.99$)。
*   如果一個人沒有病，檢測結果為陽性的機率是 $1\%$ (即 $P(\text{陽性}|\text{無病}) = 0.01$)。

現在，某人進行了檢測，結果為陽性。請問這個人真的有病的機率是多少？

**詳解**

設：
*   $D = \{\text{此人有病}\}$
*   $D^c = \{\text{此人無病}\}$
*   $P = \{\text{檢測結果為陽性}\}$

我們已知：
*   $P(D) = 0.005$ (疾病盛行率)
*   $P(D^c) = 1 - P(D) = 1 - 0.005 = 0.995$ (無病機率)
*   $P(P|D) = 0.99$ (真陽性率)
*   $P(P|D^c) = 0.01$ (假陽性率)

我們想計算的是 $P(D|P)$，即在檢測結果為陽性的條件下，此人真的有病的機率。

1.  **計算檢測結果為陽性的總機率 $P(P)$**：
    *   使用全機率公式：
        $$P(P) = P(P|D)P(D) + P(P|D^c)P(D^c)$$
    *   將已知數值代入：
        $$P(P) = (0.99)(0.005) + (0.01)(0.995)$$
        $$P(P) = 0.00495 + 0.00995$$
        $$P(P) = 0.0149$$
    *   這表示隨機一個人檢測出陽性的機率大約是 1.49%。

2.  **使用貝氏定理計算 $P(D|P)$**：
    *   貝氏定理公式：
        $$P(D|P) = \frac{P(P|D)P(D)}{P(P)}$$
    *   將已計算的數值代入：
        $$P(D|P) = \frac{(0.99)(0.005)}{0.0149}$$
        $$P(D|P) = \frac{0.00495}{0.0149}$$
        $$P(D|P) \approx 0.3322$$

3.  **結論**：
    *   即使檢測結果為陽性，此人真的有病的機率約為 **33.22%**。
    *   這個結果可能讓人驚訝。儘管檢測的真陽性率高達 99%，但由於疾病本身的盛行率非常低（0.5%），導致大部分陽性結果其實是來自於沒有病的假陽性。這強調了理解條件機率和貝氏定理在實際應用中的重要性。

---

### #### 2.3 延伸閱讀

*   **貝氏定理的深度應用**：
    *   深入理解貝氏定理如何透過新的證據來更新對事件發生機率的信念，這是統計推斷中貝氏方法的基礎。
*   **隨機變數與機率分佈**：
    *   一旦掌握了事件和機率的基礎，下一步是學習隨機變數（將隨機試驗的結果數值化）以及它們的機率分佈（如二項分佈、常態分佈、泊松分佈等），這些是統計建模的基石。
*   **期望值與變異數**：
    *   學習如何計算隨機變數的期望值（平均值）和變異數（離散程度），這些是描述隨機變數特徵的重要統計量。

**參考書目**

*   **Sheldon Ross, "A First Course in Probability"**: 經典的機率論入門教材，內容豐富且嚴謹。
*   **Jay L. Devore, "Probability and Statistics for Engineering and the Sciences"**: 結合了機率論和統計學，適合理工科背景的讀者。
*   **吳統雄, "統計學的應用"**: 繁體中文教材，深入淺出，側重應用。