# 6-1 RAG 與代理

本章將深入探討大型語言模型 (LLM) 應用領域的兩大核心技術：檢索增強生成 (Retrieval-Augmented Generation, RAG) 和代理 (Agent)。RAG 旨在為 LLM 提供外部知識以提升答案的準確性和時效性，而代理則賦予 LLM 規劃、工具使用和自主決策的能力，使其能完成更複雜的任務。

-----

### 核心概念與定義

#### 檢索增強生成 (Retrieval-Augmented Generation, RAG)

##### 定義/核心觀念
RAG 是一種將大型語言模型的**生成能力**與**外部知識檢索能力**相結合的技術。其核心目標是透過向 LLM 提供相關的、最新的、事實性的外部資訊，以提升其回答的準確性、可靠性，並減少「幻覺」（Hallucination）現象。

RAG 的工作原理分為兩個主要階段：
1.  **檢索 (Retrieval)**：當用戶提出問題時，系統會從一個外部知識庫（例如文件庫、資料庫、網路搜尋結果等）中檢索出與問題最相關的資訊片段。
2.  **生成 (Generation)**：將用戶的原始問題與檢索到的相關資訊片段一同作為「上下文」（Context）輸入給 LLM。LLM 根據這些增強的上下文來生成最終答案。

**白話解釋**：想像 LLM 是一位知識淵博但記憶有限的學生。RAG 就像給這位學生一本最新、最準確的參考書，當學生被問到問題時，他可以先翻閱參考書找到相關內容，然後再結合自己的理解來回答。這樣，他的答案不僅更準確，也能涵蓋參考書中的最新資訊。

##### 例子與推導
**典型例子**：
一家銀行希望為其客戶服務機器人提供即時的產品資訊和法規更新。
*   **傳統 LLM 應用**：若直接問通用 LLM「最新的存款利率是多少？」，它可能回答不出來（因為知識截止）或給出舊的、錯誤的資訊。
*   **RAG 應用**：
    1.  **知識庫準備**：將銀行的所有產品說明書、最新的利率表、法規文件等轉化為可檢索的格式（例如，將文字切分成小塊，並使用向量嵌入技術將其轉換為數值向量，存儲在向量資料庫中）。
    2.  **用戶提問**：客戶問「最新的活期存款利率是多少？」
    3.  **檢索階段**：RAG 系統會將這個問題轉化為向量，然後在向量資料庫中尋找與這個問題最相似的文字片段（例如，包含「活期存款」、「利率」、「最新」等關鍵詞的條目）。
    4.  **生成階段**：系統將「最新的活期存款利率是多少？」與檢索到的「本行活期存款年利率自 2024 年 5 月 1 日起調整為 0.8%...」一同傳給 LLM。LLM 便能生成準確的回答：「根據本行最新規定，活期存款年利率自 2024 年 5 月 1 日起調整為 0.8%。」

#### 代理 (Agent)

##### 定義/核心觀念
在人工智慧領域，特別是與大型語言模型結合時，代理是一種能夠**自主地感知環境、設定目標、規劃行動、執行任務、使用工具並從經驗中學習**的軟體實體。它的核心是利用 LLM 作為其**推理引擎 (Reasoning Engine)**，但其功能遠超越單純的 LLM 呼叫。

一個 LLM 驅動的代理通常包含以下關鍵組成部分：
*   **規劃 (Planning)**：理解任務、將複雜任務分解為可管理的小步驟、決定行動順序。
*   **記憶 (Memory)**：
    *   **短期記憶 (Short-term Memory)**：即上下文視窗，用於在當前任務中保留相關資訊。
    *   **長期記憶 (Long-term Memory)**：儲存過去的經驗、知識或學到的模式，通常透過外部向量資料庫實現。
*   **工具使用 (Tool Use)**：呼叫外部工具（如搜尋引擎 API、程式碼解釋器、日曆、數據庫查詢、RAG 系統等）來獲取資訊或執行特定操作。
*   **反思/自我修正 (Reflection/Self-correction)**：評估其行動的結果，識別錯誤，並調整未來的規劃或執行策略。

**白話解釋**：如果說 LLM 是一個非常聰明的「大腦」，那麼代理就是一個擁有這個大腦、能夠自主思考、手腳並用（使用工具）、有記憶和反思能力的「人」。它不僅能理解你的問題，還能為了達到目標而主動採取一系列行動。

##### 例子與推導
**典型例子**：
你要求一個代理去「為我研究一下 2024 年 AI 領域最新的十大趨勢，並生成一份摘要報告。」
1.  **任務分解與規劃**：代理首先會將這個複雜任務分解成幾個子任務：
    *   搜尋 2024 年 AI 趨勢的最新資訊。
    *   篩選和整合相關資訊。
    *   分析並識別十大趨勢。
    *   撰寫摘要報告。
2.  **工具使用 (搜尋)**：代理決定使用「搜尋引擎 API」作為工具。它可能會發出多個搜尋查詢，例如：「2024 AI trends forecast」、「latest AI developments 2024」、「emerging AI technologies」。
3.  **資訊處理與記憶**：代理從搜尋結果中提取關鍵資訊，並可能將其暫存於短期記憶中。對於重要或需要長期使用的資訊，可能會存儲到長期記憶庫（如向量資料庫）。
4.  **工具使用 (分析/整合)**：代理可能會在內部使用 LLM 的推理能力來分析和歸納搜尋到的資訊，識別出重複或不相關的內容。
5.  **反思與迭代**：在初步分析後，代理可能會發現某些趨勢的資訊不足，或者不同來源的資訊有衝突。它可能會反思，然後決定：
    *   再次發送特定的搜尋查詢以獲取更多細節。
    *   利用「Python 解釋器」工具來進行數據統計或處理，如果數據是結構化的。
    *   重新評估其篩選標準。
6.  **生成報告**：一旦代理認為它已收集並處理了足夠的資訊，它會利用 LLM 的生成能力，結合所有資訊，撰寫出一份結構清晰、內容準確的摘要報告。

整個過程中，代理不是一次性地輸出一個答案，而是透過一系列的「感知-思考-行動-反思」循環來逐步實現目標。

-----

### 與相鄰概念的關聯

#### RAG 與傳統 LLM 應用
*   **傳統 LLM 應用**：直接將用戶問題輸入 LLM，模型完全依賴其訓練時所學到的內部知識來生成答案。
    *   **優點**：簡單直接，無需額外數據準備。
    *   **缺點**：
        *   **知識截止 (Knowledge Cutoff)**：模型無法回答訓練數據截止日期之後發生的事件或新知識。
        *   **幻覺 (Hallucination)**：模型可能憑空捏造事實，給出看似合理但實際上錯誤的資訊。
        *   **缺乏透明度**：無法追溯答案的來源。
        *   **領域專有知識不足**：對於企業內部、專業領域的特定知識，通用 LLM 通常不了解。
*   **RAG 應用**：透過外部知識庫補充 LLM 的知識。
    *   **優點**：
        *   **克服知識截止**：可即時更新外部知識庫，提供最新資訊。
        *   **減少幻覺**：答案基於檢索到的事實，提升可靠性。
        *   **提高透明度**：可以指出答案來自哪個文檔或來源。
        *   **處理領域專有知識**：輕鬆整合企業或專業領域的內部數據。
    *   **缺點**：依賴檢索結果的品質，檢索品質差仍會導致生成品質差。需要額外的數據處理和基礎設施。

#### RAG 與微調 (Fine-tuning)
*   **微調 (Fine-tuning)**：透過在特定數據集上繼續訓練 LLM，調整其模型權重，使其更好地適應特定任務或領域。
    *   **目的**：改變模型行為、語氣、風格，或使其學習新的知識和模式（若數據中包含）。
    *   **何時使用**：
        *   當你需要模型以特定風格、語氣或格式回答問題時。
        *   當你需要模型對特定領域的術語、概念有更深層次的理解和推理能力時。
        *   當你有大量高質量的、帶有標籤的領域數據時。
    *   **缺點**：需要大量帶標籤的數據、計算資源。模型一旦微調完成，其知識就固化了，更新知識需要重新微調。
*   **RAG**：不改變 LLM 的模型權重，而是透過提供外部上下文來引導其生成。
    *   **目的**：為 LLM 提供外部、實時的**事實性知識**。
    *   **何時使用**：
        *   當知識頻繁更新，或知識量龐大且主要為事實性資訊時。
        *   當你希望答案有可追溯的來源時。
        *   當你不想（或不能）頻繁重新訓練模型時。
    *   **缺點**：檢索品質直接影響生成品質，無法改變 LLM 的底層推理能力或風格。

*   **兩者關係**：
    *   **互補而非替代**：微調可以提升 LLM 對特定領域的理解、推理能力和輸出風格，而 RAG 則負責提供最新、最準確的事實。
    *   **組合應用**：可以先對 LLM 進行微調，使其具備特定領域的語義理解和表達能力，然後再結合 RAG 系統來提供實時的領域知識。這樣能達到更好的效果，兼顧深度理解和廣泛知識。

#### 代理與 RAG 的關係
RAG 是代理可以**利用的一種強大工具**，但代理本身比 RAG 更廣泛、更具自主性。

*   **RAG 作為代理的工具**：
    *   當代理在執行任務時，遇到需要外部、最新或專有知識來做決策或回答問題時，它可以主動呼叫其內置的 RAG 模組或 RAG 服務。
    *   例如，一個研究型代理在撰寫報告時，可能會在某個環節判斷「我需要最新的市場數據」，然後它會啟動 RAG 流程，從其知識庫中檢索相關數據。
*   **代理管理 RAG 流程**：
    *   代理可以決定何時啟動 RAG、如何 формулировать 檢索查詢、甚至評估 RAG 的檢索結果是否滿意。
    *   例如，如果 RAG 返回的結果不夠理想，代理可能會反思並調整檢索策略（例如，擴展查詢詞、使用不同的知識庫），然後再次嘗試 RAG。
*   **代理更廣泛的自主性**：
    *   RAG 主要解決的是「知識獲取」的問題，它是一個特定的輸入增強機制。
    *   代理則是一個具備完整決策迴圈的實體，它不僅會獲取知識 (可能透過 RAG 或其他工具)，還會進行規劃、執行、反思，並綜合運用多種工具來達成複雜目標。
    *   換句話說，RAG 是代理「工具箱」中的一件工具，而代理是使用這個工具箱的「工匠」。

-----

### 進階內容

#### RAG 進階技巧

為了進一步提升 RAG 系統的性能和可靠性，研究者和開發者不斷探索以下進階策略：

1.  **優化檢索 (Retrieval Optimization)**：
    *   **查詢擴展 (Query Expansion)**：在向向量資料庫發送查詢前，先用 LLM 或詞彙模型擴展用戶的原始查詢，加入同義詞、相關概念，或將簡單查詢轉換為更複雜、語義更豐富的提問，以提高檢索命中率。
    *   **重排序 (Re-ranking)**：初始檢索通常會返回多個相似的文檔。可以使用另一個更精細的模型（如交叉編碼器 Cross-encoder）對這些候選文檔進行二次評分和排序，優先選擇最相關的文檔。
    *   **混合搜尋 (Hybrid Search)**：結合向量相似度搜尋（語義匹配）和關鍵詞搜尋（精確匹配），以兼顧語義理解和精確度。
    *   **HyDE (Hypothetical Document Embedding)**：使用 LLM 根據用戶查詢生成一個「假設性」的答案，然後將這個假設性答案轉換為向量，用它去檢索相似的真實文檔。這可以幫助捕獲更深層次的語義相關性。
    *   **多路徑檢索 (Multi-vector/Multi-path Retrieval)**：對於複雜的查詢，可能需要從不同的知識源或以不同的方式檢索資訊。例如，同時檢索摘要和原始文檔，或從多個向量空間檢索。

2.  **優化生成 (Generation Optimization)**：
    *   **上下文壓縮 (Context Compression)**：由於 LLM 的上下文窗口有限，有時檢索到的文檔可能過多或包含冗餘資訊。可以使用模型或演算法（如 LLM 自己）來壓縮或篩選檢索到的上下文，只保留最相關的內容，確保 LLM 接收到最精華的資訊。
    *   **多階段/多路徑 RAG (Multi-hop/Multi-stage RAG)**：對於需要多步推理的複雜問題，可以將 RAG 過程分解為多個步驟。例如，第一步檢索背景知識，第二步基於背景知識生成子問題，再用子問題進行第二次檢索，最後綜合所有資訊生成答案。
    *   **答案驗證 (Answer Verification)**：在 LLM 生成答案後，可以再次利用檢索系統或另一個 LLM 來驗證答案的事實準確性，減少幻覺。

#### 代理進階議題

1.  **多代理系統 (Multi-agent Systems)**：
    *   當一個複雜任務無法由單一代理有效完成時，可以設計多個代理，每個代理扮演不同的角色（例如：一個「規劃者」代理、一個「執行者」代理、一個「評估者」代理）。這些代理之間可以協同合作、分工明確，共同解決問題。
    *   **例子**：一個團隊協作完成研究報告，可能有數據收集代理、分析代理、寫作代理和審核代理。
2.  **代理的安全性與倫理考量**：
    *   **偏見與歧視**：代理的行為和決策可能繼承或放大訓練數據中的偏見。
    *   **濫用潛力**：惡意代理可能被用於生成假資訊、進行釣魚攻擊或自動化網路攻擊。
    *   **自主性與控制**：隨著代理能力越來越強，如何確保人類對其行為的有效控制，避免「失控」是重要的挑戰。
    *   **透明度與可解釋性**：理解代理為何做出某個決策，對於調試、信任和責任歸屬至關重要。
3.  **自主學習與適應 (Autonomous Learning and Adaptation)**：
    *   讓代理能夠從其與環境的互動中持續學習，改進其規劃策略、工具使用方式或決策邏輯。這可能涉及強化學習、自我進化等技術。

-----

### 常見錯誤與澄清

#### RAG 的常見誤解

1.  **RAG 是萬靈丹，能解決所有 LLM 幻覺問題**
    *   **澄清**：RAG 確實能顯著減少幻覺，但並非絕對。如果檢索到的文檔本身就是錯誤的、過時的，或與查詢不相關（"Garbage In, Garbage Out"），LLM 仍可能生成錯誤答案。此外，如果 LLM 未能完全理解檢索到的上下文，或者在整合資訊時出現偏差，也可能導致錯誤。檢索品質是 RAG 成功的關鍵。
2.  **RAG 等同於微調 (Fine-tuning)**
    *   **澄清**：這兩者是不同的技術，解決不同的問題。RAG 提供外部事實性知識而不改變模型權重，適合處理頻繁更新或大量外部數據。微調則調整模型權重，使其在特定任務上表現更好或適應特定風格，通常需要大量標註數據。它們可以互補使用，但不是一回事。
3.  **RAG 只適用於問答系統**
    *   **澄清**：雖然問答是 RAG 最直觀的應用，但它也可以用於摘要、內容創作、程式碼生成等。只要任何需要 LLM 依賴外部、最新或特定事實的任務，RAG 都能發揮作用。

#### 代理的常見誤解

1.  **代理只是複雜的 LLM 提示 (Prompt)**
    *   **澄清**：LLM 提示是代理的輸入之一，但代理遠不止於此。代理的核心在於其**決策迴圈**（感知-規劃-行動-反思）、**工具使用能力**和**自主性**。它會根據環境反饋多次與 LLM 互動，並主動調用外部資源。單純的 LLM 提示通常是一次性的輸入輸出。
2.  **代理總能找到最佳解或完美執行任務**
    *   **澄清**：代理的能力上限受其底層 LLM 的推理能力、所能使用的工具的限制，以及其規劃和反思邏輯的完善程度影響。複雜的任務可能導致代理陷入循環、產生不合理規劃或未能有效使用工具。代理的發展仍在早期階段，其「智能」仍是有限的。
3.  **代理意味著完全脫離人類控制**
    *   **澄清**：目前大多數代理系統都設計為在人類監管下工作，或者在特定、受限的環境中執行任務。對於關鍵或高風險的任務，人類的審核和最終決策仍然是不可或缺的。未來在自主性提升的同時，如何確保安全、可控和透明將是研究重點。

-----

### 小練習

#### 小練習 1：設計 RAG 系統場景

**情境**：一家大型製造公司希望為其客戶服務部門建立一個智慧問答系統。客戶經常詢問關於產品規格、故障排除步驟、保固條款、退換貨政策等問題。這些資訊分散在數千份 PDF 格式的產品手冊、內部知識庫網頁和 Excel 格式的數據表中。

**問題**：
1.  說明為何此場景適合使用 RAG，而非直接使用通用 LLM。
2.  簡述建立此 RAG 系統的關鍵步驟，從數據準備到最終應用。

**詳解**：

1.  **為何適合 RAG**：
    *   **知識專有性與廣度**：客戶的問題涉及公司獨有的產品細節、內部流程和保固條款，這些知識是通用 LLM 訓練時無法獲取的。
    *   **知識時效性**：產品規格、保固政策可能隨時間更新，通用 LLM 的知識有截止日期，無法提供最新資訊。RAG 可以透過更新知識庫來實現即時知識更新。
    *   **減少幻覺**：直接使用通用 LLM 可能會針對未知問題編造答案，產生「幻覺」。RAG 則能基於企業內部事實生成答案，大大提高可信度。
    *   **可追溯性**：RAG 系統可以指示答案來自哪份文件或哪段文字，增強透明度，方便客戶或客服人員驗證。

2.  **建立 RAG 系統的關鍵步驟**：

    *   **步驟一：數據收集與預處理 (Ingestion)**
        *   **收集**：從 PDF 手冊、內部網頁、Excel 表格等來源收集所有相關知識文檔。
        *   **解析與提取**：開發解析器來從不同格式中提取純文字內容（例如，PDF 解析器將 PDF 轉換為文字，Excel 解析器提取表格數據並結構化）。
        *   **清洗與規範化**：移除雜訊、錯誤，統一數據格式。

    *   **步驟二：數據切塊 (Chunking)**
        *   將提取的長篇文本內容切分成大小適中的「塊」（chunks）。過大會引入不相關資訊，過小則可能丟失上下文。通常設定一個固定字數或段落數的限制，並考慮重疊 (overlap) 以保留上下文連貫性。

    *   **步驟三：向量嵌入與索引 (Embedding & Indexing)**
        *   選擇一個合適的嵌入模型 (Embedding Model)，將每個文本塊轉換成高維度的數值向量。這些向量捕捉了文本的語義信息。
        *   將這些向量及其對應的原始文本塊存儲到一個**向量資料庫 (Vector Database)** 中，並建立索引以實現高效的相似度搜索。

    *   **步驟四：檢索模組開發 (Retrieval Module)**
        *   當用戶輸入問題時，使用相同的嵌入模型將用戶問題轉換為查詢向量。
        *   在向量資料庫中執行相似度搜索，找出與查詢向量最相似的 K 個文本塊（即最相關的知識片段）。
        *   可以加入重排序 (Re-ranking) 或過濾邏輯，進一步優化檢索結果。

    *   **步驟五：生成模組與應用整合 (Generation & Application Integration)**
        *   將用戶的原始問題和檢索到的 K 個文本塊（作為上下文）一起，構建一個提示 (prompt)。
        *   將此提示發送給一個大型語言模型 (LLM)（例如 GPT-4, Llama 2 等）。
        *   LLM 根據提供的上下文生成答案。
        *   將生成的答案整合到客戶服務應用界面中，並可選擇顯示檢索到的來源文檔，以增強透明度。

#### 小練習 2：判斷代理行為

**情境**：你正在開發一個應用程式，它需要根據用戶的請求，從網路上搜尋最新的市場趨勢數據，分析這些數據，然後生成一份包含圖表和文字說明的摘要報告。

**問題**：
1.  為了實現上述功能，你需要一個 LLM 還是 LLM 驅動的代理？請說明理由。
2.  列舉該代理在完成此任務時可能使用的至少三種「工具」。

**詳解**：

1.  **需要 LLM 驅動的代理**。

    *   **理由**：
        *   **多步驟任務**：這個任務涉及多個連續的、不同性質的子步驟（搜尋、分析、生成報告）。單純的 LLM 呼叫通常只能處理一次性的輸入輸出。
        *   **外部數據獲取**：需要從「網路上搜尋最新數據」，這意味著 LLM 需要一個外部工具（如搜尋引擎）來獲取其訓練數據之外的即時資訊。
        *   **數據分析**：任務要求「分析這些數據」，這可能涉及數據處理、統計計算，超出了 LLM 純文本生成的能力，需要專門的分析工具。
        *   **結構化輸出**：要求生成「包含圖表和文字說明的摘要報告」，這不僅是文本生成，還可能涉及圖表生成工具或數據可視化庫。
        *   **規劃與決策**：代理需要自主規劃這些步驟的順序，並根據每個步驟的結果來調整後續行動（例如，如果搜尋結果不理想，需要調整查詢重新搜尋）。這些都屬於代理的範疇。

2.  **代理可能使用的工具**：

    *   **網路搜尋引擎 API (e.g., Google Search API, Bing Search API)**：用於根據市場趨勢相關的關鍵詞，從網路上檢索最新的資訊和數據。
    *   **Python 解釋器 / 數據分析庫 (e.g., Pandas, NumPy)**：用於處理、分析從網路獲取的結構化或半結構化數據，進行統計計算、數據清洗等。代理可以生成 Python 程式碼並執行它。
    *   **圖表生成庫 / 數據可視化工具 (e.g., Matplotlib, Plotly)**：如果需要生成圖表，代理可以利用這些庫生成數據圖，然後將圖表嵌入到報告中。
    *   **文件操作工具 / 報告生成工具**：用於將文字說明和生成的圖表整合到一份格式化的報告中（例如生成 PDF 或 Word 文檔）。
    *   **RAG 系統（本身也可視為一種工具）**：如果代理擁有一個內部知識庫（如過去的市場報告），它可能會使用 RAG 工具從中檢索相關背景資訊。

-----

### 延伸閱讀/參考

*   **RAG 原始論文**：
    *   Lewis, P., et al. (2020). *Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks*. NeurIPS 2020. [arXiv:2005.11401](https://arxiv.org/abs/2005.11401)
*   **代理相關研究**：
    *   Wang, L., et al. (2023). *A Survey on Large Language Model based Autonomous Agents*. [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)
    *   Wei, J., et al. (2022). *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*. NeurIPS 2022. [arXiv:2201.11903](https://arxiv.org/abs/2201.11903) (間接相關，CoT 是代理規劃的基礎)
*   **開源 RAG 框架與代理框架**：
    *   **LangChain**: 一個用於開發 LLM 應用程式的框架，支持 RAG、代理和工具使用。
        *   [官方網站](https://www.langchain.com/)
    *   **LlamaIndex**: 專注於 LLM 數據框架，提供將任何數據源與 LLM 連接的工具，是 RAG 的核心組件。
        *   [官方網站](https://www.llamaindex.ai/)
*   **部落格文章與教學**：
    *   Hugging Face 的 RAG 介紹：[Hugging Face - RAG](https://huggingface.co/docs/transformers/model_doc/rag)
    *   深入理解 LLM Agents：[Towards Data Science - Understanding LLM Agents](https://towardsdatascience.com/understanding-llm-agents-42173169f4c3)