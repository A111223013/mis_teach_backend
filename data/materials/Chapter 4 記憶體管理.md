# Chapter 4 記憶體管理

記憶體是電腦系統中最核心的資源之一，其效率與效能直接影響著整個系統的運作。記憶體管理的核心目標是有效率地追蹤、分配、使用與回收主記憶體，同時確保多個程式能夠安全地共享有限的記憶體資源。本章將深入探討記憶體管理的概念、機制與挑戰。

-----

### 1. 核心概念與定義

#### 1.1 記憶體管理的重要性

**定義/核心觀念：**
記憶體管理 (Memory Management) 是一組作業系統用來管理電腦主記憶體 (RAM) 的功能。它負責處理以下任務：
*   **分配與回收：** 當程式啟動或結束時，分配和回收記憶體空間。
*   **保護：** 確保一個程式無法非法存取其他程式或作業系統的記憶體空間。
*   **共享：** 允許多個程式安全地共享部分記憶體，以提高效率（例如，共享函式庫）。
*   **位址轉換：** 將程式碼中使用的邏輯位址轉換為實際的實體記憶體位址。
*   **虛擬化：** 提供虛擬記憶體抽象層，讓程式認為自己擁有比實際記憶體更大的連續空間。

**例子或推導：**
想像一台電腦只有 4GB 實體記憶體，但您同時執行了瀏覽器、文字編輯器、音樂播放器等多個應用程式，這些程式的記憶體需求總和可能遠超 4GB。記憶體管理機制允許這些程式同時運行，並在需要時將不活躍的資料移至硬碟（交換），或只載入程式的活躍部分。此外，如果沒有記憶體保護，一個惡意或錯誤的程式可能會覆寫作業系統的核心資料，導致系統崩潰。

**與相鄰概念的關聯：**
記憶體管理是作業系統資源管理的一部分，與處理機管理、檔案系統管理和 I/O 管理共同構成作業系統的核心功能。它直接影響著多道程式設計的效率和安全性。

#### 1.2 邏輯位址與實體位址

**定義/核心觀念：**
*   **邏輯位址 (Logical Address / Virtual Address)：** 程式在執行時所產生的位址，也被稱為虛擬位址。它是相對於程式自身的起始點，由 CPU 產生。
*   **實體位址 (Physical Address)：** 記憶體單元在主記憶體中的實際位址。這是記憶體管理單元 (MMU) 將邏輯位址轉換後，記憶體控制器實際用來存取記憶體的位址。

**例子或推導：**
假設一個程式認為它的程式碼從位址 0 開始，並嘗試存取位址 100。這個 100 就是邏輯位址。如果作業系統將這個程式載入到實體記憶體位址 10000 的位置，那麼當程式存取邏輯位址 100 時，MMU 會將其轉換為實體位址 10000 + 100 = 10100。

位址轉換公式：`實體位址 = 基底位址 (Base Address) + 邏輯位址` (在簡單重定位方案中)

**與相鄰概念的關聯：**
邏輯位址與實體位址的分離是實現虛擬記憶體、多道程式設計和記憶體保護的基礎。沒有這種分離，每個程式都必須被載入到固定的實體位址，且無法輕鬆移動。

#### 1.3 位址綁定 (Address Binding)

**定義/核心觀念：**
位址綁定是指將程式的邏輯位址（符號位址）映射到實體記憶體位址的過程。綁定可以在不同的時間點發生：
*   **編譯時綁定 (Compile-time Binding)：** 如果在編譯時就知道程式將被載入到記憶體的哪個固定位置，編譯器可以直接產生絕對實體位址。
*   **載入時綁定 (Load-time Binding)：** 如果程式的實體位址在編譯時未知，但一旦載入就固定不變，編譯器會產生可重定位的程式碼。載入器 (loader) 會在程式載入主記憶體時執行位址綁定。
*   **執行時綁定 (Execution-time Binding / Runtime Binding)：** 如果程式在執行過程中可能從記憶體的一個位置移動到另一個位置（例如交換），那麼綁定必須延遲到執行時。這需要硬體支持，通常是透過記憶體管理單元 (MMU) 實現。

**例子或推導：**
*   **編譯時：** 早期作業系統，程式只能載入到記憶體開頭，編譯器直接寫死實體位址。
*   **載入時：** 一個作業系統可能在載入時分配一塊連續記憶體給程式，並讓載入器調整所有位址參考。
*   **執行時：** 現代作業系統幾乎都使用執行時綁定。當程式運行時，MMU 即時將 CPU 產生的邏輯位址轉換為實體位址。這是最靈活的，也是實現虛擬記憶體的關鍵。

**與相鄰概念的關聯：**
執行時綁定是分頁、分段、虛擬記憶體和交換等高級記憶體管理技術的基石，它提供了最大的靈活性，允許作業系統動態地管理記憶體資源。

#### 1.4 記憶體配置類型：連續與非連續

**定義/核心觀念：**
*   **連續記憶體配置 (Contiguous Memory Allocation)：** 每個程式都被分配一塊單一的、連續的實體記憶體區塊。
*   **非連續記憶體配置 (Non-contiguous Memory Allocation)：** 程式可以被分散載入到多個不連續的實體記憶體區塊中。

**例子或推導：**
*   **連續：** 想像一個停車場，每輛車都必須停在一個完整的、不中斷的停車格中。
*   **非連續：** 想像一個拼圖，每個拼圖塊雖然屬於同一個圖案，但可以放在不同的位置。作業系統透過位址映射機制（如分頁表）將這些分散的記憶體區塊邏輯上串聯起來。

**與相鄰概念的關聯：**
連續記憶體配置方案相對簡單，但在多道程式環境下容易產生嚴重的碎裂問題。非連續記憶體配置（如分頁和分段）則能更有效地利用記憶體，減少碎裂，是實現虛擬記憶體的基礎。

#### 1.5 碎裂 (Fragmentation)：內部與外部

**定義/核心觀念：**
碎裂是記憶體管理中一個常見的問題，指的是記憶體被分割成許多小區塊，導致記憶體雖然總量足夠，但沒有足夠大的連續區塊來滿足請求。
*   **外部碎裂 (External Fragmentation)：** 總體上存在足夠的空閒記憶體來滿足一個請求，但這些空閒記憶體分佈在許多不連續的小區塊中，無法形成一個大的連續區塊。這主要發生在連續記憶體配置方案中。
*   **內部碎裂 (Internal Fragmentation)：** 程式被分配的記憶體區塊大於其實際所需的記憶體量，多出來的、未被使用的空間就存在於已分配的區塊內部。這主要發生在固定分割區配置或分頁等技術中。

**例子或推導：**
*   **外部碎裂：** 您有 100KB 的空閒記憶體，分佈在三個區塊：20KB, 30KB, 50KB。一個需要 60KB 連續記憶體的程式將無法載入，即使總量夠用。
*   **內部碎裂：** 系統以 4KB 為單位（頁框或固定分割區）分配記憶體。一個程式需要 4.1KB 的記憶體，系統會分配兩個 4KB 區塊（共 8KB），其中 3.9KB ($2 \times 4KB - 4.1KB$) 將成為內部碎裂。或者一個程式只用 2.5KB，但分配給它一個 4KB 頁框，則有 1.5KB 內部碎裂。

**與相鄰概念的關聯：**
碎裂是衡量記憶體配置方案效率的重要指標。分頁和分段等非連續配置方案的設計目標之一就是減輕或消除外部碎裂，但它們可能引入內部碎裂。壓縮 (Compaction) 是一種處理外部碎裂的方法。

#### 1.6 交換 (Swapping)

**定義/核心觀念：**
交換是指作業系統暫時將一個程式或其部分程式從主記憶體移到硬碟上的交換空間 (Swap Space)，以釋放出主記憶體供其他程式使用。當需要該程式時，再將其從硬碟移回主記憶體。

**例子或推導：**
想像您同時打開了 20 個瀏覽器分頁，其中許多是閒置的。作業系統可能會將這些閒置分頁所佔用的記憶體交換到硬碟上，以便您正在使用的活躍分頁能夠獲得更多的實體記憶體，從而提高反應速度。當您切換到一個之前被交換出去的分頁時，作業系統會將其從硬碟讀回主記憶體。

**與相鄰概念的關聯：**
交換是實現虛擬記憶體的重要基礎之一，它允許系統運行比實際記憶體總量更大的程式集合。它也是解決外部碎裂問題的一種手段，因為透過交換可以將不活躍的程式移出記憶體，騰出更大的連續空間。然而，硬碟的存取速度遠慢於 RAM，頻繁的交換（稱為「抖動」）會嚴重降低系統效能。

-----

### 2. 連續記憶體配置與其挑戰

#### 2.1 固定分割區配置 (Fixed-Partition Allocation)

**定義/核心觀念：**
在固定分割區配置中，主記憶體被分割成固定大小的區域（分割區）。每個分割區可以容納一個程式。
*   **優點：** 實現簡單，記憶體保護容易。
*   **缺點：** 產生內部碎裂（如果程式小於分割區）和外部碎裂（如果沒有足夠大的分割區），分割區數量固定限制了多道程式的數量。

**例子或推導：**
假設主記憶體被分為四個固定大小的分割區：100KB, 200KB, 50KB, 150KB。
*   程式 A (90KB) 載入 100KB 分割區：產生 10KB 內部碎裂。
*   程式 B (180KB) 載入 200KB 分割區：產生 20KB 內部碎裂。
*   此時，一個需要 60KB 的程式 C 無法載入，因為沒有任何一個剩餘的分割區 (50KB, 150KB) 大於 60KB，即使 50KB + 150KB 的總和遠大於 60KB，但它們不連續。這就是外部碎裂。

**與相鄰概念的關聯：**
這是最簡單的連續記憶體配置方案，但由於其明顯的缺點，已很少用於現代作業系統。它引出了「碎裂」這個重要概念。

#### 2.2 可變分割區配置 (Variable-Partition Allocation)

**定義/核心觀念：**
在可變分割區配置中，記憶體會根據程式的實際需求動態地劃分成大小可變的區域。當一個程式載入時，作業系統會從空閒記憶體區塊中為它找到一個足夠大的連續空間。
**優點：** 消除內部碎裂（因為分配的空間剛好滿足需求），更能有效利用記憶體。
**缺點：** 會產生嚴重的外部碎裂，管理複雜。

**常見配置演算法：**
作業系統需要維護一個空閒區塊列表 (free list)，並在有新的記憶體請求時，從列表中選擇一個區塊：
1.  **首次適配 (First Fit)：** 掃描空閒區塊列表，選擇第一個足夠大的區塊。
    *   **優點：** 尋找速度快。
    *   **缺點：** 可能在列表開頭留下許多小碎塊。
2.  **最佳適配 (Best Fit)：** 掃描整個空閒區塊列表，選擇所有足夠大的區塊中，大小最接近請求的那個。
    *   **優點：** 傾向於留下更大的空閒區塊，減少外部碎裂。
    *   **缺點：** 尋找速度慢，且會產生很多非常小的外部碎塊。
3.  **最差適配 (Worst Fit)：** 掃描整個空閒區塊列表，選擇所有足夠大的區塊中，大小最大的那個。
    *   **優點：** 留下較大的剩餘區塊，可能對後續的大請求更有利。
    *   **缺點：** 尋找速度慢，容易導致大區塊很快被消耗殆盡。

**例子或推導：**
假設空閒記憶體區塊列表為：(100KB, 500KB, 200KB, 300KB, 600KB)。
現有一個 210KB 的程式請求記憶體。
*   **首次適配：** 選擇 500KB 區塊 (因為 100KB 不夠，500KB 是第一個夠的)。剩下 290KB。
*   **最佳適配：** 選擇 300KB 區塊 (因為 200KB 不夠，300KB 是所有夠的區塊 (500, 200, 300, 600) 中最小且最接近 210KB 的)。剩下 90KB。
*   **最差適配：** 選擇 600KB 區塊。剩下 390KB。

**與相鄰概念的關聯：**
可變分割區配置是連續記憶體配置的另一種形式。它引入了管理空閒區塊和選擇最佳區塊的策略，這些策略直接影響系統記憶體的使用效率和外部碎裂的嚴重程度。當外部碎裂問題嚴重時，可能需要進行記憶體壓縮 (Compaction)，將所有已分配的區塊移動到記憶體的一端，把所有空閒區塊合併成一個大的連續區塊。

-----

### 3. 非連續記憶體配置：分頁 (Paging)

#### 3.1 核心概念：分頁表 (Page Table), 頁框 (Frame) 與頁 (Page)

**定義/核心觀念：**
分頁是一種非連續記憶體配置技術，旨在解決連續配置中的外部碎裂問題。
*   **實體記憶體：** 被劃分成固定大小的區塊，稱為 **頁框 (Frame)**。
*   **邏輯記憶體 (程式的位址空間)：** 被劃分成與頁框大小相同的區塊，稱為 **頁 (Page)**。
*   **分頁表 (Page Table)：** 每個程式都有一個分頁表，它記錄了程式的每個邏輯頁對應到哪個實體頁框的映射關係。分頁表本身儲存在主記憶體中。

**工作原理：**
當 CPU 產生一個邏輯位址時，MMU 會將其分割成兩部分：
1.  **頁碼 (Page Number, $p$)：** 用於在分頁表中查找對應的頁框號。
2.  **頁偏移量 (Page Offset, $d$)：** 用於在頁框內定位實際位址。

**位址轉換：**
`實體位址 = (頁框號 * 頁框大小) + 頁偏移量`

**例子或推導：**
假設系統使用 4KB (即 $2^{12}$ Bytes) 的頁大小。
一個 32 位的邏輯位址（可定址 $2^{32}$ Bytes）。
*   頁偏移量 (d) 需要 12 位（因為 $2^{12}$ Bytes = 4KB）。
*   頁碼 (p) 需要 $32 - 12 = 20$ 位。

當 CPU 產生邏輯位址 `0x0000A40C` 時：
*   頁碼 (p) = `0x0000A` (前 20 位)
*   頁偏移量 (d) = `0x40C` (後 12 位)

MMU 會查閱當前程式的分頁表，假設頁碼 `0x0000A` 對應的頁框號是 `0x123`。
那麼實體位址為：`0x123` (頁框號) `0x40C` (偏移量) = `0x12340C`。

**與相鄰概念的關聯：**
分頁是實現虛擬記憶體最常用的基礎機制，它徹底消除了外部碎裂，但可能引入輕微的內部碎裂（最後一個頁可能沒有完全填滿）。分頁表是位址轉換的核心，但其存取效率對系統性能至關重要。

#### 3.2 轉譯後備緩衝區 (TLB - Translation Lookaside Buffer)

**定義/核心觀念：**
由於每次記憶體存取都需要進行位址轉換，這意味著要先存取分頁表（在記憶體中），然後再存取實際資料（也在記憶體中），這會導致兩次記憶體存取，降低效率。轉譯後備緩衝區 (TLB) 是一個高速硬體快取，專門用於儲存近期使用過的頁碼到頁框號的映射關係。

**工作原理：**
1.  CPU 產生邏輯位址。
2.  MMU 首先在 TLB 中查找頁碼。
3.  **TLB 命中 (Hit)：** 如果找到映射關係，直接從 TLB 取得頁框號，然後生成實體位址。這一步速度非常快。
4.  **TLB 未命中 (Miss)：** 如果 TLB 中沒有，MMU 必須從主記憶體的分頁表中查找映射關係。
5.  查到後，將該映射關係添加到 TLB 中以備將來使用（如果 TLB 已滿，則根據替換策略踢出舊的項目）。
6.  最後，生成實體位址。

**例子或推導：**
假設 TLB 命中率為 90%，TLB 查詢時間為 20ns，記憶體存取時間為 100ns。
有效存取時間 (Effective Access Time, EAT)：
`EAT = (TLB 命中率 * (TLB 查詢時間 + 記憶體存取時間)) + (TLB 未命中率 * (TLB 查詢時間 + 記憶體存取時間 (分頁表) + 記憶體存取時間 (資料)))`
`EAT = (0.9 * (20ns + 100ns)) + (0.1 * (20ns + 100ns + 100ns))`
`EAT = (0.9 * 120ns) + (0.1 * 220ns)`
`EAT = 108ns + 22ns = 130ns`

如果沒有 TLB，每次存取都需要 2 次記憶體存取，即 $2 \times 100ns = 200ns$。TLB 顯著提高了性能。

**與相鄰概念的關聯：**
TLB 是分頁機制不可或缺的性能優化組件，是快取記憶體概念在位址轉換領域的應用。它的存在使得分頁的開銷得以控制在可接受的範圍內。

#### 3.3 分頁表的結構 (多層分頁、反向分頁表)

**定義/核心觀念：**
單一的分頁表對於擁有巨大邏輯位址空間的 64 位系統來說，會非常龐大，甚至可能佔用數 GB 的記憶體。為了解決這個問題，出現了不同的分頁表結構。

1.  **多層分頁 (Multi-level Paging)：** 將分頁表本身進行分頁。例如，一個兩層分頁系統，最外層是一個「外部分頁表」，它的每個條目指向一個「內部分頁表」。只有當內部分頁表實際包含有效映射時才載入。
    *   **優點：** 只需為程式的活躍部分分配分頁表空間，節省記憶體。
    *   **缺點：** 每次位址轉換可能需要多次記憶體存取來遍歷多層分頁表（但 TLB 可以緩解此問題）。

2.  **反向分頁表 (Inverted Page Table)：** 系統中只有一張反向分頁表，每個實體頁框只有一個條目。這個條目記錄了哪個程式的哪個邏輯頁佔用了這個實體頁框。
    *   **優點：** 分頁表大小與實體記憶體大小成正比，而不是與邏輯位址空間大小成正比，對於大型虛擬位址空間特別節省記憶體。
    *   **缺點：** 查找映射關係時，需要掃描整個表或使用雜湊表，查找效率可能較低（但也通常搭配 TLB 使用）。

**例子或推導：**
*   **兩層分頁：**
    一個 32 位邏輯位址，頁大小 4KB ($2^{12}$ Bytes)。
    頁碼需要 20 位。將這 20 位再分成 10 位外部頁碼和 10 位內部頁碼。
    邏輯位址 ($p_1, p_2, d$) -> $p_1$ 指向外部分頁表 -> 取得內部分頁表的基底位址 -> $p_2$ 指向內部分頁表 -> 取得頁框號 -> 與 $d$ 組合成實體位址。
    如果一個程式只使用了幾個頁，它只需要少量的內部分頁表，而不需要完整的 2^20 個頁表條目。

*   **反向分頁表：**
    每個條目包含 (Process ID, 頁碼)。當 CPU 產生 (Process ID, 頁碼) 時，需要搜尋反向分頁表，找到匹配的條目，該條目的索引就是實體頁框號。這通常透過雜湊來加速查找。

**與相鄰概念的關聯：**
分頁表的結構優化是處理大規模虛擬位址空間和節省記憶體資源的關鍵。多層分頁和反向分頁表各有優缺點，通常與 TLB 協同工作，以在空間效率和時間效率之間取得平衡。

-----

### 4. 非連續記憶體配置：分段 (Segmentation)

#### 4.1 核心概念：分段表 (Segment Table)

**定義/核心觀念：**
分段是一種記憶體管理方案，它支援使用者對記憶體的抽象視圖。程式員將程式視為一組邏輯單元（段），例如：程式碼段、資料段、堆棧段、子程式段等。每個段都有自己的名稱和長度。
*   **段 (Segment)：** 程式的邏輯單元，大小可變。
*   **分段表 (Segment Table)：** 每個程式都有一個分段表。分段表中的每個條目包含兩個欄位：
    *   **基底位址 (Base Address)：** 該段在實體記憶體中的起始位址。
    *   **長度限制 (Limit)：** 該段的長度。

**位址轉換：**
CPU 產生一個邏輯位址 (段號 $s$, 偏移量 $d$)。
1.  用段號 $s$ 作為分段表的索引。
2.  檢查偏移量 $d$ 是否小於或等於該段的長度限制 (Limit)。如果 $d \geq Limit$，則發生越界錯誤。
3.  實體位址 = 分段表[s].基底位址 + 偏移量 $d$。

**例子或推導：**
假設一個程式有三個段：
*   段 0 (程式碼)：基底 1000, 長度 200
*   段 1 (資料)：基底 3000, 長度 500
*   段 2 (堆棧)：基底 8000, 長度 300

如果 CPU 產生邏輯位址 (段 1, 偏移 150)：
1.  查分段表，段 1 的基底是 3000，長度是 500。
2.  檢查偏移 150 < 500 (合法)。
3.  實體位址 = 3000 + 150 = 3150。

如果 CPU 產生邏輯位址 (段 1, 偏移 600)：
1.  查分段表，段 1 的基底是 3000，長度是 500。
2.  檢查偏移 600 < 500 (不合法)，發生越界錯誤。

**與相鄰概念的關聯：**
分段支援程式的邏輯視圖，方便共享（例如，兩個程式可以共享同一個程式碼段）和保護（每個段可以有不同的存取權限）。分段的缺點是它會導致外部碎裂，因為段的大小是可變的，而且需要找到連續的實體記憶體空間來容納它們。

#### 4.2 分段與分頁的比較

| 特性           | 分頁 (Paging)                                     | 分段 (Segmentation)                                |
| :------------- | :------------------------------------------------ | :------------------------------------------------- |
| **使用者視角** | 不可見，使用者感覺記憶體是單一、連續的            | 可見，使用者將程式組織成邏輯段，如程式碼、資料等 |
| **位址空間**   | 線性的一維位址空間                                | 二維位址空間 (段號, 偏移量)                        |
| **區塊大小**   | 固定大小的頁 (Page)                               | 可變大小的段 (Segment)                             |
| **碎裂**       | 內部碎裂 (最後一頁可能未完全填滿)                 | 外部碎裂 (難以找到連續空間)                        |
| **實作複雜度** | 較為複雜，需要分頁表、TLB 等硬件支持              | 較為簡單，但外部碎裂處理較複雜                     |
| **保護與共享** | 透過頁表條目中的權限位和共享頁框實現              | 透過段表條目中的權限位和共享段實現，更符合邏輯 |

**分段分頁 (Segmented Paging)：**
**定義/核心觀念：**
結合了分段和分頁的優點。每個邏輯段本身又被分頁。
CPU 產生邏輯位址 (段號 $s$, 邏輯頁碼 $p$, 頁偏移量 $d$)。
*   首先，透過段號 $s$ 查閱主分段表，找到該段的分頁表的基底位址。
*   然後，透過邏輯頁碼 $p$ 查閱該段的分頁表，找到實體頁框號。
*   最後，將實體頁框號和頁偏移量 $d$ 組合，形成最終的實體位址。

**優點：**
*   既保留了分段的邏輯視圖、共享與保護的優點，又解決了分段的外部碎裂問題。
*   每個段可以獨立管理其頁表，提高了記憶體利用率。

**與相鄰概念的關聯：**
分段分頁是現代作業系統中常見的一種混合記憶體管理方案，例如 Intel IA-32/x86-64 架構就使用了類似的概念，但在實際應用中，純分頁（輔以 TLB 和多級分頁）通常被認為是更簡潔高效的方案。

-----

### 5. 虛擬記憶體 (Virtual Memory)

#### 5.1 核心概念：按需分頁 (Demand Paging)

**定義/核心觀念：**
虛擬記憶體是一種記憶體管理技術，它允許執行程式所需的記憶體量大於實際可用的實體記憶體。其核心思想是將程式的邏輯位址空間與實體記憶體分離，讓程式員感覺擁有一個巨大且連續的位址空間。
**按需分頁 (Demand Paging)** 是虛擬記憶體最常見的實現方式。它只在真正需要時才將程式的頁面載入到實體記憶體中，而不是一次性載入整個程式。

**工作原理：**
1.  當程式啟動時，只有一小部分（甚至沒有）頁面被載入到實體記憶體。
2.  當 CPU 存取一個尚未載入到實體記憶體的頁面時，會發生一個 **頁錯誤 (Page Fault)**。
3.  作業系統介入，將所需的頁面從硬碟上的交換空間 (Swap Space) 載入到一個空閒的實體頁框中。
4.  更新分頁表，將該邏輯頁與新載入的實體頁框關聯。
5.  重新啟動導致頁錯誤的指令。

**優點：**
*   允許執行比實體記憶體更大的程式。
*   允許更多程式同時運行（多道程式的程度提高）。
*   減少了程式載入時間。
*   提高了 CPU 利用率，因為 I/O 操作可以在頁面載入時進行。

**與相鄰概念的關聯：**
虛擬記憶體是現代作業系統的基石，它與分頁機制緊密結合。頁錯誤是虛擬記憶體運作的關鍵事件，而頁替換演算法則是處理頁錯誤時如何選擇替換頁的策略。

#### 5.2 頁錯誤 (Page Fault)

**定義/核心觀念：**
頁錯誤是 CPU 存取一個邏輯頁時，發現該頁面沒有被載入到實體記憶體中時所產生的中斷。

**頁錯誤處理流程：**
1.  硬體捕獲到一個頁錯誤（透過分頁表條目中的「有效/無效」位）。
2.  作業系統的中斷處理程式被呼叫。
3.  OS 檢查該邏輯位址是否合法（即是否在程式的有效位址空間內）。如果不合法，則終止程式。
4.  OS 找到一個空閒的實體頁框。如果沒有空閒頁框，則根據頁替換演算法選擇一個犧牲頁框，並將其內容寫回硬碟（如果被修改過）。
5.  從硬碟上的交換空間讀取所需的頁面到選定的實體頁框。
6.  更新分頁表條目，標記該頁為「有效」，並指向新的實體頁框。
7.  重新執行導致頁錯誤的指令。

**與相鄰概念的關聯：**
頁錯誤是按需分頁的核心事件。頁錯誤的頻率直接影響系統性能，而頁替換演算法的目標就是最小化頁錯誤率。

#### 5.3 頁替換演算法 (Page Replacement Algorithms)

**定義/核心觀念：**
當發生頁錯誤且實體記憶體中沒有空閒頁框時，作業系統必須選擇一個已載入的頁面將其替換掉。頁替換演算法的目標是選擇一個「最佳」的頁面來替換，以最小化未來再次發生頁錯誤的機率。

**常見演算法：**
1.  **先進先出 (FIFO - First-In, First-Out)：**
    *   **策略：** 選擇最早載入到記憶體的頁面進行替換。
    *   **優點：** 實現簡單。
    *   **缺點：** 可能替換掉常用的頁面（Belady's Anomaly - 增加頁框數反而導致更多頁錯誤）。

2.  **最佳頁替換 (Optimal Page Replacement)：**
    *   **策略：** 選擇在未來最長時間內不會被使用的頁面進行替換。
    *   **優點：** 產生最少的頁錯誤（理論上的最佳演算法）。
    *   **缺點：** 無法實現，因為需要預知未來。主要用於評估其他演算法的性能。

3.  **最近最少使用 (LRU - Least Recently Used)：**
    *   **策略：** 選擇在過去最長時間內沒有被使用的頁面進行替換。
    *   **優點：** 實踐中表現良好，基於局部性原理。
    *   **缺點：** 實現複雜，需要昂貴的硬體支持（計時器、計數器）或軟體維護（堆棧）。

4.  **時鐘演算法 (Clock / Second Chance)：**
    *   **策略：** 一種對 FIFO 的改進，利用每個頁面的「使用位」(Reference Bit)。
        *   當頁面被存取時，其使用位設置為 1。
        *   替換時，演算法以循環方式掃描頁面。如果頁面的使用位為 1，則將其清零，並給予「第二次機會」，繼續檢查下一個頁面。
        *   如果頁面的使用位為 0，則選擇該頁面進行替換。
    *   **優點：** 比 LRU 實現簡單，且表現優於 FIFO。
    *   **缺點：** 不如 LRU 精確。

**例子或推導：**
假設頁框數為 3，頁面參考字串為：`7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1`。

*   **FIFO：**
    | 7   | 0   | 1   | 2   | 0   | 3   | 0   | 4   | 2   | 3   | 0   | 3   | 2   | 1   | 2   | 0   | 1   | 7   | 0   | 1   |
    | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
    | 7   | 7   | 7   | 2   | 2   | 2   | 0   | 0   | 0   | 3   | 3   | 3   | 2   | 2   | 2   | 0   | 0   | 0   | 7   | 7   |
    |     | 0   | 0   | 0   | 0   | 3   | 3   | 3   | 3   | 0   | 0   | 0   | 0   | 1   | 1   | 1   | 7   | 7   | 7   | 0   |
    |     |     | 1   | 1   | 1   | 1   | 1   | 4   | 4   | 4   | 4   | 2   | 2   | 2   | 0   | 0   | 1   | 1   | 1   |
    頁錯誤次數：15

*   **LRU：**
    | 7   | 0   | 1   | 2   | 0   | 3   | 0   | 4   | 2   | 3   | 0   | 3   | 2   | 1   | 2   | 0   | 1   | 7   | 0   | 1   |
    | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
    | 7   | 7   | 7   | 2   | 2   | 2   | 0   | 0   | 0   | 3   | 3   | 3   | 2   | 2   | 2   | 0   | 0   | 0   | 7   | 7   |
    |     | 0   | 0   | 0   | 0   | 0   | 3   | 3   | 3   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 1   | 1   | 0   |
    |     |     | 1   | 1   | 1   | 1   | 1   | 1   | 4   | 4   | 4   | 4   | 4   | 4   | 4   | 4   | 4   | 4   | 4   | 1   |
    頁錯誤次數：12

**與相鄰概念的關聯：**
頁替換演算法是虛擬記憶體性能的關鍵因素，直接影響著系統的頁錯誤率和整體吞吐量。它與局部性原理密切相關，好的演算法能夠利用程式的存取局部性來減少頁錯誤。

#### 5.4 寫時複製 (Copy-on-Write, COW)

**定義/核心觀念：**
寫時複製是一種優化技術，當父程序呼叫 `fork()` 創建子程序時，作業系統並不會立即複製父程序的所有頁面給子程序。相反，父子程序會共享這些頁面，但會將它們標記為「只讀」。只有當任一程序試圖修改（寫入）這些共享頁面中的一個時，該頁面才會被複製一份，兩個程序各自擁有自己的副本，並可獨立修改。

**優點：**
*   **減少資源消耗：** 避免不必要的記憶體複製，特別是當子程序執行 `exec()` 而替換自身程式碼時，可以節省大量記憶體和 CPU 時間。
*   **提高性能：** 減少 `fork()` 系統呼叫的開銷。

**例子或推導：**
1.  父程序有一個頁面 P1 (內容為 "Hello")。
2.  父程序 `fork()` 子程序。此時，P1 被標記為只讀，父子程序都指向 P1 的實體頁框。
3.  父程序嘗試修改 P1 的內容為 "World"。
    *   OS 檢測到寫入只讀頁面，觸發頁保護錯誤。
    *   OS 介入，複製 P1 的內容到一個新的實體頁框 P2。
    *   父程序的分頁表更新，P1 指向 P2 (現在可寫入)。
    *   父程序在 P2 上寫入 "World"。
4.  此時，父程序看到 "World"，子程序仍然看到 "Hello"。

**與相鄰概念的關聯：**
寫時複製是虛擬記憶體技術的一個重要應用，它利用了頁保護機制，是實現高效進程創建的關鍵技術。它也是記憶體管理中資源共享和效率優化的一個典範。

#### 5.5 抖動 (Thrashing)

**定義/核心觀念：**
抖動是指作業系統的性能急劇下降的狀態，因為程式花費了過多的時間在頁面調入/調出（交換）上，而不是執行有用的工作。當系統分配給程式的實體記憶體不足以容納其 **工作集 (Working Set)** 時，就容易發生抖動。

**工作集 (Working Set)：** 一個程序在某個時間窗口內，活躍使用的頁面集合。
*   如果一個程式的實體記憶體空間小於其工作集，它將無法容納其所需的活躍頁面。
*   每次存取都會導致頁錯誤，導致頁面頻繁地在記憶體和硬碟之間交換。

**原因：**
*   系統中執行程式過多，記憶體資源被過度分配。
*   程式的局部性行為不佳。

**解決方案：**
*   **增加實體記憶體：** 最直接但成本最高的方法。
*   **減少多道程式程度：** 暫停或終止一些不活躍的程式。
*   **基於工作集或頁錯誤頻率的替換策略：** 作業系統監控頁錯誤率，並根據情況調整分配給程式的頁框數量。
*   **頁鎖定 (Page Locking)：** 將某些關鍵頁面（如作業系統核心程式碼）鎖定在記憶體中，防止被交換出去。

**與相鄰概念的關聯：**
抖動是虛擬記憶體技術的一個主要挑戰，它強調了頁面替換演算法和記憶體分配策略的重要性。工作集模型是理解和預防抖動的理論基礎。

-----

### 6. 常見錯誤與澄清

#### 6.1 邏輯位址與虛擬位址的混淆

**錯誤：** 認為邏輯位址和虛擬位址是不同的概念。
**澄清：** 在大多數現代作業系統語境下，**邏輯位址 (Logical Address)** 和 **虛擬位址 (Virtual Address)** 是可以互換使用的術語。它們都指的是 CPU 產生、程式內部使用的抽象位址，與實體記憶體位址無關。

#### 6.2 內部碎裂與外部碎裂的區分

**錯誤：** 混淆內部碎裂和外部碎裂。
**澄清：**
*   **內部碎裂 (Internal Fragmentation)：** 發生在 **已分配的記憶體區塊內部**。由於分配單元大小固定（如頁或固定分割區），程式即使只需部分空間，也會被分配整個單元，導致單元內部有未使用的空間。例如，一個 4KB 頁框中只有 2.5KB 被使用。
*   **外部碎裂 (External Fragmentation)：** 發生在 **未分配的空閒記憶體區塊之間**。總的空閒記憶體充足，但這些空閒區塊是分散的、不連續的，無法滿足需要連續大區塊的請求。例如，空閒記憶體有 20KB, 30KB, 50KB，但請求一個 60KB 的連續區塊。
*   **分頁** 解決了外部碎裂，但引入了內部碎裂。
*   **分段** 消除了內部碎裂，但會導致外部碎裂。

#### 6.3 頁替換演算法的選擇準則

**錯誤：** 認為 LRU 總是最好的頁替換演算法。
**澄清：** LRU 在理論上和實踐中表現良好，因為它利用了時間局部性原理。然而：
*   **實現成本高昂：** 純粹的 LRU 需要硬體支持（如時間戳或計數器）或複雜的軟體維護（如堆棧），成本高且會增加系統開銷。
*   **近似 LRU 算法：** 實際系統通常採用近似 LRU 算法，例如時鐘演算法（Second-Chance），它在性能和實現複雜度之間取得了較好的平衡。
*   **最佳演算法是理論值：** 最佳頁替換演算法是不可實現的，但它為評估其他算法提供了一個基準。不同的工作負載可能適合不同的算法。

-----

### 7. 小練習 (附詳解)

#### 小練習 1: 分頁位址轉換

**題目：**
假設一個虛擬記憶體系統使用 32 位元邏輯位址，頁面大小為 4KB (2^12 Bytes)。
分頁表條目 (PTE) 大小為 4 Bytes。
某個程式的邏輯位址 `0x00012345` 欲被轉換為實體位址。
已知該程式的分頁表位於實體位址 `0x80000000`，且分頁表中頁碼為 `0x00012` 的條目內容為 `0x0000C00F` (其中 `0x0000C` 是頁框號，最後一位 `F` 代表一些狀態位，假設其為有效位)。

請計算出該邏輯位址對應的實體位址。

**詳解：**

1.  **確定頁面大小與位址的劃分：**
    *   頁面大小為 4KB = $2^{12}$ Bytes。
    *   頁偏移量 (Page Offset, $d$) 需要 12 位。
    *   邏輯位址是 32 位元，所以頁碼 (Page Number, $p$) 需要 $32 - 12 = 20$ 位。

2.  **將邏輯位址 `0x00012345` 拆分為頁碼和偏移量：**
    *   邏輯位址為 `0x00012345`。
    *   頁碼 (前 20 位): `0x00012`
    *   頁偏移量 (後 12 位): `0x345`

3.  **計算分頁表條目的實體位址 (PTE Address)：**
    *   分頁表基底位址：`0x80000000`
    *   頁碼：`0x00012`
    *   每個 PTE 大小：4 Bytes
    *   PTE Address = 分頁表基底位址 + (頁碼 * PTE 大小)
    *   PTE Address = `0x80000000` + (`0x00012` * 4)
    *   `0x00012` (十進制) = $1 \times 16^4 + 2 \times 16^0 = 65536 + 2 = 65538$
    *   $65538 \times 4 = 262152$ (十進制)
    *   $262152$ (十進制) = `0x00040008` (十六進制)
    *   PTE Address = `0x80000000` + `0x00040008` = `0x80040008`

4.  **從分頁表中讀取頁框號：**
    *   根據題目，分頁表中頁碼為 `0x00012` 的條目內容為 `0x0000C00F`。
    *   我們假設 `0x0000C` 是頁框號。
    *   頁框號 (Frame Number, $f$) = `0x0000C`

5.  **組合實體位址：**
    *   實體位址 = (頁框號 * 頁面大小) + 頁偏移量
    *   實體位址 = (`0x0000C` << 12) | `0x345` (左移 12 位相當於乘以 $2^{12}$)
    *   實體位址 = `0xC000` + `0x345`
    *   實體位址 = `0x0000C345`

**最終答案：** 邏輯位址 `0x00012345` 對應的實體位址是 `0x0000C345`。

-----

#### 小練習 2: LRU 頁替換演算法

**題目：**
假設系統有 4 個實體頁框可用。給定以下頁面參考字串：
`4, 1, 2, 4, 3, 2, 1, 5, 2, 1, 4, 3, 6, 2, 1`

請使用 LRU (Least Recently Used) 頁替換演算法，計算過程中發生的頁錯誤次數，並展示每個步驟頁框內的頁面狀態。

**詳解：**

**頁框數：4**
**頁面參考字串：`4, 1, 2, 4, 3, 2, 1, 5, 2, 1, 4, 3, 6, 2, 1`**

我們將使用一個列表來表示頁框內容，並在旁邊標註頁面上次被使用的時間戳（或順序），LRU 總是替換時間戳最小的頁面。

| 參考頁 | 頁框 1 | 頁框 2 | 頁框 3 | 頁框 4 | 頁錯誤? | LRU 替換的頁 |
| :--- | :----: | :----: | :----: | :----: | :-----: | :----------- |
| `4`  |   4    |        |        |        |    是   |              |
| `1`  |   4    |   1    |        |        |    是   |              |
| `2`  |   4    |   1    |   2    |        |    是   |              |
| `4`  |   4    |   1    |   2    |        |    否   |              |
| `3`  |   4    |   1    |   2    |   3    |    是   |              |
| `2`  |   4    |   1    |   2    |   3    |    否   |              |
| `1`  |   4    |   1    |   2    |   3    |    否   |              |
| `5`  |   5    |   1    |   2    |   3    |    是   |      4       |
| `2`  |   5    |   1    |   2    |   3    |    否   |              |
| `1`  |   5    |   1    |   2    |   3    |    否   |              |
| `4`  |   5    |   4    |   2    |   3    |    是   |      1       |
| `3`  |   5    |   4    |   2    |   3    |    否   |              |
| `6`  |   6    |   4    |   2    |   3    |    是   |      5       |
| `2`  |   6    |   4    |   2    |   3    |    否   |              |
| `1`  |   6    |   4    |   2    |   1    |    是   |      3       |

**頁錯誤次數計算：**
統計「頁錯誤?」欄位中「是」的數量。
1 (4) + 1 (1) + 1 (2) + 0 (4) + 1 (3) + 0 (2) + 0 (1) + 1 (5) + 0 (2) + 0 (1) + 1 (4) + 0 (3) + 1 (6) + 0 (2) + 1 (1)
總計：$1+1+1+1+1+1+1 = 7$ 次頁錯誤。

**最終答案：** LRU 演算法在此參考字串下，發生了 **7** 次頁錯誤。

-----

### 8. 延伸閱讀/參考

1.  **作業系統概念 (Operating System Concepts)** by Abraham Silberschatz, Peter B. Galvin, Greg Gagne. (經典教材，詳細介紹各種記憶體管理技術)。
2.  **現代作業系統 (Modern Operating Systems)** by Andrew S. Tanenbaum, Herbert Bos. (另一本經典，提供更深入的系統設計和實作細節)。
3.  **Understanding the Linux Kernel** by Daniel P. Bovet, Marco Cesati. (針對 Linux 記憶體管理實作的詳細解析)。
4.  **CPU Cache, TLB, and Context Switch - A Primer for the HPC Admin**: 深入了解 TLB 在高性能計算中的作用。
5.  **Virtual Memory: Issues, Solutions, and Futures**: 探討虛擬記憶體的演變和未來發展。